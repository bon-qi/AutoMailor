<!doctype html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Publications | Real Virtual Humans | University of TÃ¼bingen </title><link rel="stylesheet" href="/css/all.css?t=1634472901"></head><body><div class="border-bottom box-shadow mb-5 bg-grey pt-1"><nav class="navbar navbar-expand-md navbar-light pt-4 pb-4"><div class="container"><button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#navbar"><span class="navbar-toggler-icon"></span></button><div class="navbar-collapse collapse" id="navbar"><ul class="navbar-nav m-auto"><li class="nav-item"><a class="p-sm-2 p-lg-3" href="/">Home</a></li><li class="nav-item"><a class="p-sm-2 p-lg-3" href="/people.html">Team</a></li><li class="nav-item"><a class="p-sm-2 p-lg-3" href="/research.html">Research</a></li><li class="nav-item active"><a class="p-sm-2 p-lg-3" href="/publications.html">Publications</a></li><li class="nav-item"><a class="p-sm-2 p-lg-3" href="/software.html">Data&nbsp;&&nbsp;Software</a></li><li class="nav-item"><a class="p-sm-2 p-lg-3" href="/jobs.html">Job&nbsp;Offers</a></li><li class="nav-item"><a class="p-sm-2 p-lg-3" href="/talks.html">Talks</a></li><!--                     <li class="nav-item"> --><!--                         <a class="p-sm-2 p-lg-3" href="/teaching.html">Teaching</a> --><!--                     </li> --><li class="nav-item dropdown show"><a href type="javascript:void(0)" class="p-sm-2 p-lg-3" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="true">Teaching</a><div class="dropdown-menu dropdown-menu-right dropdown-danger"><div class="dropdown-header"><a class="dropdown-item" href="/teaching_thesis.html">Bachelor and Master Theses</a><a class="dropdown-item" href="/teaching.html">Current Lecture/Seminar</a><a class="dropdown-item" href="/teaching_old.html">Past Lectures</a></div></div></div></div></nav><div class="mt-5 mb-5 container"><h1 class="text-center">Publications</h1></div></div><main role="main" id="main", class="container"><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/control-nerf/teaser.gif" alt="Control-NeRF: Editable Feature Volumes for Scene Rendering and Manipulation" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Lazova.html">Verica Lazova</a>,
                                                <a href="/people/Guzov.html">Vladimir Guzov</a>,
                                                <span>Kyle Olszewski</span>,
                                                <span>Sergey Tulyakov</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Control-NeRF: Editable Feature Volumes for Scene Rendering and Manipulation</strong><br/>
                                                                        in <em>Winter Conference on Applications of Computer Vision (WACV)</em>,
                                                                                                                        
            2023.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#lazova2023control"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="https://arxiv.org/pdf/2204.10850" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2204.10850" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/control-nerf/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="lazova2023control"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Control-NeRF: Editable Feature Volumes for Scene Rendering and Manipulation</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{lazova2023control,
    title = {Control-NeRF: Editable Feature Volumes for Scene Rendering and Manipulation},
    author = {Lazova, Verica and Guzov, Vladimir and Olszewski, Kyle and Tulyakov, Sergey and Pons-Moll, Gerard},
    booktitle = {Winter Conference on Applications of Computer Vision ({WACV})},
    month = {January},
    year = {2023},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/art/zhou22art.png" alt="Adjoint Rigid Transform Network: Task-conditioned Alignment of 3D Shapes" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Zhou.html">Keyang Zhou</a>,
                                                <a href="/people/Bhatnagar.html">Bharat Lal Bhatnagar</a>,
                                                <span>Bernt Schiele</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Adjoint Rigid Transform Network: Task-conditioned Alignment of 3D Shapes</strong><br/>
                                                                        in <em>2022 International Conference on 3D Vision (3DV)</em>,
                                                                                                                        
            2022.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#zhou2022art"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/zhou22art/art.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2102.01161" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/art/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="zhou2022art"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Adjoint Rigid Transform Network: Task-conditioned Alignment of 3D Shapes</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{zhou2022art,
    title = {Adjoint Rigid Transform Network: Task-conditioned Alignment of 3D Shapes},
    author = {Zhou, Keyang and Bhatnagar, Bharat Lal and Schiele, Bernt and Pons-Moll, Gerard},
    booktitle = {2022 International Conference on 3D Vision (3DV)},
    organization = {IEEE},
    year = {2022},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/img/Xian2022gin.png" alt="Any-Shot GIN: Generalizing Implicit Networks for Reconstructing Novel Classes" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Yongqin Xian</span>,
                                                <a href="/people/Chibane.html">Julian Chibane</a>,
                                                <a href="/people/Bhatnagar.html">Bharat Lal Bhatnagar</a>,
                                                <span>Bernt Schiele</span>,
                                                <span>Zeynep Akata</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Any-Shot GIN: Generalizing Implicit Networks for Reconstructing Novel Classes</strong><br/>
                                                                        in <em>2022 International Conference on 3D Vision (3DV)</em>,
                                                                                                                        
            2022.
            <br/><strong><font color="red">Oral - Best Paper Honourable Mention</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#Xian2022gin"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/gin/GIN.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/gin/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="Xian2022gin"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Any-Shot GIN: Generalizing Implicit Networks for Reconstructing Novel Classes</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{Xian2022gin,
    title = {Any-Shot GIN: Generalizing Implicit Networks for Reconstructing Novel Classes},
    author = {Xian, Yongqin and Chibane, Julian and Bhatnagar, Bharat Lal and Schiele, Bernt and Akata, Zeynep and Pons-Moll, Gerard},
    booktitle = {2022 International Conference on 3D Vision (3DV)},
    organization = {IEEE},
    year = {2022},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/chibane22Box2Mask/teaser.gif" alt="Box2Mask: Weakly Supervised 3D Semantic Instance Segmentation Using Bounding Boxes" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Chibane.html">Julian Chibane</a>,
                                                <span>Francis Engelmann</span>,
                                                <span>Tuan Anh Tran</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Box2Mask: Weakly Supervised 3D Semantic Instance Segmentation Using Bounding Boxes</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV)</em>,
                                                                                                                        
            2022.
            <br/><strong><font color="red">Oral</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#chibane2021box2mask"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/chibane22Box2Mask/Chibane_Box2Mask.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2206.01203" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/box2mask/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="chibane2021box2mask"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Box2Mask: Weakly Supervised 3D Semantic Instance Segmentation Using Bounding Boxes</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{chibane2021box2mask,
    title = {Box2Mask: Weakly Supervised 3D Semantic Instance Segmentation Using Bounding Boxes},
    author = {Chibane, Julian and Engelmann, Francis and Tran, Tuan Anh and Pons-Moll, Gerard},
    booktitle = {European Conference on Computer Vision ({ECCV})},
    month = {October},
    organization = {{Springer}},
    year = {2022},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/xie22chore/teaser_crop.png" alt="CHORE: Contact, Human and Object REconstruction from a single RGB image" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Xianghui Xie</span>,
                                                <a href="/people/Bhatnagar.html">Bharat Lal Bhatnagar</a>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>CHORE: Contact, Human and Object REconstruction from a single RGB image</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV)</em>,
                                                                                                                        
            2022.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#xie22chore"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/xie22chore/chore.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/xie22chore/chore_supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2204.02445" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/chore/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="xie22chore"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">CHORE: Contact, Human and Object REconstruction from a single RGB image</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{xie22chore,
    title = {CHORE: Contact, Human and Object REconstruction from a single RGB image},
    author = {Xie, Xianghui and Bhatnagar, Bharat Lal and Pons-Moll, Gerard},
    booktitle = {European Conference on Computer Vision ({ECCV})},
    month = {October},
    organization = {{Springer}},
    year = {2022},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/couch/couch_teaser.gif" alt="COUCH: Towards Controllable Human-Chair Interactions" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Zhang.html">Xiaohan Zhang</a>,
                                                <a href="/people/Bhatnagar.html">Bharat Lal Bhatnagar</a>,
                                                <span>Sebastian Starke</span>,
                                                <a href="/people/Guzov.html">Vladimir Guzov</a>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>COUCH: Towards Controllable Human-Chair Interactions</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV)</em>,
                                                                                                                        
            2022.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#zhang2022couch"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/couch/zhang2022couch.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2205.00541" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/couch/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="zhang2022couch"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">COUCH: Towards Controllable Human-Chair Interactions</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{zhang2022couch,
    title = {COUCH: Towards Controllable Human-Chair Interactions},
    author = {Zhang, Xiaohan and Bhatnagar, Bharat Lal and Starke, Sebastian and Guzov, Vladimir and Pons-Moll, Gerard},
    booktitle = {European Conference on Computer Vision ({ECCV})},
    month = {October},
    organization = {{Springer}},
    year = {2022},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/corona22lvd/lvd_gif_horizontal.gif" alt="Learned Vertex Descent: A New Direction for 3D Human Model Fitting" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Enric Corona</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Guillem Alenya</span>,
                                                <span>Francesc Moreno-Noguer</span><br/><strong>Learned Vertex Descent: A New Direction for 3D Human Model Fitting</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV)</em>,
                                                                                                                        
            2022.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#coronaLVD"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="https://arxiv.org/pdf/2205.06254.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/pdf/2205.06254" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="coronaLVD"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Learned Vertex Descent: A New Direction for 3D Human Model Fitting</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{coronaLVD,
    title = {Learned Vertex Descent: A New Direction for 3D Human Model Fitting},
    author = {Corona, Enric and Pons-Moll, Gerard and Alenya, Guillem and  Moreno-Noguer,Francesc},
    booktitle = {European Conference on Computer Vision ({ECCV})},
    month = {October},
    organization = {{Springer}},
    year = {2022},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/posendf/teaser.png" alt="Pose-NDF: Modeling Human Pose Manifolds with Neural Distance Fields" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Tiwari.html">Garvita Tiwari</a>,
                                                <span>Dimitrije Antic</span>,
                                                <a href="/people/Lenssen.html">Jan Eric Lenssen</a>,
                                                <span>Nikolaos Sarafianos</span>,
                                                <span>Tony Tung</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Pose-NDF: Modeling Human Pose Manifolds with Neural Distance Fields</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV)</em>,
                                                                                                                        
            2022.
            <br/><strong><font color="red">Oral - Best Paper Honourable Mention</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#tiwari22posendf"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/posendf/posendf_paper.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/posendf/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="tiwari22posendf"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Pose-NDF: Modeling Human Pose Manifolds with Neural Distance Fields</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{tiwari22posendf,
    title = {Pose-NDF: Modeling Human Pose Manifolds with Neural Distance Fields},
    author = {Tiwari, Garvita and Antic, Dimitrije and Lenssen, Jan Eric and Sarafianos, Nikolaos and Tung, Tony and Pons-Moll, Gerard},
    booktitle = {European Conference on Computer Vision ({ECCV})},
    month = {October},
    organization = {{Springer}},
    year = {2022},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/liao2022pose/liao2022pose.png" alt="Skeleton-free Pose Transfer for Stylized 3D Characters" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Zhouyingcheng Liao</span>,
                                                <span>Jimei Yang</span>,
                                                <span>Jun Saito</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Yang Zhou</span><br/><strong>Skeleton-free Pose Transfer for Stylized 3D Characters</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV)</em>,
                                                                                                                        
            2022.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#liao2022pose"><i class="fa fa-quote-right"></i> BibTeX
                    </button></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="liao2022pose"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Skeleton-free Pose Transfer for Stylized 3D Characters</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{liao2022pose,
    title = {Skeleton-free Pose Transfer for Stylized 3D Characters},
    author = {Liao, Zhouyingcheng and Yang, Jimei and Saito, Jun and Pons-Moll, Gerard and Zhou, Yang},
    booktitle = {European Conference on Computer Vision ({ECCV})},
    month = {October},
    organization = {{Springer}},
    year = {2022},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/toch/zhou22toch.gif" alt="TOCH: Spatio-Temporal Object-to-Hand Correspondence for Motion Refinement" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Zhou.html">Keyang Zhou</a>,
                                                <a href="/people/Bhatnagar.html">Bharat Lal Bhatnagar</a>,
                                                <a href="/people/Lenssen.html">Jan Eric Lenssen</a>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>TOCH: Spatio-Temporal Object-to-Hand Correspondence for Motion Refinement</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV)</em>,
                                                                                                                        
            2022.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#zhou2022toch"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/zhou22toch/toch.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2205.07982" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/toch/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="zhou2022toch"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">TOCH: Spatio-Temporal Object-to-Hand Correspondence for Motion Refinement</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{zhou2022toch,
    title = {TOCH: Spatio-Temporal Object-to-Hand Correspondence for Motion Refinement},
    author = {Zhou, Keyang and Bhatnagar, Bharat Lal and Lenssen, Jan Eric and Pons-Moll, Gerard},
    booktitle = {European Conference on Computer Vision ({ECCV})},
    month = {October},
    organization = {{Springer}},
    year = {2022},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/bhatnagar22behave/teaser.png" alt="BEHAVE: Dataset and Method for Tracking Human Object Interactions" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Bhatnagar.html">Bharat Lal Bhatnagar</a>,
                                                <span>Xianghui Xie</span>,
                                                <a href="/people/Petrov.html">Ilya Petrov</a>,
                                                <span>Cristian Sminchisescu</span>,
                                                <span>Christian Theobalt</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>BEHAVE: Dataset and Method for Tracking Human Object Interactions</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2022.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#bhatnagar22behave"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/bhatnagar22behave/behave.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2204.06950" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/behave/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="bhatnagar22behave"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">BEHAVE: Dataset and Method for Tracking Human Object Interactions</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{bhatnagar22behave,
    title = {BEHAVE: Dataset and Method for Tracking Human Object Interactions},
    author = {Bhatnagar, Bharat Lal and  Xie, Xianghui and Petrov, Ilya and Sminchisescu, Cristian and Theobalt, Christian and Pons-Moll, Gerard},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2022},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/guzov22hops/guzov22hops.gif" alt="Visually plausible human-object interaction capture from wearable sensors" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Guzov.html">Vladimir Guzov</a>,
                                                <span>Torsten Sattler</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Visually plausible human-object interaction capture from wearable sensors</strong><br/>
                                                                        in <em>arXiv</em>,
                                                                                                                        
            2022.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#guzov22hops"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/guzov22hops/guzov22hops.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2205.02830" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/hops/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="guzov22hops"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Visually plausible human-object interaction capture from wearable sensors</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{guzov22hops,
    title = {Visually plausible human-object interaction capture from wearable sensors},
    author = {Guzov, Vladimir and Sattler, Torsten and Pons-Moll, Gerard},
    booktitle = {arXiv},
    month = {May},
    year = {2022},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/tiwari21neuralgif/teaser1.png" alt="Neural-GIF: Neural Generalized Implicit Functions for Animating People in Clothing" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Tiwari.html">Garvita Tiwari</a>,
                                                <span>Nikolaos Sarafianos</span>,
                                                <span>Tony Tung</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Neural-GIF: Neural Generalized Implicit Functions for Animating People in Clothing</strong><br/>
                                                                        in <em>International Conference on Computer Vision (ICCV)</em>,
                                                                                                                        
            2021.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#tiwari21neuralgif"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/tiwari21neuralgif/neuralgif.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2108.08807" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/neuralgif/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="tiwari21neuralgif"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Neural-GIF: Neural Generalized Implicit Functions for Animating People in Clothing</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{tiwari21neuralgif,
    title = {Neural-GIF: Neural Generalized Implicit Functions for Animating People in Clothing},
    author = {Tiwari, Garvita and Sarafianos, Nikolaos and Tung, Tony and Pons-Moll, Gerard},
    booktitle = {International Conference on Computer Vision ({ICCV})},
    month = {October},
    year = {2021},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/guzov-mir21HPS/guzov-mir21HPS.gif" alt="Human POSEitioning System (HPS): 3D Human Pose Estimation and Self-localization in Large Scenes from Body-Mounted Sensors " class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Guzov.html">Vladimir Guzov</a>,
                                                <a href="/people/Mir.html">Aymen Mir</a>,
                                                <span>Torsten Sattler</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Human POSEitioning System (HPS): 3D Human Pose Estimation and Self-localization in Large Scenes from Body-Mounted Sensors </strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2021.
            <br/>(First two authors contributed equally) <br><strong><font color="red">Oral, Best paper finalist</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#HPS"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/guzov-mir21HPS/guzov-mir21HPS.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/guzov-mir21HPS/guzov-mir21HPS_supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2103.17265" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/hps/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="HPS"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Human POSEitioning System (HPS): 3D Human Pose Estimation and Self-localization in Large Scenes from Body-Mounted Sensors </span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{HPS,
    title = {Human POSEitioning System (HPS): 3D Human Pose Estimation and Self-localization in Large Scenes from Body-Mounted Sensors },
    author = {Guzov, Vladimir and Mir, Aymen and Sattler, Torsten and Pons-Moll, Gerard},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {jun},
    organization = {{IEEE}},
    year = {2021},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/chibane21SRF/srf_website_teaser.gif" alt="Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes " class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Chibane.html">Julian Chibane</a>,
                                                <span>Aayush Bansal</span>,
                                                <a href="/people/Lazova.html">Verica Lazova</a>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes </strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2021.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#SRF"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/chibane21SRF/chibane21srf.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/chibane21SRF/chibane21srf_supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2104.06935" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/srf/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="SRF"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes </span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{SRF,
    title = {Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes },
    author = {Chibane, Julian and Bansal, Aayush and Lazova, Verica and Pons-Moll, Gerard},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {jun},
    organization = {{IEEE}},
    year = {2021},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/corona21SMPLicit/corona21SMPLicit.png" alt="SMPLicit: Topology-aware Generative Model for Clothed People" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Enric Corona</span>,
                                                <span>Albert Pumarola</span>,
                                                <span>Guillem Alenya</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Francesc Moreno-Noguer</span><br/><strong>SMPLicit: Topology-aware Generative Model for Clothed People</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2021.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#coronaSMPLicit"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/corona21SMPLicit/corona21SMPLicit.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/corona21SMPLicit/corona21SMPLicit.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2103.06871" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="http://www.iri.upc.edu/people/ecorona/smplicit/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="coronaSMPLicit"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">SMPLicit: Topology-aware Generative Model for Clothed People</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{coronaSMPLicit,
    title = {SMPLicit: Topology-aware Generative Model for Clothed People},
    author = {Corona, Enric and Pumarola, Albert and Alenya, Guillem and Pons-Moll, Gerard and Moreno-Noguer, Francesc},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {jun},
    organization = {{IEEE}},
    year = {2021},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/pumarola21dnerf/pumarola21dnerf.gif" alt="D-NeRF: Neural Radiance Fields for Dynamic Scenes" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Albert Pumarola</span>,
                                                <span>Enric Corona</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Francesc Moreno-Noguer</span><br/><strong>D-NeRF: Neural Radiance Fields for Dynamic Scenes</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2021.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#pumarolaDNERF"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/pumarola21dnerf/pumarola21dnerf.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/pumarola21dnerf/pumarola21dnerf.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2011.13961" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="https://www.albertpumarola.com/research/D-NeRF/index.html" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="pumarolaDNERF"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">D-NeRF: Neural Radiance Fields for Dynamic Scenes</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{pumarolaDNERF,
    title = {D-NeRF: Neural Radiance Fields for Dynamic Scenes},
    author = {Pumarola, Albert and Corona, Enric and Pons-Moll, Gerard and Moreno-Noguer, Francesc},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {jun},
    organization = {{IEEE}},
    year = {2021},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/chibane2020ndf/ndf_video.gif" alt="Neural Unsigned Distance Fields for Implicit Function Learning" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Chibane.html">Julian Chibane</a>,
                                                <a href="/people/Mir.html">Aymen Mir</a>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Neural Unsigned Distance Fields for Implicit Function Learning</strong><br/>
                                                                        in <em>Advances in Neural Information Processing Systems (NeurIPS)</em>,
                                                                                                                        
            2020.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#chibane2020ndf"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/chibane2020ndf/chibane2020ndf.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/chibane2020ndf/chibane2020ndf-supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2010.13938" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/ndf/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="chibane2020ndf"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Neural Unsigned Distance Fields for Implicit Function Learning</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{chibane2020ndf,
    title = {Neural Unsigned Distance Fields for Implicit Function Learning},
    author = {Chibane, Julian and Mir, Aymen and Pons-Moll, Gerard},
    booktitle = {Advances in Neural Information Processing Systems ({NeurIPS})},
    month = {December},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/bhatnagar2020loopreg/bhatnagar2020loopreg.png" alt="LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Bhatnagar.html">Bharat Lal Bhatnagar</a>,
                                                <span>Cristian Sminchisescu</span>,
                                                <span>Christian Theobalt</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration</strong><br/>
                                                                        in <em>Advances in Neural Information Processing Systems (NeurIPS)</em>,
                                                                                                                        
            2020.
            <br/><strong><font color="red">Oral</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#bhatnagar2020loopreg"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/bhatnagar2020loopreg/bhatnagar2020loopreg.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/bhatnagar2020loopreg/bhatnagar2020loopreg_supplementary.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2010.12447" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/loopreg/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="bhatnagar2020loopreg"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{bhatnagar2020loopreg,
    title = {LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration},
    author = {Bhatnagar, Bharat Lal and Sminchisescu, Cristian and Theobalt, Christian and Pons-Moll, Gerard},
    booktitle = {Advances in Neural Information Processing Systems ({NeurIPS})},
    month = {December},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/SelfPose2020/SelfPose2020.png" alt="SelfPose: 3D Egocentric Pose Estimation from a Headset Mounted Camera" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Denis Tome</span>,
                                                <a href="/people/alldieck.html">Thiemo Alldieck</a>,
                                                <span>Patrick Peluse</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Lourdes Agapito</span>,
                                                <span>Hernan Badino</span>,
                                                <span>Fernando de la Torre</span><br/><strong>SelfPose: 3D Egocentric Pose Estimation from a Headset Mounted Camera</strong><br/>
                                                            in <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>,
                                                                                                                                    
            2020.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#SelfPose2020"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9217955" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="SelfPose2020"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">SelfPose: 3D Egocentric Pose Estimation from a Headset Mounted Camera</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@article{SelfPose2020,
    title = {SelfPose: 3D Egocentric Pose Estimation from a Headset Mounted Camera},
    author = {Tome, Denis and Alldieck, Thiemo and Peluse, Patrick and Pons-Moll, Gerard and Agapito, Lourdes and Badino, Hernan and de la Torre, Fernando},
    journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
    month = {Oct},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/jchibane20ifnet/sharp_thumbnail.png" alt="Implicit Feature Networks for Texture Completion from Partial 3D Data" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Chibane.html">Julian Chibane</a>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Implicit Feature Networks for Texture Completion from Partial 3D Data</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV), Workshops</em>,
                                                                                                                        
            2020.
            <br/><strong><font color="red">1st Place Winner in all Categories of SHARP Challange</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#chibane2020ifnet_texture"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/jchibane20ifnet/SHARP2020.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2009.09458" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/ifnets/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="chibane2020ifnet_texture"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Implicit Feature Networks for Texture Completion from Partial 3D Data</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{chibane2020ifnet_texture,
    title = {Implicit Feature Networks for Texture Completion from Partial 3D Data},
    author = {Chibane, Julian and Pons-Moll, Gerard},
    booktitle = {European Conference on Computer Vision ({ECCV}), Workshops},
    month = {August},
    organization = {{Springer}},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"></div><div class="media-body align-self-center"><span>Hosnieh Sattar</span>,
                                                <span>Katharina Kromholz</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Mario Fritz</span><br/><strong>Body Shape Privacy in Images: Understanding Privacy and Preventing Automatic Shape Extraction</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV), Workshops</em>,
                                                                                                                        
            2020.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#sattar2020privacy"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="https://arxiv.org/abs/1905.11503" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="sattar2020privacy"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Body Shape Privacy in Images: Understanding Privacy and Preventing Automatic Shape Extraction</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{sattar2020privacy,
    title = {Body Shape Privacy in Images: Understanding Privacy and Preventing Automatic Shape Extraction},
    author = {Sattar, Hosnieh and Kromholz, Katharina and Pons-Moll, Gerard and Fritz, Mario},
    booktitle = {European Conference on Computer Vision ({ECCV}), Workshops},
    month = {August},
    organization = {{Springer}},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/NASA20/NASA.png" alt="NASA: Neural Articulated Shape Approximation" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Boyang Deng</span>,
                                                <span>JP Lewis</span>,
                                                <span>Timothy Jeruzalski</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Geoffrey Hinton</span>,
                                                <span>Mohammad Norouzi</span>,
                                                <span>Andrea Tagliasacchi</span><br/><strong>NASA: Neural Articulated Shape Approximation</strong><br/>
                                                                        in <em>The European Conference on Computer Vision (ECCV)</em>,
                                                                                                                        
            2020.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#deng2019neural"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/NASA20/NASA.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/1912.03207" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/nasa/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="deng2019neural"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">NASA: Neural Articulated Shape Approximation</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{deng2019neural,
    title = {NASA: Neural Articulated Shape Approximation},
    author = {Deng, Boyang and Lewis, JP and Jeruzalski, Timothy and Pons-Moll, Gerard and Hinton, Geoffrey and Norouzi, Mohammad and Tagliasacchi, Andrea},
    booktitle = {The European Conference on Computer Vision (ECCV)},
    month = {August},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/tiwari20sizer/teaser_final.jpg" alt="SIZER: A Dataset and Model for Parsing 3D Clothing and Learning Size Sensitive 3D Clothing" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Tiwari.html">Garvita Tiwari</a>,
                                                <a href="/people/Bhatnagar.html">Bharat Lal Bhatnagar</a>,
                                                <span>Tony Tung</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>SIZER: A Dataset and Model for Parsing 3D Clothing and Learning Size Sensitive 3D Clothing</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV)</em>,
                                                                                                                        
            2020.
            <br/><strong><font color="red">Oral</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#tiwari20sizer"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/tiwari20sizer/sizer.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/tiwari20sizer/sizer-supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2007.11610" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/sizer/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="tiwari20sizer"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">SIZER: A Dataset and Model for Parsing 3D Clothing and Learning Size Sensitive 3D Clothing</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{tiwari20sizer,
    title = {SIZER: A Dataset and Model for Parsing 3D Clothing and Learning Size Sensitive 3D Clothing},
    author = {Tiwari, Garvita and Bhatnagar, Bharat Lal and Tung, Tony and Pons-Moll, Gerard},
    booktitle = {European Conference on Computer Vision ({ECCV})},
    month = {August},
    organization = {{Springer}},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/bhatnagar2020ipnet/bhatnagar2020ipnet.png" alt="Combining Implicit Function Learning and Parametric Models for 3D Human Reconstruction" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Bhatnagar.html">Bharat Lal Bhatnagar</a>,
                                                <span>Cristian Sminchisescu</span>,
                                                <span>Christian Theobalt</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Combining Implicit Function Learning and Parametric Models for 3D Human Reconstruction</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV)</em>,
                                                                                                                        
            2020.
            <br/><strong><font color="red">Oral</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#bhatnagar2020ipnet"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/bhatnagar2020ipnet/bhatnagar2020ipnet.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/bhatnagar2020ipnet/bhatnagar2020ipnet-supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2007.11432" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/ipnet/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="bhatnagar2020ipnet"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Combining Implicit Function Learning and Parametric Models for 3D Human Reconstruction</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{bhatnagar2020ipnet,
    title = {Combining Implicit Function Learning and Parametric Models for 3D Human Reconstruction},
    author = {Bhatnagar, Bharat Lal and Sminchisescu, Cristian and Theobalt, Christian and Pons-Moll, Gerard},
    booktitle = {European Conference on Computer Vision ({ECCV})},
    month = {August},
    organization = {{Springer}},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/kzhou20unsupervised/teaser.png" alt="Unsupervised Shape and Pose Disentanglement for 3D Meshes" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Zhou.html">Keyang Zhou</a>,
                                                <a href="/people/Bhatnagar.html">Bharat Lal Bhatnagar</a>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Unsupervised Shape and Pose Disentanglement for 3D Meshes</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV)</em>,
                                                                                                                        
            2020.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#zhou20unsupervised"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/kzhou20unsupervised/paper.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/kzhou20unsupervised/supplemental.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2007.11341" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/unsup_shape_pose/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="zhou20unsupervised"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Unsupervised Shape and Pose Disentanglement for 3D Meshes</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{zhou20unsupervised,
    title = {Unsupervised Shape and Pose Disentanglement for 3D Meshes},
    author = {Zhou, Keyang and Bhatnagar, Bharat Lal and Pons-Moll, Gerard},
    booktitle = {European Conference on Computer Vision (ECCV)},
    month = {August},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/brazilECCV20/brazilECCV20.png" alt="Kinematic 3D Object Detection in Monocular Video" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Garrick Brazil</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Xiaoming Liu</span>,
                                                <span>Bernt Schiele</span><br/><strong>Kinematic 3D Object Detection in Monocular Video</strong><br/>
                                                                        in <em>The European Conference on Computer Vision (ECCV)</em>,
                                                                                                                        
            2020.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#Brazil20Kinematic"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/brazilECCV20/brazilECCV20.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/brazilECCV20/brazilECCV20-supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="Brazil20Kinematic"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Kinematic 3D Object Detection in Monocular Video</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{Brazil20Kinematic,
    title = {Kinematic 3D Object Detection in Monocular Video},
    author = {Brazil, Garrick and Pons-Moll, Gerard and Liu, Xiaoming and Schiele, Bernt},
    booktitle = {The European Conference on Computer Vision (ECCV)},
    month = {August},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/Mehta20XNect/XNect_teaser.jpg" alt="XNect: Real-time Multi-Person 3D Motion Capture with a Single RGB Camera" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Dushyant Mehta</span>,
                                                <span>Oleksandr Sotnychenko</span>,
                                                <span>Franziska Mueller</span>,
                                                <span>Weipeng Xu</span>,
                                                <span>Mohamed Elgharib</span>,
                                                <span>Pascal Fua</span>,
                                                <span>Hans-Peter Seidel</span>,
                                                <span>Helge Rhodin</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Christian Theobalt</span><br/><strong>XNect: Real-time Multi-Person 3D Motion Capture with a Single RGB Camera</strong><br/>
                                                            in <em>ACM Transactions on Graphics, (Proc. SIGGRAPH)</em>,
                 vol. 39,                  no. 4,                                                                                                     
            2020.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#XNect_SIGGRAPH2020"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/Mehta20XNect/XNect_SIGGRAPH2020.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/Mehta20XNect/XNect_supp_SIGGRAPH2020.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="http://gvv.mpi-inf.mpg.de/projects/XNect/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="XNect_SIGGRAPH2020"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">XNect: Real-time Multi-Person 3D Motion Capture with a Single RGB Camera</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@article{XNect_SIGGRAPH2020,
    title = {{XNect}: Real-time Multi-Person {3D} Motion Capture with a Single {RGB} Camera},
    author = {Mehta, Dushyant and Sotnychenko, Oleksandr and Mueller, Franziska and Xu, Weipeng and Elgharib, Mohamed and Fua, Pascal and Seidel, Hans-Peter and Rhodin, Helge and Pons-Moll, Gerard and Theobalt, Christian},
    journal = {ACM Transactions on Graphics, (Proc. SIGGRAPH)},
    month = {July},
    number = {4},
    volume = {39},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/chibane20ifnet/chibane20ifnet.png" alt="Implicit Functions in Feature Space for 3D Shape Reconstruction and Completion" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Chibane.html">Julian Chibane</a>,
                                                <a href="/people/alldieck.html">Thiemo Alldieck</a>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Implicit Functions in Feature Space for 3D Shape Reconstruction and Completion</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2020.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#chibane20ifnet"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/chibane20ifnet/chibane20ifnet.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/chibane20ifnet/chibane20ifnet_supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2003.01456" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/ifnets/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="chibane20ifnet"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Implicit Functions in Feature Space for 3D Shape Reconstruction and Completion</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{chibane20ifnet,
    title = {Implicit Functions in Feature Space for 3D Shape Reconstruction and Completion},
    author = {Chibane, Julian and Alldieck, Thiemo and Pons-Moll, Gerard},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {jun},
    organization = {{IEEE}},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/patel20tailornet/patel20tailornet.png" alt="TailorNet: Predicting Clothing in 3D as a Function of Human Pose, Shape and Garment Style" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Chaitanya Patel</span>,
                                                <span>Zhouyingcheng Liao</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>TailorNet: Predicting Clothing in 3D as a Function of Human Pose, Shape and Garment Style</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2020.
            <br/><strong><font color="red">Oral</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#patel20tailornet"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/patel20tailornet/patel20tailornet.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/patel20tailornet/patel20tailornet_supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2003.04583" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/tailornet/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="patel20tailornet"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">TailorNet: Predicting Clothing in 3D as a Function of Human Pose, Shape and Garment Style</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{patel20tailornet,
    title = {TailorNet: Predicting Clothing in 3D as a Function of Human Pose, Shape and Garment Style},
    author = {Patel, Chaitanya and Liao, Zhouyingcheng and Pons-Moll, Gerard},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {jun},
    organization = {{IEEE}},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/mir20pix2surf/mir20pix2surf.jpg" alt="Learning to Transfer Texture from Clothing Images to 3D Humans" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Mir.html">Aymen Mir</a>,
                                                <a href="/people/alldieck.html">Thiemo Alldieck</a>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Learning to Transfer Texture from Clothing Images to 3D Humans</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2020.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#mir20pix2surf"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/mir20pix2surf/mir20pix2surf.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/mir20pix2surf/mir20pix2surf_supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/2003.02050" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/pix2surf/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="mir20pix2surf"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Learning to Transfer Texture from Clothing Images to 3D Humans</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{mir20pix2surf,
    title = {Learning to Transfer Texture from Clothing Images to 3D Humans},
    author = {Mir, Aymen and Alldieck, Thiemo and Pons-Moll, Gerard},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    organization = {{IEEE}},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ma20autoenclother/ma20autoenclother.png" alt="Learning to Dress 3D People in Generative Clothing" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Qianli Ma</span>,
                                                <span>Jinlong Yang</span>,
                                                <span>Anurag Ranjan</span>,
                                                <span>Sergi Pujades</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Siyu Tang</span>,
                                                <span>Michael Black</span><br/><strong>Learning to Dress 3D People in Generative Clothing</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2020.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#ma20autoenclother"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="https://arxiv.org/abs/1907.13615" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="ma20autoenclother"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Learning to Dress 3D People in Generative Clothing</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{ma20autoenclother,
    title = {Learning to Dress 3D People in Generative Clothing},
    author = {Ma, Qianli and Yang, Jinlong and Ranjan, Anurag and Pujades, Sergi and Pons-Moll, Gerard and Tang, Siyu and Black, Michael},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {jun},
    organization = {{IEEE}},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/habermann20deepcap/habermann20deepcap.png" alt="DeepCap: Monocular Human Performance Capture Using Weak Supervision" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Marc Habermann</span>,
                                                <span>Weipeng Xu</span>,
                                                <span>Michael and Zollhoefer</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Christian Theobalt</span><br/><strong>DeepCap: Monocular Human Performance Capture Using Weak Supervision</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2020.
            <br/><strong><font color="red">Oral - Best Student Paper Honorable Mention</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#habermann20deepcap"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/habermann20deepcap/habermann20deepcap.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/habermann20deepcap/habermann20deepcap_supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://people.mpi-inf.mpg.de/~mhaberma/projects/2020-cvpr-deepcap/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="habermann20deepcap"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">DeepCap: Monocular Human Performance Capture Using Weak Supervision</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{habermann20deepcap,
    title = {DeepCap: Monocular Human Performance Capture Using Weak Supervision},
    author = {Habermann, Marc and Xu, Weipeng and and Zollhoefer, Michael and Pons-Moll, Gerard and Theobalt, Christian},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {jun},
    organization = {{IEEE}},
    year = {2020},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/bhatnagar2019mgn/bhatnagar2019mgn.png" alt="Multi-Garment Net: Learning to Dress 3D People from Images" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Bhatnagar.html">Bharat Lal Bhatnagar</a>,
                                                <a href="/people/Tiwari.html">Garvita Tiwari</a>,
                                                <span>Christian Theobalt</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Multi-Garment Net: Learning to Dress 3D People from Images</strong><br/>
                                                                        in <em>IEEE International Conference on Computer Vision (ICCV)</em>,
                                                                                                                        
            2019.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#bhatnagar2019mgn"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/bhatnagar2019mgn/bhatnagar2019mgn.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/bhatnagar2019mgn/bhatnagar2019mgn_supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/1908.06903" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/mgn/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="bhatnagar2019mgn"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Multi-Garment Net: Learning to Dress 3D People from Images</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{bhatnagar2019mgn,
    title = {Multi-Garment Net: Learning to Dress 3D People from Images},
    author = {Bhatnagar, Bharat Lal and Tiwari, Garvita and Theobalt, Christian and Pons-Moll, Gerard},
    booktitle = {{IEEE} International Conference on Computer Vision ({ICCV})},
    month = {oct},
    organization = {{IEEE}},
    year = {2019},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/alldieck2019tex2shape/alldieck2019tex2shape.png" alt="Tex2Shape: Detailed Full Human Body Geometry from a Single Image" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/alldieck.html">Thiemo Alldieck</a>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Christian Theobalt</span>,
                                                <span>Marcus Magnor</span><br/><strong>Tex2Shape: Detailed Full Human Body Geometry from a Single Image</strong><br/>
                                                                        in <em>IEEE International Conference on Computer Vision (ICCV)</em>,
                                                                                                                        
            2019.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#alldieck2019tex2shape"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/alldieck2019tex2shape/alldieck2019tex2shape.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/alldieck2019tex2shape/alldieck2019tex2shape_suppl.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/1904.08645" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/tex2shape/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="alldieck2019tex2shape"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Tex2Shape: Detailed Full Human Body Geometry from a Single Image</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{alldieck2019tex2shape,
    title = {Tex2Shape: Detailed Full Human Body Geometry from a Single Image},
    author = {Alldieck, Thiemo and Pons-Moll, Gerard and Theobalt, Christian and Magnor, Marcus},
    booktitle = {{IEEE} International Conference on Computer Vision ({ICCV})},
    month = {oct},
    organization = {{IEEE}},
    year = {2019},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/mahmood2019amass/mahmood2019amass.png" alt="AMASS: Archive of Motion Capture as Surface Shapes" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Naureen Mahmood</span>,
                                                <span>Nima Ghorbani</span>,
                                                <span>Nikolaus F. Troje</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Michael J. Black</span><br/><strong>AMASS: Archive of Motion Capture as Surface Shapes</strong><br/>
                                                                        in <em>IEEE International Conference on Computer Vision (ICCV)</em>,
                                                                                                                        
            2019.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#mahmood2019amass"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="https://arxiv.org/abs/1904.03278" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="mahmood2019amass"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">AMASS: Archive of Motion Capture as Surface Shapes</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{mahmood2019amass,
    title = {AMASS: Archive of Motion Capture as Surface Shapes},
    author = {Mahmood, Naureen and Ghorbani, Nima and Troje, Nikolaus F. and Pons-Moll, Gerard and Black, Michael J.},
    booktitle = {{IEEE} International Conference on Computer Vision ({ICCV})},
    month = {oct},
    organization = {{IEEE}},
    year = {2019},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/lazova3dv2019/lazova3dv2019.gif" alt="360-Degree Textures of People in Clothing from a Single Image" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Lazova.html">Verica Lazova</a>,
                                                <span>Eldar Insafutdinov</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>360-Degree Textures of People in Clothing from a Single Image</strong><br/>
                                                                        in <em>International Conference on 3D Vision (3DV)</em>,
                                                                                                                        
            2019.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#lazova3dv2019"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/lazova3dv2019/lazova3dv2019.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/lazova3dv2019/lazova3dv2019-supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/1908.07117" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="/360tex/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="lazova3dv2019"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">360-Degree Textures of People in Clothing from a Single Image</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{lazova3dv2019,
    title = {360-Degree Textures of People in Clothing from a Single Image},
    author = {Lazova, Verica and Insafutdinov, Eldar and Pons-Moll, Gerard},
    booktitle = {International Conference on 3D Vision (3DV)},
    month = {sep},
    year = {2019},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/DoubleFusion2018/DoubleFusion2018.jpg" alt="DoubleFusion: Real-time Capture of Human Performance with Inner Body Shape from a Depth Sensor" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Tao Yu</span>,
                                                <span>Jianhui Zhao</span>,
                                                <span>Zhang Zerong</span>,
                                                <span>Kaiwen Guo</span>,
                                                <span>Dai Quionhai</span>,
                                                <span>Hao Li</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Yebin Liu</span><br/><strong>DoubleFusion: Real-time Capture of Human Performance with Inner Body Shape from a Depth Sensor</strong><br/>
                                                            in <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>,
                                                                                                                                    
            2019.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#DoubleFusionPAMI_2019"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/YuPAMI2019/YuPAMI2019.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=23LMfj2soNQ" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a><a role="button" class="btn btn-light" href="http://www.liuyebin.com/doublefusion/doublefusion.htm" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="DoubleFusionPAMI_2019"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">DoubleFusion: Real-time Capture of Human Performance with Inner Body Shape from a Depth Sensor</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@article{DoubleFusionPAMI_2019,
    title = {DoubleFusion: Real-time Capture of Human Performance with Inner Body Shape from a Depth Sensor},
    author = {Yu, Tao and Zhao, Jianhui and Zerong, Zhang and Guo, Kaiwen and Quionhai, Dai and Li, Hao and Pons-Moll, Gerard and Liu, Yebin},
    journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
    month = {july},
    year = {2019},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/habermann2019TOG/habermann2019TOG.png" alt="LiveCap: Real-time Human Performance Capture from Monocular Video" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Marc Habermann</span>,
                                                <span>Weipeng Xu</span>,
                                                <span>Michael and Zollhoefer</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Christian Theobalt</span><br/><strong>LiveCap: Real-time Human Performance Capture from Monocular Video</strong><br/>
                                                            in <em>ACM Transactions on Graphics, (Proc. SIGGRAPH)</em>,
                                                                                                                                    
            2019.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#habermann2019TOG"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/habermann2019TOG/habermann2019TOG.mp4" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/1810.02648" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="https://gvv.mpi-inf.mpg.de/projects/LiveCap/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="habermann2019TOG"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">LiveCap: Real-time Human Performance Capture from Monocular Video</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@article{habermann2019TOG,
    title = {LiveCap: Real-time Human Performance Capture from Monocular Video},
    author = {Habermann, Marc and Xu, Weipeng and and Zollhoefer, Michael and Pons-Moll, Gerard and Theobalt, Christian},
    journal = {ACM Transactions on Graphics, (Proc. SIGGRAPH)},
    month = {jul},
    year = {2019},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/habibieCVPR2019/habibieCVPR19.png" alt="In the Wild Human Pose Estimation using Explicit 2D Features and Intermediate 3D Representations" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Ikhsanul Habibie</span>,
                                                <span>Weipeng Xu</span>,
                                                <span>Dushyant Mehta</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Christian Theobalt</span><br/><strong>In the Wild Human Pose Estimation using Explicit 2D Features and Intermediate 3D Representations</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2019.
            <br/><strong><font color="red">Oral</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#habibieCVPR19"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="https://arxiv.org/abs/1810.02648" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="https://people.mpi-inf.mpg.de/~ihabibie/projects/2019-cvpr-lifting-projection/index.htm" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="habibieCVPR19"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">In the Wild Human Pose Estimation using Explicit 2D Features and Intermediate 3D Representations</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{habibieCVPR19,
    title = {In the Wild Human Pose Estimation using Explicit 2D Features and Intermediate 3D Representations},
    author = {Habibie, Ikhsanul and Xu, Weipeng and Mehta, Dushyant and Pons-Moll, Gerard and Theobalt, Christian},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2019},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/alldieck19cvpr/alldieck19cvpr.png" alt="Learning to Reconstruct People in Clothing from a Single RGB Camera" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/alldieck.html">Thiemo Alldieck</a>,
                                                <span>Marcus Magnor</span>,
                                                <a href="/people/Bhatnagar.html">Bharat Lal Bhatnagar</a>,
                                                <span>Christian Theobalt</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Learning to Reconstruct People in Clothing from a Single RGB Camera</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2019.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#alldieck19cvpr"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/alldieck19cvpr/alldieck19cvpr.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=_wuEru4WeDw" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a><a role="button" class="btn btn-light" href="/octopus/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="alldieck19cvpr"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Learning to Reconstruct People in Clothing from a Single RGB Camera</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{alldieck19cvpr,
    title = {Learning to Reconstruct People in Clothing from a Single {RGB} Camera},
    author = {Alldieck, Thiemo and Magnor, Marcus and Bhatnagar, Bharat Lal and Theobalt, Christian and Pons-Moll, Gerard},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {jun},
    year = {2019},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/SimulCap19/SimulCap19.png" alt="SimulCap : Single-View Human Performance Capture with Cloth Simulation" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Tao Yu</span>,
                                                <span>Zerong Zheng</span>,
                                                <span>Yuan Zhong</span>,
                                                <span>Jianhui Zhao</span>,
                                                <span>Dai Quionhai</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Yebin Liu</span><br/><strong>SimulCap : Single-View Human Performance Capture with Cloth Simulation</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2019.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#SimulCap19"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/SimulCap19/SimulCap19.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=rTdz3saGKsQ&amp;t=1s" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="SimulCap19"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">SimulCap : Single-View Human Performance Capture with Cloth Simulation</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{SimulCap19,
    title = {SimulCap : Single-View Human Performance Capture with Cloth Simulation},
    author = {Yu, Tao and Zheng, Zerong and Zhong, Yuan and Zhao, Jianhui and Quionhai, Dai and Pons-Moll, Gerard and Liu, Yebin},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {jun},
    year = {2019},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/sattar2019WACV/sattar2019WACV.png" alt="Fashion is Taking Shape: Understanding Clothing Preference Based on Body Shape From Online Sources" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Hosnieh Sattar</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Mario Fritz</span><br/><strong>Fashion is Taking Shape: Understanding Clothing Preference Based on Body Shape From Online Sources</strong><br/>
                                                                        in <em>IEEE Winter Conference on Applications of Computer Vision (WACV 2019)</em>,
                                                                                                                        
            2019.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#sattar19wacv"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/sattar2019WACV/sattar2019WACV.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/computer-vision-and-fashion/fashion-is-taking-shape-understanding-clothing-preference-based-on-body-shape-from-online-sources/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="sattar19wacv"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Fashion is Taking Shape: Understanding Clothing Preference Based on Body Shape From Online Sources</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{sattar19wacv,
    title = {Fashion is Taking Shape: {U}nderstanding Clothing Preference Based on Body Shape From Online Sources},
    author = {Sattar, Hosnieh and Pons-Moll, Gerard and Fritz, Mario},
    address = {Waikoloa Village, HI, USA},
    booktitle = {IEEE Winter Conference on Applications of Computer Vision (WACV 2019)},
    month = {jan},
    year = {2019},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/DIPSiggraphAsia18/DIP_teaser.png" alt="Deep Inertial Poser: Learning to Reconstruct Human Pose from Sparse Inertial Measurements in Real Time" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Yinghao Huang</span>,
                                                <span>Manuel Kaufmann</span>,
                                                <span>Emre Aksan</span>,
                                                <span>Michael J. Black</span>,
                                                <span>Otmar Hilliges</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Deep Inertial Poser: Learning to Reconstruct Human Pose from Sparse Inertial Measurements in Real Time</strong><br/>
                                                            in <em>ACM Transactions on Graphics, (Proc. SIGGRAPH Asia)</em>,
                 vol. 37,                  no. 6,                                                                                                     185:1-185:15
            2018.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#DIPSIGGRAPHAsia2018"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/DIPSiggraphAsia18/DIP.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=p1fmpOWA504" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a><a role="button" class="btn btn-light" href="http://dip.is.tuebingen.mpg.de/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="DIPSIGGRAPHAsia2018"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Deep Inertial Poser: Learning to Reconstruct Human Pose from Sparse Inertial Measurements in Real Time</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@article{DIP:SIGGRAPHAsia:2018,
    title = {Deep Inertial Poser: Learning to Reconstruct Human Pose from Sparse Inertial Measurements in Real Time},
    author = {Huang, Yinghao and Kaufmann, Manuel and Aksan, Emre and Black, Michael J. and Hilliges, Otmar and Pons-Moll, Gerard},
    journal = {ACM Transactions on Graphics, (Proc. SIGGRAPH Asia)},
    month = {nov},
    number = {6},
    pages = {185:1--185:15},
    volume = {37},
    year = {2018},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/habermann2018GCPR/habermann2018GCPR.png" alt="NRST: Non-rigid Surface Tracking from Monocular Video" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Marc Habermann</span>,
                                                <span>Weipeng Xu</span>,
                                                <span>Helge Rohdin</span>,
                                                <span>Michael Zollhoefer</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Christian Theobalt</span><br/><strong>NRST: Non-rigid Surface Tracking from Monocular Video</strong><br/>
                                                                        in <em>German Conference on Pattern Recognition (GCPR)</em>,
                                                                                                                        
            2018.
            <br/><strong><font color="red">Oral</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#habermann2018GCPR"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/habermann2018GCPR/habermann2018GCPR.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/habermann2018GCPR/habermann2018GCPR.mp4" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a><a role="button" class="btn btn-light" href="https://people.mpi-inf.mpg.de/~mhaberma/projects/2018-gcpr-nrst/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="habermann2018GCPR"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">NRST: Non-rigid Surface Tracking from Monocular Video</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{habermann2018GCPR,
    title = {NRST: Non-rigid Surface Tracking from Monocular Video},
    author = {Habermann, Marc and Xu, Weipeng and Rohdin, Helge and Zollhoefer, Michael and Pons-Moll, Gerard and Theobalt, Christian},
    booktitle = {German Conference on Pattern Recognition (GCPR)},
    month = {oct},
    year = {2018},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/alldieck2018detailed/alldieck2018detailed.jpg" alt="Detailed Human Avatars from Monocular Video" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/alldieck.html">Thiemo Alldieck</a>,
                                                <span>Marcus Magnor</span>,
                                                <span>Weipeng Xu</span>,
                                                <span>Christian Theobalt</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Detailed Human Avatars from Monocular Video</strong><br/>
                                                                        in <em>International Conference on 3D Vision (3DV)</em>,
                                                                                                                        
            2018.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#alldieck20183DV"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/alldieck2018detailed/alldieck2018detailed.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://graphics.tu-bs.de/upload/publications/alldieck2018detailed/detailed_avatars.mp4" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/1808.01338" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="https://github.com/thmoa/semantic_human_texture_stitching" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="alldieck20183DV"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Detailed Human Avatars from Monocular Video</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{alldieck20183DV,
    title = {Detailed Human Avatars from Monocular Video},
    author = {Alldieck, Thiemo and Magnor, Marcus and Xu, Weipeng and Theobalt, Christian and Pons-Moll, Gerard},
    booktitle = {International Conference on 3D Vision (3DV)},
    month = {sep},
    year = {2018},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/omran2018NBF/omran2018NBF.png" alt="Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Mohamed Omran</span>,
                                                <span>Christoph Lassner</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Peter Gehler</span>,
                                                <span>Bernt Schiele</span><br/><strong>Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation</strong><br/>
                                                                        in <em>International Conference on 3D Vision (3DV)</em>,
                                                                                                                        
            2018.
            <br/><strong><font color="red">Oral, 3DV Best Student Paper Award</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#omran2018NBF"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/omran2018NBF/omran2018NBF.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/omran2018NBF/omran2018NBF_supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://github.com/mohomran/neural_body_fitting" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="omran2018NBF"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{omran2018NBF,
    title = {Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose and Shape Estimation},
    author = {Omran, Mohamed and Lassner, Christoph and Pons-Moll, Gerard and Gehler, Peter and Schiele, Bernt},
    booktitle = {International Conference on 3D Vision (3DV)},
    month = {sep},
    year = {2018},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/vonmarcardECCV18/vonmarcardECCV18.png" alt="Recovering Accurate 3D Human Pose in The Wild Using IMUs and a Moving Camera" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Marcard.html">Timo von Marcard</a>,
                                                <span>Roberto Henschel</span>,
                                                <span>Michael Black</span>,
                                                <span>Bodo Rosenhahn</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Recovering Accurate 3D Human Pose in The Wild Using IMUs and a Moving Camera</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV)</em>,
                                                                                                                        
            2018.
            <br/><strong><font color="red">3D Poses in the Wild (3DPW) dataset available to download!</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#vonMarcard2018"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/vonmarcardECCV18/vonmarcardECCV18.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/vonmarcardECCV18/vonmarcardECCV18_supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=6S5TG31SqCY&amp;t=1s" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a><a role="button" class="btn btn-light" href="/3DPW/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="vonMarcard2018"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Recovering Accurate 3D Human Pose in The Wild Using IMUs and a Moving Camera</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{vonMarcard2018,
    title = {Recovering Accurate 3D Human Pose in The Wild Using IMUs and a Moving Camera},
    author = {von Marcard, Timo and Henschel, Roberto and Black, Michael and Rosenhahn, Bodo and Pons-Moll, Gerard},
    booktitle = {European Conference on Computer Vision (ECCV)},
    month = {sep},
    year = {2018},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/mehta2018multiperson/mehta2018multiperson.png" alt="Single-Shot Multi-Person 3D Pose Estimation From Monocular RGB" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Dushyant Mehta</span>,
                                                <span>Oleksandr Sotnychenko</span>,
                                                <span>Franziska Mueller</span>,
                                                <span>Weipeng Xu</span>,
                                                <span>Srinath Sridhar</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Christian Theobalt</span><br/><strong>Single-Shot Multi-Person 3D Pose Estimation From Monocular RGB</strong><br/>
                                                                        in <em>International Conference on 3D Vision (3DV)</em>,
                                                                                                                        
            2018.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#mehta2018multiperson"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/mehta2018multiperson/mehta2018multiperson.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/mehta2018multiperson/mehta2018multiperson_supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="/papers/mehta2018multiperson/mehta2018multiperson.mp4" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="mehta2018multiperson"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Single-Shot Multi-Person 3D Pose Estimation From Monocular RGB</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{mehta2018multiperson,
    title = {Single-Shot Multi-Person 3D Pose Estimation From Monocular RGB},
    author = {Mehta, Dushyant and Sotnychenko, Oleksandr and Mueller, Franziska and Xu, Weipeng and Sridhar, Srinath and Pons-Moll, Gerard and Theobalt, Christian},
    booktitle = {International Conference on 3D Vision (3DV)},
    month = {sep},
    year = {2018},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/DoubleFusion2018/DoubleFusion2018.jpg" alt="DoubleFusion: Real-time Capture of Human Performance with Inner Body Shape from a Depth Sensor" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Tao Yu</span>,
                                                <span>Zerong Zheng</span>,
                                                <span>Kaiwen Guo</span>,
                                                <span>Jianhui Zhao</span>,
                                                <span>Dai Quionhai</span>,
                                                <span>Hao Li</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Yebin Liu</span><br/><strong>DoubleFusion: Real-time Capture of Human Performance with Inner Body Shape from a Depth Sensor</strong><br/>
                                                                        in <em>IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2018.
            <br/><strong><font color="red">Oral</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#DoubleFusion2018"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/DoubleFusion2018/DoubleFusion2018.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=23LMfj2soNQ" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="DoubleFusion2018"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">DoubleFusion: Real-time Capture of Human Performance with Inner Body Shape from a Depth Sensor</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{DoubleFusion2018,
    title = {DoubleFusion: Real-time Capture of Human Performance with Inner Body Shape from a Depth Sensor},
    author = {Yu, Tao and Zheng, Zerong and Guo, Kaiwen and Zhao, Jianhui and Quionhai, Dai and Li, Hao and Pons-Moll, Gerard and Liu, Yebin},
    booktitle = {{IEEE} Conf. on Computer Vision and Pattern Recognition (CVPR)},
    journal = {{IEEE} Conf. on Computer Vision and Pattern Recognition},
    month = {june},
    year = {2018},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/img/alldieck2018video.jpg" alt="Video Based Reconstruction of 3D People Models" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/alldieck.html">Thiemo Alldieck</a>,
                                                <span>Marcus Magnor</span>,
                                                <span>Weipeng Xu</span>,
                                                <span>Christian Theobalt</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Video Based Reconstruction of 3D People Models</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2018.
            <br/><strong><font color="red">Spotlight</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#alldieck2018video"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/alldieck2018video/alldieck2018videoshapes.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="/papers/alldieck2018video/alldieck2018videoshapes_supp.pdf" target="_blank"><i class="fa fa-file"></i> Suppl. Material
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=Htry63oRIjQ&amp;t=8s" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a><a role="button" class="btn btn-light" href="https://arxiv.org/abs/1803.04758" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a><a role="button" class="btn btn-light" href="https://graphics.tu-bs.de/people-snapshot" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="alldieck2018video"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Video Based Reconstruction of 3D People Models</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{alldieck2018video,
    title = {Video Based Reconstruction of 3D People Models},
    author = {Alldieck, Thiemo and Magnor, Marcus and Xu, Weipeng and Theobalt, Christian and Pons-Moll, Gerard},
    booktitle = {{IEEE} Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {June},
    year = {2018},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/mehta2017single/mehta2017single.png" alt="Single-Shot Multi-Person 3D Body Pose Estimation From Monocular RGB Input" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Dushyant Mehta</span>,
                                                <span>Oleksandr Sotnychenko</span>,
                                                <span>Franziska Mueller</span>,
                                                <span>Weipeng Xu</span>,
                                                <span>Srinath Sridhar</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Christian Theobalt</span><br/><strong>Single-Shot Multi-Person 3D Body Pose Estimation From Monocular RGB Input</strong><br/>
                                                            in <em>arXiv preprint arXiv:1712.03453</em>,
                                                                                                                                    
            2018.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#mehta2017single"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="https://arxiv.org/abs/1712.03453" target="_blank"><i class="fa fa-archive"></i> arXiv
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="mehta2017single"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Single-Shot Multi-Person 3D Body Pose Estimation From Monocular RGB Input</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@article{mehta2017single,
    title = {Single-Shot Multi-Person 3D Body Pose Estimation From Monocular RGB Input},
    author = {Mehta, Dushyant and Sotnychenko, Oleksandr and Mueller, Franziska and Xu, Weipeng and Sridhar, Srinath and Pons-Moll, Gerard and Theobalt, Christian},
    journal = {arXiv preprint arXiv:1712.03453},
    month = {january},
    year = {2018},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/GenerativeModelPeople2017/A_Generative_Model_ICCV_2017.jpg" alt="A Generative Model of People in Clothing" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Christoph Lassner</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Peter V. Gehler</span><br/><strong>A Generative Model of People in Clothing</strong><br/>
                                                                        in <em>Proceedings IEEE International Conference on Computer Vision (ICCV)</em>,
                                                 IEEE,                                                                         
            2017.
            <br/><strong><font color="red">Spotlight</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#LassnerGP2017"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="http://files.is.tuebingen.mpg.de/classner/gp/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="LassnerGP2017"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">A Generative Model of People in Clothing</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{Lassner:GP:2017,
    title = {A Generative Model of People in Clothing},
    author = {Lassner, Christoph and Pons-Moll, Gerard and Gehler, Peter V.},
    address = {Piscataway, NJ, USA},
    booktitle = {Proceedings IEEE International Conference on Computer Vision (ICCV)},
    month = {oct},
    publisher = {IEEE},
    year = {2017},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollSIGGRAPH17clothcap/ponsmollSIGGRAPH17clothcap.png" alt="ClothCap: Seamless 4D Clothing Capture and Retargeting" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Sergi Pujades</span>,
                                                <span>Sonny Hu</span>,
                                                <span>Michael Black</span><br/><strong>ClothCap: Seamless 4D Clothing Capture and Retargeting</strong><br/>
                                                            in <em>ACM Transactions on Graphics (SIGGRAPH)</em>,
                 vol. 36,                  no. 4,                                                                                                     
            2017.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#ponsmollSIGGRAPH17clothcap"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/ponsmollSIGGRAPH17clothcap/ponsmollSIGGRAPH17clothcap.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=dVxj8tzx04U" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a><a role="button" class="btn btn-light" href="http://clothcap.is.tue.mpg.de" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="ponsmollSIGGRAPH17clothcap"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">ClothCap: Seamless 4D Clothing Capture and Retargeting</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@article{ponsmollSIGGRAPH17clothcap,
    title = {{ClothCap}: Seamless {4D} Clothing Capture and Retargeting},
    author = {Pons-Moll, Gerard and Pujades, Sergi and Hu, Sonny and Black, Michael},
    journal = {ACM Transactions on Graphics (SIGGRAPH)},
    number = {4},
    volume = {36},
    year = {2017},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/meekyoungSIGGRAPH2017/meekyoungSIGGRAPH2017.png" alt="Data-Driven Physics for Human Soft Tissue Animation" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Meekyoung Kim</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Sergi Pujades</span>,
                                                <span>Seungbae Bang</span>,
                                                <span>Jinwook Kim</span>,
                                                <span>Michael J. Black</span>,
                                                <span>Sung-Hee Lee</span><br/><strong>Data-Driven Physics for Human Soft Tissue Animation</strong><br/>
                                                            in <em>ACM Transactions on Graphics, (Proc. SIGGRAPH)</em>,
                 vol. 36,                  no. 4,                                                                                                     
            2017.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#Meekyoungsiggraph"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/meekyoungSIGGRAPH2017/meekyoungSIGGRAPH2017.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://youtu.be/YySDlC7NZg4" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="Meekyoungsiggraph"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Data-Driven Physics for Human Soft Tissue Animation</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@article{Meekyoung:siggraph,
    title = {Data-Driven Physics for Human Soft Tissue Animation},
    author = {Kim, Meekyoung and Pons-Moll, Gerard and Pujades, Sergi and Bang, Seungbae and Kim, Jinwook and Black, Michael J. and Lee, Sung-Hee},
    journal = {ACM Transactions on Graphics, (Proc. SIGGRAPH)},
    number = {4},
    volume = {36},
    year = {2017},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/shapeunderclothCVPR17/shapeunderclothCVPR17.png" alt="Detailed, accurate, human shape estimation from clothed 3D scan sequences" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Chao Zhang</span>,
                                                <span>Sergi Pujades</span>,
                                                <span>Michael Black</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Detailed, accurate, human shape estimation from clothed 3D scan sequences</strong><br/>
                                                                        in <em>IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2017.
            <br/><strong><font color="red">Spotlight</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#shapeunderclothCVPR17"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/shapeunderclothCVPR17/shapeunderclothCVPR17.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=QOFR77-U30g" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a><a role="button" class="btn btn-light" href="http://buff.is.tue.mpg.de" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="shapeunderclothCVPR17"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Detailed, accurate, human shape estimation from clothed 3D scan sequences</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{shapeundercloth:CVPR17,
    title = {Detailed, accurate, human shape estimation from clothed {3D} scan sequences},
    author = {Zhang, Chao and Pujades, Sergi and Black, Michael and Pons-Moll, Gerard},
    booktitle = {{IEEE} Conf. on Computer Vision and Pattern Recognition (CVPR)},
    year = {2017},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/DFAUST2017/DFAUST2017.png" alt="Dynamic FAUST: Registering Human Bodies in Motion" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Federica Bogo</span>,
                                                <span>Javier Romero</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Michael J. Black</span><br/><strong>Dynamic FAUST: Registering Human Bodies in Motion</strong><br/>
                                                                        in <em>IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2017.
            <br/><strong><font color="red">Oral</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#dfaustCVPR2017"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/DFAUST2017/DFAUST2017.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=6T9FSC2bQDA" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a><a role="button" class="btn btn-light" href="http://dfaust.is.tue.mpg.de" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="dfaustCVPR2017"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Dynamic FAUST: Registering Human Bodies in Motion</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{dfaust:CVPR:2017,
    title = {Dynamic {FAUST}: Registering Human Bodies in Motion},
    author = {Bogo, Federica and Romero, Javier and Pons-Moll, Gerard and Black, Michael J.},
    booktitle = {{IEEE} Conf. on Computer Vision and Pattern Recognition (CVPR)},
    year = {2017},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/SIP2017/SIP2017.png" alt="Sparse Inertial Poser: Automatic 3D Human Pose Estimation from Sparse IMUs" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Marcard.html">Timo von Marcard</a>,
                                                <span>Bodo Rosenhahn</span>,
                                                <span>Michael Black</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Sparse Inertial Poser: Automatic 3D Human Pose Estimation from Sparse IMUs</strong><br/>
                                                            in <em>Computer Graphics Forum 36(2), Proceedings of the 38th Annual Conference of the European Association for Computer Graphics (Eurographics)</em>,
                                                                                                                                    349-360 
            2017.
            <br/><strong><font color="red">Best Paper Award</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#SIP2017"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/SIP2017/SIP2017.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=3x9dimY7o-o&amp;feature=youtu.be" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="SIP2017"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Sparse Inertial Poser: Automatic 3D Human Pose Estimation from Sparse IMUs</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@article{SIP2017,
    title = {Sparse Inertial Poser: Automatic 3D Human Pose Estimation from Sparse IMUs},
    author = {von Marcard, Timo and Rosenhahn, Bodo and Black, Michael and Pons-Moll, Gerard},
    journal = {Computer Graphics Forum 36(2), Proceedings of the 38th Annual Conference of the European Association for Computer Graphics (Eurographics)},
    pages = {349--360 },
    year = {2017},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/vonmarcardponsmollPAMI16/vonmarcardponsmollPAMI16.png" alt="Human Pose Estimation from Video and IMUs" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/Marcard.html">Timo von Marcard</a>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Bodo Rosenhahn</span><br/><strong>Human Pose Estimation from Video and IMUs</strong><br/>
                                                            in <em>Transactions on Pattern Analysis and Machine Intelligence (PAMI)</em>,
                                                                                                                                    
            2016.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#vonmarcardponsmollPAMI16"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/vonmarcardponsmollPAMI16/vonmarcardponsmollPAMI16.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="http://www.tnt.uni-hannover.de/project/TNT15/" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="vonmarcardponsmollPAMI16"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Human Pose Estimation from Video and IMUs</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@article{vonmarcardponsmollPAMI16,
    title = {Human Pose Estimation from Video and IMUs},
    author = {von Marcard, Timo and Pons-Moll, Gerard and Rosenhahn, Bodo},
    journal = {Transactions on Pattern Analysis and Machine Intelligence (PAMI)},
    month = {jan},
    year = {2016},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/SMPL15/SMPL15.jpg" alt="SMPL: A Skinned Multi-Person Linear Model" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Matthew Loper</span>,
                                                <span>Naureen Mahmood</span>,
                                                <span>Javier Romero</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Michael J. Black</span><br/><strong>SMPL: A Skinned Multi-Person Linear Model</strong><br/>
                                                            in <em>ACM Trans. Graphics (Proc. SIGGRAPH Asia)</em>,
                 vol. 34,                  no. 6,                  ACM,                                                                                     248:1-248:16
            2015.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#SMPL2015"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/SMPL15/SMPL15.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=kuBlUyHeV5U" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a><a role="button" class="btn btn-light" href="http://smpl.is.tue.mpg.de" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="SMPL2015"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">SMPL: A Skinned Multi-Person Linear Model</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@article{SMPL:2015,
    title = {{SMPL}: A Skinned Multi-Person Linear Model},
    author = {Loper, Matthew and Mahmood, Naureen and Romero, Javier and Pons-Moll, Gerard and Black, Michael J.},
    address = {New York, NY},
    journal = {ACM Trans. Graphics (Proc. SIGGRAPH Asia)},
    month = {oct},
    number = {6},
    pages = {248:1--248:16},
    publisher = {ACM},
    volume = {34},
    year = {2015},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollSIGGRAPH15Dyna/ponsmollSIGGRAPH15Dyna.png" alt="Dyna: A Model of Dynamic Human Shape in Motion" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Javier Romero</span>,
                                                <span>Naureen Mahmood</span>,
                                                <span>Michael J. Black</span><br/><strong>Dyna: A Model of Dynamic Human Shape in Motion</strong><br/>
                                                            in <em>ACM Transactions on Graphics, (Proc. SIGGRAPH)</em>,
                 vol. 34,                  no. 4,                  ACM,                                                                                     120:1-120:14
            2015.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#ponsmollSIGGRAPH15Dyna"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/ponsmollSIGGRAPH15Dyna/ponsmollSIGGRAPH15Dyna.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://youtu.be/mWthea2K8-Q" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a><a role="button" class="btn btn-light" href="http://dyna.is.tue.mpg.de" target="_blank"><i class="fa fa-code"></i> Code/Data
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="ponsmollSIGGRAPH15Dyna"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Dyna: A Model of Dynamic Human Shape in Motion</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@article{ponsmollSIGGRAPH15Dyna,
    title = {Dyna: A Model of Dynamic Human Shape in Motion},
    author = {Pons-Moll, Gerard and Romero, Javier and Mahmood, Naureen and Black, Michael J.},
    journal = {ACM Transactions on Graphics, (Proc. SIGGRAPH)},
    month = {aug},
    number = {4},
    pages = {120:1--120:14},
    publisher = {ACM},
    volume = {34},
    year = {2015},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollMRFIJCV15/ponsmollMRFIJCV15.png" alt="Metric Regression Forests for Correspondence Estimation" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Jonathan Taylor</span>,
                                                <span>Jamie Shotton</span>,
                                                <span>Aaron Hertzmann</span>,
                                                <span>Andrew Fitzgibbon</span><br/><strong>Metric Regression Forests for Correspondence Estimation</strong><br/>
                                                            in <em>International Journal of Computer Vision (IJCV)</em>,
                                                                                                                                    1-13
            2015.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#PonsMoll_MRFIJCV"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/ponsmollMRFIJCV15/ponsmollMRFIJCV15.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="PonsMoll_MRFIJCV"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Metric Regression Forests for Correspondence Estimation</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@article{Pons-Moll_MRFIJCV,
    title = {Metric Regression Forests for Correspondence Estimation},
    author = {Pons-Moll, Gerard and Taylor, Jonathan and Shotton, Jamie and Hertzmann, Aaron and Fitzgibbon, Andrew},
    journal = {International Journal of Computer Vision (IJCV)},
    pages = {1-13},
    year = {2015},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollDissertation14/ponsmollDissertation14.png" alt="Human Pose Estimation from Video and Inertial Sensors" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a><br/><strong>Human Pose Estimation from Video and Inertial Sensors</strong><br/>
                                                                                                PhD thesis,                                                
            2014.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#PonsMoll_dissertation"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/ponsmollDissertation14/ponsmollDissertation14.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="PonsMoll_dissertation"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Human Pose Estimation from Video and Inertial Sensors</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@phdthesis{Pons-Moll_dissertation,
    title = {Human Pose Estimation from Video and Inertial Sensors},
    author = {Pons-Moll, Gerard},
    booktitle = {Ph.D Thesis},
    publisher = {-},
    year = {2014},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollCVPR14posebits/ponsmollCVPR14posebits.png" alt="Posebits for Monocular Human Pose Estimation" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>David J. Fleet</span>,
                                                <span>Bodo Rosenhahn</span><br/><strong>Posebits for Monocular Human Pose Estimation</strong><br/>
                                                                        in <em> Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        2345-2352
            2014.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#ponsmollCVPR14posebits"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/ponsmollCVPR14posebits/ponsmollCVPR14posebits.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="ponsmollCVPR14posebits"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Posebits for Monocular Human Pose Estimation</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{ponsmollCVPR14posebits,
    title = {Posebits for Monocular Human Pose Estimation},
    author = {Pons-Moll, Gerard and Fleet, David J. and Rosenhahn, Bodo},
    address = {Columbus, Ohio, USA},
    booktitle = { Proceedings IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)},
    month = {jun},
    pages = {2345--2352},
    year = {2014},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollMetricForests13/ponsmollMetricForests13.png" alt="Metric Regression Forests for Human Pose Estimation" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Jonathan Taylor</span>,
                                                <span>Jamie Shotton</span>,
                                                <span>Aaron Hertzmann</span>,
                                                <span>Andrew Fitzgibbon</span><br/><strong>Metric Regression Forests for Human Pose Estimation</strong><br/>
                                                                        in <em>British Machine Vision Conference (BMVC)</em>,
                                                 BMVA Press,                                                                         
            2013.
            <br/><strong><font color="red">Best Paper Award</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#ponsmolMetricForests13"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/ponsmollMetricForests13/ponsmollMetricForests13.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="ponsmolMetricForests13"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Metric Regression Forests for Human Pose Estimation</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{ponsmolMetricForests13,
    title = {Metric Regression Forests for Human Pose Estimation},
    author = {Pons-Moll, Gerard and Taylor, Jonathan and Shotton, Jamie and Hertzmann, Aaron and Fitzgibbon, Andrew},
    booktitle = {British Machine Vision Conference (BMVC)},
    month = {sep},
    publisher = {BMVA Press},
    year = {2013},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/kuznetsovaPonsmollGCPR2011/kuznetsovaPonsmollGCPR2011.png" alt="PCA-enhanced stochastic optimization methods" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Alina Kuznetsova</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Bodo Rosenhahn</span><br/><strong>PCA-enhanced stochastic optimization methods</strong><br/>
                                                                        in <em>German Conference on Pattern Recognition (GCPR)</em>,
                                                                                                                        
            2012.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#kuznetsovaPonsmollGCPR2011"><i class="fa fa-quote-right"></i> BibTeX
                    </button></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="kuznetsovaPonsmollGCPR2011"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">PCA-enhanced stochastic optimization methods</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{kuznetsovaPonsmollGCPR2011,
    title = {PCA-enhanced stochastic optimization methods},
    author = {Kuznetsova, Alina and Pons-Moll, Gerard and Rosenhahn, Bodo},
    booktitle = {German Conference on Pattern Recognition (GCPR)},
    month = {aug},
    year = {2012},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/lealPonsmollCVPR2012/lealPonsmollCVPR2012.png" alt="Branch-and-price global optimization for multi-view multi-object tracking" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Laura Leal-Taixe</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Bodo Rosenhahn</span><br/><strong>Branch-and-price global optimization for multi-view multi-object tracking</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2012.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#lealPonsmollCVPR2012"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/lealPonsmollCVPR2012/lealPonsmollCVPR2012.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=639bh3jVOVU&amp;t=48s" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="lealPonsmollCVPR2012"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Branch-and-price global optimization for multi-view multi-object tracking</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{lealPonsmollCVPR2012,
    title = {Branch-and-price global optimization for multi-view multi-object tracking},
    author = {Leal-Taixe, Laura and Pons-Moll, Gerard and Rosenhahn, Bodo},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {jun},
    year = {2012},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollLealDagstuhl2011/ponsmollLealDagstuhl2011.png" alt="Data-driven Manifolds for Outdoor Motion Capture" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Laura Leal-Taixe</span>,
                                                <span>Juergen Gall</span>,
                                                <span>B. Rosenhahn</span><br/><strong>Data-driven Manifolds for Outdoor Motion Capture</strong><br/>
                                                in  <i>Outdoor and Large-Scale Real-World Scene Analysis</i>,
                 Springer,                                                                                                                 305-328
            2012.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#ponsmollLealDagstuhl2011"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/ponsmollLealDagstuhl2011/ponsmollLealDagstuhl2011.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="ponsmollLealDagstuhl2011"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Data-driven Manifolds for Outdoor Motion Capture</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@incollection{ponsmollLealDagstuhl2011,
    title = {Data-driven Manifolds for Outdoor Motion Capture},
    author = {Pons-Moll, Gerard and Leal-Taixe, Laura and Gall, Juergen and Rosenhahn, B.},
    booktitle = {Outdoor and Large-Scale Real-World Scene Analysis},
    pages = {305-328},
    publisher = {Springer},
    series = {LNCS},
    volume = {7474},
    year = {2012},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/lealPonsmollDagstuhl2011/lealPonsmollDagstuhl2011.png" alt="Exploiting pedestrian interaction via global optimization and social behaviors" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Laura Leal-Taixe</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Bodo Rosenhahn</span><br/><strong>Exploiting pedestrian interaction via global optimization and social behaviors</strong><br/>
                                                in  <i>Theoretic Foundations of Computer Vision: Outdoor and Large-Scale Real-World Scene Analysis</i>,
                 Springer,                                                                                                                 
            2012.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#lealPonsmollDagstuhl2011"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/lealPonsmollDagstuhl2011/lealPonsmollDagstuhl2011.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="lealPonsmollDagstuhl2011"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Exploiting pedestrian interaction via global optimization and social behaviors</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@incollection{lealPonsmollDagstuhl2011,
    title = {Exploiting pedestrian interaction via global optimization and social behaviors},
    author = {Leal-Taixe, Laura and Pons-Moll, Gerard and Rosenhahn, Bodo},
    booktitle = {Theoretic Foundations of Computer Vision: Outdoor and Large-Scale Real-World Scene Analysis},
    month = {apr},
    publisher = {Springer},
    year = {2012},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/lealPonsmollICCVW2011/lealPonsmollICCVW2011.png" alt="Everybody needs somebody: modeling social and grouping behavior on a linear programming multiple people tracker" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Laura Leal-Taixe</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Bodo Rosenhahn</span><br/><strong>Everybody needs somebody: modeling social and grouping behavior on a linear programming multiple people tracker</strong><br/>
                                                                        in <em>IEEE International Conference on Computer Vision Workshops (IICCVW)</em>,
                                                                                                                        
            2011.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#lealPonsmollICCVW2011"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/lealPonsmollICCVW2011/lealPonsmollICCVW2011.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=1DP3soJVOck" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="lealPonsmollICCVW2011"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Everybody needs somebody: modeling social and grouping behavior on a linear programming multiple people tracker</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{lealPonsmollICCVW2011,
    title = {Everybody needs somebody: modeling social and grouping behavior on a linear programming multiple people tracker},
    author = {Leal-Taixe, Laura and Gerard Pons-Moll and Bodo Rosenhahn},
    booktitle = {IEEE International Conference on Computer Vision Workshops (IICCVW)},
    month = {nov},
    year = {2011},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollModelBased/ponsmollModelBased.png" alt="Model-Based Pose Estimation" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Bodo Rosenhahn</span><br/><strong>Model-Based Pose Estimation</strong><br/>
                                                                                                                    139-170
            2011.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#ponsmollModelBased"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/ponsmollModelBased/ponsmollModelBased.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="ponsmollModelBased"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Model-Based Pose Estimation</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inbook{ponsmollModelBased,
    title = {Model-Based Pose Estimation},
    author = {Pons-Moll, Gerard and Rosenhahn, Bodo},
    booktitle = {Visual Analysis of Humans: Looking at People},
    chapter = {9},
    pages = {139-170},
    publisher = {Springer},
    year = {2011},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollICCV2011/ponsmollICCV2011.png" alt="Outdoor Human Motion Capture using Inverse Kinematics and von Mises-Fisher Sampling" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Andreas Baak</span>,
                                                <span>Juergen Gall</span>,
                                                <span>Laura Leal-Taixe</span>,
                                                <span>Meinard Mueller</span>,
                                                <span>Hans-Peter Seidel</span>,
                                                <span>Bodo Rosenhahn</span><br/><strong>Outdoor Human Motion Capture using Inverse Kinematics and von Mises-Fisher Sampling</strong><br/>
                                                                        in <em>IEEE International Conference on Computer Vision (ICCV)</em>,
                                                                                                                        1243-1250
            2011.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#ponsmollICCV2011"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/ponsmollICCV2011/ponsmollICCV2011.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=9NjH7dNMbuM" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="ponsmollICCV2011"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Outdoor Human Motion Capture using Inverse Kinematics and von Mises-Fisher Sampling</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{ponsmollICCV2011,
    title = {Outdoor Human Motion Capture using Inverse Kinematics and von Mises-Fisher Sampling},
    author = {Pons-Moll, Gerard and Baak, Andreas and Gall, Juergen and Leal-Taixe, Laura and Mueller, Meinard and Seidel, Hans-Peter and Rosenhahn, Bodo},
    booktitle = {IEEE International Conference on Computer Vision (ICCV)},
    month = {nov},
    pages = {1243--1250},
    year = {2011},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollGCPR2011/ponsmollGCPR2011.png" alt="Efficient and Robust Shape Matching for Model Based Human Motion Capture " class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Laura Leal-Taixe</span>,
                                                <span>Tri Truong</span>,
                                                <span>Bodo Rosenhahn</span><br/><strong>Efficient and Robust Shape Matching for Model Based Human Motion Capture </strong><br/>
                                                                        in <em>German Conference on Pattern Recognition (GCPR)</em>,
                                                                                                                        416-425
            2011.
            <br/><strong><font color="red">Oral</font></strong><div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#ponsmollGCPR2011"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/ponsmollGCPR2011/ponsmollGCPR2011.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=65H5L4X86is&amp;t=7s" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="ponsmollGCPR2011"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Efficient and Robust Shape Matching for Model Based Human Motion Capture </span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{ponsmollGCPR2011,
    title = {Efficient and Robust Shape Matching for Model Based Human Motion Capture },
    author = {Pons-Moll, Gerard and Leal-Taixe, Laura and Truong, Tri and Rosenhahn, Bodo},
    booktitle = {German Conference on Pattern Recognition (GCPR)},
    month = {sep},
    pages = {416--425},
    year = {2011},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/baakAnalysis2010/baakAnalysis2010.png" alt="Analyzing and Evaluating Markerless Motion Tracking Using Inertial Sensors" class="img-thumbnail"></span></div><div class="media-body align-self-center"><span>Andreas Baak</span>,
                                                <span>Thomas Helten</span>,
                                                <span>Meinard MÃ¼ller</span>,
                                                <a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Bodo Rosenhahn</span>,
                                                <span>Hans-Peter Seidel</span><br/><strong>Analyzing and Evaluating Markerless Motion Tracking Using Inertial Sensors</strong><br/>
                                                                        in <em>European Conference on Computer Vision (ECCV Workshops)</em>,
                                                                                                                        
            2010.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#BaakAnalysis2010"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/baakAnalysis2010/baakAnalysis2010.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=solJzP7pbzA&amp;t=1s" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="BaakAnalysis2010"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Analyzing and Evaluating Markerless Motion Tracking Using Inertial Sensors</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{BaakAnalysis2010,
    title = {Analyzing and Evaluating Markerless Motion Tracking Using Inertial Sensors},
    author = {Baak, Andreas and Helten, Thomas and M{\&quot;u}ller, Meinard and Pons-Moll, Gerard and Rosenhahn, Bodo and Seidel, Hans-Peter},
    booktitle = {European Conference on Computer Vision (ECCV Workshops)},
    month = {sep},
    year = {2010},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollCVPR2010/ponsmollCVPR2010.png" alt="Multisensor-Fusion for 3D Full-Body Human Motion Capture" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Andreas Baak</span>,
                                                <span>Thomas Helten</span>,
                                                <span>Meinard MÃ¼ller</span>,
                                                <span>Hans-Peter Seidel</span>,
                                                <span>Bodo Rosenhahn</span><br/><strong>Multisensor-Fusion for 3D Full-Body Human Motion Capture</strong><br/>
                                                                        in <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
                                                                                                                        
            2010.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#ponsmollCVPR2010"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/ponsmollCVPR2010/ponsmollCVPR2010.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a><a role="button" class="btn btn-light" href="https://www.youtube.com/watch?v=QBXP7Ahar0Q&amp;t=26s" target="_blank"><i class="fa fa-video-camera"></i> Video
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="ponsmollCVPR2010"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Multisensor-Fusion for 3D Full-Body Human Motion Capture</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{ponsmollCVPR2010,
    title = {Multisensor-Fusion for 3D Full-Body Human Motion Capture},
    author = {Pons-Moll, Gerard and Baak, Andreas and Helten, Thomas and M{\&quot;u}ller, Meinard and Seidel, Hans-Peter and Rosenhahn, Bodo},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
    month = {jun},
    year = {2010},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollWACV2009/ponsmollWACV2009.png" alt="Ball Joints for Marker-less Human Motion Capture" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Bodo Rosenhahn</span><br/><strong>Ball Joints for Marker-less Human Motion Capture</strong><br/>
                                                                        in <em>IEEE Workshop on Applications of Computer Vision (WACV)</em>,
                                                                                                                        
            2009.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#ponsmollWACV2009"><i class="fa fa-quote-right"></i> BibTeX
                    </button><a role="button" class="btn btn-light" href="/papers/ponsmollWACV2009/ponsmollWACV2009.pdf" target="_blank"><i class="fa fa-file-pdf-o"></i> PDF
                        </a></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="ponsmollWACV2009"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Ball Joints for Marker-less Human Motion Capture</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{ponsmollWACV2009,
    title = {Ball Joints for Marker-less Human Motion Capture},
    author = {Pons-Moll, Gerard and Rosenhahn, Bodo},
    booktitle = {IEEE Workshop on Applications of Computer Vision (WACV)},
    month = {dec},
    year = {2009},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollWC2009/ponsmollWC2009.png" alt="4D Cardiac Segmentation of the Epicardium and Left Ventricle" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Gilead Tadmor</span>,
                                                <span>Rob S. MacLeod</span>,
                                                <span>Bodo Rosenhahn</span>,
                                                <span>Dana H. Brooks</span><br/><strong>4D Cardiac Segmentation of the Epicardium and Left Ventricle</strong><br/>
                                                                        in <em> World Congress of Medical Physics and Biomedical Engineering (WC)</em>,
                                                                                                                        
            2009.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#ponsmollWC2009"><i class="fa fa-quote-right"></i> BibTeX
                    </button></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="ponsmollWC2009"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">4D Cardiac Segmentation of the Epicardium and Left Ventricle</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{ponsmollWC2009,
    title = {4D Cardiac Segmentation of the Epicardium and Left Ventricle},
    author = {Pons-Moll, Gerard and Tadmor, Gilead and MacLeod, Rob S. and Rosenhahn, Bodo and Brooks, Dana H.},
    booktitle = { World Congress of Medical Physics and Biomedical Engineering (WC)},
    month = {sep},
    year = {2009},
}
</pre></div></div></div></div><div class="media mb-5"><div class="pub-img mr-3"><span class="thumbnail"><img src="/papers/ponsmollCINC2009/ponsmollCINC2009.png" alt="Parametric Modeling of the Beating Heart with Respiratory Motion Extracted from Magnetic Resonance Images" class="img-thumbnail"></span></div><div class="media-body align-self-center"><a href="/people/pons-moll.html">Gerard Pons-Moll</a>,
                                                <span>Cano Crosas</span>,
                                                <span>Gilead Tadmor</span>,
                                                <span>Rob MacLeod</span>,
                                                <span>Bodo Rosenhahn</span>,
                                                <span>Dana Brooks</span><br/><strong>Parametric Modeling of the Beating Heart with Respiratory Motion Extracted from Magnetic Resonance Images</strong><br/>
                                                                        in <em> IEEE Computers in Cardiology (CINC)</em>,
                                                                                                                        
            2009.
                        <div class="mt-2"><div class="btn-group btn-group-sm" role="group"><button type="button" class="btn btn-light" data-toggle="modal" data-target="#ponsmollCINC2009"><i class="fa fa-quote-right"></i> BibTeX
                    </button></div></div></div></div><div class="modal fade bd-example-modal-sm" tabindex="-1" role="dialog" aria-hidden="true" id="ponsmollCINC2009"><div class="modal-dialog modal-lg"><div class="modal-content"><div class="modal-header"><span class="lead modal-title">Parametric Modeling of the Beating Heart with Respiratory Motion Extracted from Magnetic Resonance Images</span><button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button></div><div class="modal-body"><pre>@inproceedings{ponsmollCINC2009,
    title = {Parametric Modeling of the Beating Heart with Respiratory Motion Extracted from Magnetic Resonance Images},
    author = {Pons-Moll, Gerard and Crosas, Cano and Tadmor, Gilead and MacLeod, Rob and Rosenhahn, Bodo and Brooks, Dana},
    booktitle = { IEEE Computers in Cardiology (CINC)},
    month = {sep},
    year = {2009},
}
</pre></div></div></div></div></main><footer class="mt-5 pt-2 pb-3 border-top text-center text-muted"><a href="/contact.html" class="text-muted small">Contact</a> â¢
    <a href="//imprint.mpi-klsb.mpg.de/inf/virtualhumans.mpi-inf.mpg.de" class="text-muted small">Imprint / Impressum</a> â¢
    <a href="//data-protection.mpi-klsb.mpg.de/inf/virtualhumans.mpi-inf.mpg.de" class="text-muted small">Data Protection / Datenschutzhinweis</a></footer><script src="/js/all.js?t=1670676458"></script></body></html>