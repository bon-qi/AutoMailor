<!DOCTYPE html>

<html>
	
	<head><meta http-equiv="Content-Type" content="text/html; charset=utf-8">		
	    <meta http-equiv="cache-control" content="no-cache">
		
		<meta name="viewport" content="width=device-width, initial-scale=1">
        <!-- <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css"> -->
        <!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> -->
        <link rel="stylesheet" href="./css/w3.css">
        <link rel="stylesheet" href="./css/font-awesome.min.css">
		<link rel="stylesheet" type="text/css" href="./css/style.css?rnd=5123">
		<script type="text/javascript" src="./js/main.js"></script>
		<title>Qifeng Chen (é³å¯å³°)</title>
	</head>

	<body>

		<header class="nav-bar color-theme">
			<a href="https://cqf.io">
				<div class="logo color-theme-dark">
					<span>CQF</span>
				</div>
			</a>

			<div class="menu">
				<a href="index.html"><button class="btn-element color-theme-d2">About Me</button></a>
				<a href="publications.html"><button class="btn-element color-theme-d2">Publications</button></a>
				<a href="lab.html"><button class="btn-element color-theme-d2">Lab</button></a>
				<a href="teaching.html"><button class="btn-element color-theme-d2">Teaching</button></a>
				<a href="index.html#others"><button class="btn-element color-theme-d2">Others</button></a>
			</div>


            <div class="logo menu-icon color-theme-l1" onclick="showMenu()">
                <i class="fa">&#9776;</i>
                <ol id="menu_list_container" class="sub-menu color-theme" aria-label="submenu">
                    <li class="menu-item"><a href="index.html">About Me</a></li>
                    <li class="menu-item"><a href="publication.html">Publications</a></li>
                    <li class="menu-item"><a href="lab.html">Lab</a></li>
                    <li class="menu-item"><a href="teaching.html">Teaching</a></li>
                    <li class="menu-item"><a href="index.html#others">Others</a></li>
                </ol>
            </div>
		</header>

		<div class="main-container">
			
			<div id="about_me" class="content-row introduction color-theme-l5">

				<div class="brief-intro">
                    <span>
                        <h3>PUBLICATIONS</h3>
                    </span>
                </div>
<!--https://gohkust-my.sharepoint.com/:p:/g/personal/cqf_ust_hk/EQDo0Gr5GX1Okbiy4j_yLJUBJ-UiK7owdx8fyxr-Nmi9WA?e=t6W44P-->
                <div class="detailed-intro">
                    <h5>Our lab focuses on AI solutions for visual computing and content generation.<br>
					We are also interested in solving visual challenges in autonomous driving.<br>
					<center>
					<ul style="width: 650px;">
					<li>3D AI-Generated Content (AIGC) (<a href="https://gohkust-my.sharepoint.com/:p:/g/personal/cqf_ust_hk/EXAQCYz0KlhBsLuBmEupL2cB_G37NljVfNOm83FeYCgiIg?e=otP8ea">Slides</a>)</li>
					<li>AI based sensing technologies (<a href="https://gohkust-my.sharepoint.com/:p:/g/personal/cqf_ust_hk/ET3ibvUJA6dJoCjt6VdClAIB5HUCbMqEQYUauhL8zbN6xw?e=ZRU6bu">Slides</a>)</li>
					<li>Invertibility in Image Processing and Restoration (<a href="https://gohkust-my.sharepoint.com/:p:/g/personal/cqf_ust_hk/EcFJe5XtoY5Cp51_SFsstuMBjZEqJCC9Y9-Y-gWu0L_xow?e=c5HJ1m">Slides</a>)</li>
					<li>AI for Image Processing and Synthesis (<a href="https://gohkust-my.sharepoint.com/:p:/g/personal/cqf_ust_hk/EVfD3PrIg0hKoGSGy3QWVCcBond_aZXMpV5m4bXli-bVlA?e=UUL8SU">Slides</a>)</li>
					<li>Safety-aware Autonomous Driving (<a href="https://gohkust-my.sharepoint.com/:p:/g/personal/cqf_ust_hk/EXY0lC0pfqNIh7ugdKdAWeUBXLWhJM3dxqr5MDQJy2Sg_w?e=l0VgpI">Slides</a>)</li>
					</ul>
					</center>
					</h5>
                    <h5><a href="technical-report.html">Some technical reports can be found here</a></h5>
                    <h6>* indicates joint first authors</h6>
                </div>
			</div>
            <div id="publication" class="publication color-theme-l1">

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Improving_3D_Image_Synthesis_NeurIPS2022.pdf">Improving 3D-aware Image Synthesis with A Geometry-aware Discriminator</a></p>
                            <p>Zifan Shi, Yinghao Xu, Yujun Shen, Deli Zhao, <b>Qifeng Chen</b>, and Dit-Yan Yeung</p>
                            <p>Conference on Neural Information Processing Systems (NeurIPS), 2022</p>
							<p><a href="https://vivianszf.github.io/geod/">Project Website</a></p>
							<p><a href="https://github.com/vivianszf/geod">Source Code</a></p>
							<p>Spotlight (5.2% acceptance rate)</p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Anifacegan_NeurIPS2022.pdf">AniFaceGAN: Animatable 3D-Aware Face Image Generation for Video Avatars</a></p>
                            <p>Yue Wu, Yu Deng, Jiaolong Yang, Fangyun Wei, <b>Qifeng Chen</b>, and Xin Tong
</p>
                            <p>Conference on Neural Information Processing Systems (NeurIPS), 2022</p>
							<p><a href="https://yuewuhkust.github.io/AniFaceGAN/">Source Code</a></p>
							<p>Spotlight (5.2% acceptance rate)</p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/One_Model_to_Edit_Them_All_NeurIPS2022.pdf">One Model to Edit Them All: Free-Form Text-Driven Image Manipulation with Semantic Modulations
</a></p>
                            <p>Yiming Zhu*, Hongyu Liu*, Yibing Song, Ziyang Yuan, Xintong Han, Chun Yuan, <b>Qifeng Chen</b>, and Jue Wang</p>
                            <p>Conference on Neural Information Processing Systems (NeurIPS), 2022</p>
							<p><a href="https://github.com/KumapowerLIU/FFCLIP">Source Code</a></p>
							<p>Spotlight (5.2% acceptance rate)</p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Planning_for_Sample_Efficient_NeurIPS2022.pdf">Planning for Sample Efficient Imitation Learning</a></p>
                            <p>Zhao-Heng Yin, Weirui Ye, <b>Qifeng Chen</b>, and Yang Gao</p>
                            <p>Conference on Neural Information Processing Systems (NeurIPS), 2022</p>
							<p><a href="https://github.com/zhaohengyin/EfficientImitate">Source Code</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/7DoF_Grasping_CoRL2022.pdf">Volumetric-based Contact Point Detection for 7-DoF Grasping</a></p>
                            <p>Junhao Cai, Jingcheng Su, Zida Zhou, Hui Cheng, <b>Qifeng Chen</b>, and Michael Yu Wang</p>
                            <p>Conference on Robot Learning (CoRL), 2022</p>
							<p><a href="https://github.com/caijunhao/vcpd">Source Code</a></p>
                        </div>
                    </div>


					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="https://arxiv.org/abs/2210.00912">Federated Domain Generalization for Image Recognition via Cross-Client Style Transfer</a></p>
                            <p>Junming Chen, Meirui Jiang, Qi Dou, and <b>Qifeng Chen</b></p>
                            <p>Winter Conference on Applications of Computer Vision (WACV), 2023</p>
							<p><a href="https://github.com/JeremyCJM/CCST">Source Code</a></p>
							<p><a href="https://chenjunming.ml/proj/CCST/">Project Website</a></p>
                        </div>
                    </div>


					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/3D-Aware_Indoor_Scene_Synthesis_ECCV2022.pdf">3D-Aware Indoor Scene Synthesis with Depth Priors</a></p>
                            <p>Zifan Shi, Yujun Shen, Jiapeng Zhu, Dit-Yan Yeung, and <b>Qifeng Chen</b></p>
                            <p>European Conference on Computer Vision (ECCV), 2022</p>
							<p>Full Oral Presentation (acceptance rate 2.7%)</p>
							<p><a href="https://vivianszf.github.io/depthgan/">Project Website</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Real-Time_Neural_Character_Rendering_ECCV2022.pdf">Real-Time Neural Character Rendering with Pose-Guided Multiplane Images</a></p>
                            <p>Hao Ouyang, Bo Zhang, Pan Zhang, Hao Yang, Jiaolong Yang, Dong Chen, <b>Qifeng Chen</b>, and Fang Wen</p>
                            <p>European Conference on Computer Vision (ECCV), 2022</p>
							<p><a href="https://ken-ouyang.github.io/cmpi/index.html">Project Website</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Image_Compression_Denoising_ECCV2022.pdf">Optimizing Image Compression via Joint Learning with Denoising</a></p>
                            <p>Ka Leong Cheng*, Yueqi Xie*, and <b>Qifeng Chen</b></p>
                            <p>European Conference on Computer Vision (ECCV), 2022</p>
							<p><a href="https://github.com/felixcheng97/DenoiseCompression">Source Code</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Point_Cloud_Compression_ECCV2022.pdf">Point Cloud Compression with Sibling Context and Surface Priors</a></p>
                            <p>Zhili Chen, Zian Qian, Sukai Wang, and <b>Qifeng Chen</b></p>
                            <p>European Conference on Computer Vision (ECCV), 2022</p>
							<p><a href="https://github.com/zlichen/PCC-S">Source Code</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/GASN_ECCV2022.pdf">Efficient Point Cloud Segmentation with Geometry-aware Sparse Networks</a></p>
                            <p>Maosheng Ye, Rui Wan, Shuangjie Xu, Tongyi Cao, and <b>Qifeng Chen</b></p>
                            <p>European Conference on Computer Vision (ECCV), 2022</p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Efficient_Video_Denoising_ACMMM2022.pdf">Real-time Streaming Video Denoising with Bidirectional Buffers</a></p>
                            <p>Chenyang Qi*, Junming Chen*, Xin Yang, and <b>Qifeng Chen</b></p>
                            <p>ACM International Conference on Multimedia (ACM MM), 2022</p>
							<p><a href="https://github.com/ChenyangQiQi/BSVD">Source Code</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Composite_Photograph_Harmonization_ACMMM2022.pdf">Composite Photograph Harmonization with Complete Background Cues</a></p>
                            <p>Yazhou Xing, Yu Li, Xintao Wang, Ye Zhu, and <b>Qifeng Chen</b></p>
                            <p>ACM International Conference on Multimedia (ACM MM), 2022</p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Multiscopic_Novel_View_Time_Synthesis_IROS2022.pdf">A Portable Multiscopic Camera for Novel View and Time Synthesis in
Dynamic Scenes</a></p>
                            <p>Tianjia Zhang, Yuen-Fui Lau, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Intelligent Robots and Systems (IROS), 2022</p>
							<p><a href="https://yuenfuilau.github.io/">Project Website</a></p>
                        </div>
                    </div>


					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/ReSeFa_ICML2022.pdf">Region-Based Semantic Factorization in GANs</a></p>
                            <p>Jiapeng Zhu, Yujun Shen, Yinghao Xu, Deli Zhao, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Machine Learning (ICML), 2022</p>
							<p><a href="https://github.com/zhujiapeng/resefa">Source Code</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Optimizing_Video_Prediction_CVPR2022.pdf">Optimizing Video Prediction via Video Frame Interpolation
</a></p>
                            <p>Yue Wu, Qiang Wen, and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2022</p>
							<p><a href="https://yuewuhkust.github.io/OVP_VFI/">Project Website</a></p>
							<p><a href="supplement/Video_Prediction_CVPR2022.mp4">Demo Video</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/SPW_CVPR2022.pdf">Shape from Polarization for Complex Scenes in the Wild
</a></p>
                            <p>Chenyang Lei*, Chenyang Qi*, Jiaxin Xie*, Na Fan, Vladlen Koltun, and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2022</p>
							<p><a href="https://chenyanglei.github.io/sfpwild/index.html">Project Website</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/HFGI_CVPR2022.pdf">High-Fidelity GAN Inversion for Image Attribute Editing</a></p>
                            <p>Tengfei Wang, Yong Zhang, Yanbo Fan, Jue Wang, and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2022</p>
							<p><a href="https://github.com/Tengfei-Wang/HFGI">Project Website</a></p>
                        </div>
                    </div>
					
					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/FS6D_CVPR2022.pdf">FS6D: Few-Shot 6D Pose Estimation of Novel Objects
</a></p>
                            <p>Yisheng He, Yao Wang, Haoqiang Fan, Jian Sun, and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2022</p>
							<p><a href="https://fs6d.github.io/">Project Website</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><font color=red>An initial attempt for invertible image processing</font></p>
							<p><a href="papers/Quasi-Invertible_Network_AAAI2022.pdf">Restorable Image Operators with Quasi-Invertible Networks</a></p>
                            <p>Hao Ouyang*, Tengfei Wang*, and <b>Qifeng Chen</b></p>
                            <p>AAAI Conference on Artificial Intelligence (AAAI), 2022</p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="https://ieeexplore.ieee.org/document/9678082">Deep Video Prior for Video Consistency and Propagation</a></p>
                            <p>Chenyang Lei, Yazhou Xing, Hao Ouyang, and <b>Qifeng Chen</b></p>
                            <p>To Appear in IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</p>
							<p><a href="https://github.com/ChenyangLEI/deep-video-prior">Source Code</a>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="https://arxiv.org/abs/2106.04488">Low-Rank Subspaces in GANs</a></p>
                            <p>
Jiapeng Zhu, Ruili Feng, Yujun Shen, Deli Zhao, Zhengjun Zha, Jingren Zhou, and <b>Qifeng Chen</b></p>
                            <p>Conference on Neural Information Processing Systems (NeurIPS), 2021</p>
							<p><a href="https://github.com/zhujiapeng/LowRankGAN">Source Code</a>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="https://arxiv.org/abs/2103.04027">Learning to Predict Vehicle Trajectories with Model-based Planning</a></p>
                            <p>
Haoran Song, Di Luan, Wenchao Ding, Michael Yu Wang, and <b>Qifeng Chen</b></p>
                            <p>Conference on Robot Learning (CoRL), 2021</p>
							<p><a href="http://song-haoran.com/prime/">Project Website</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Super_Resolution_ICCV2021.pdf">Dual-Camera Super-Resolution with Aligned Attention Modules</a></p>
                            <p>
Tengfei Wang*, Jiaxin Xie*, Wenxiu Sun, Qiong Yan, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Computer Vision (ICCV), 2021</p>
							<p>Full Oral Presentation (3.4% acceptance rate)</p>
							<p><a href="https://tengfei-wang.github.io/Dual-Camera-SR/index.html">Project Website with Code</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Motion_Prediction_Unseen_Vehicles_ICCV2021.pdf">Safety-aware Motion Prediction with Unseen Vehicles for Autonomous Driving</a></p>
                            <p>
Xuanchi Ren*, Tao Yang*, Li Erran Li, Alexandre Alahi, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Computer Vision (ICCV), 2021</p>
							<p><i>Xuanchi is an HKUST undergraduate.</i></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Internal_Video_Inpainting_ICCV2021.pdf">Internal Video Inpainting by Implicit Long-range Propagation</a></p>
                            <p>Hao Ouyang*, Tengfei Wang*, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Computer Vision (ICCV), 2021</p>
							<p><a href="https://tengfei-wang.github.io/Implicit-Internal-Video-Inpainting/index.html">Project Website with Code</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/DRINet_ICCV2021.pdf">DRINet: A Dual-Representation Iterative Learning Network for Point Cloud Segmentation</a></p>
                            <p>Maosheng Ye*, Shuangjie Xu*, Tongyi Cao, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Computer Vision (ICCV), 2021</p>
                        </div>
                    </div>


					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Embedding_Novel_Views_ICCV2021.pdf">Embedding Novel Views in a Single JPEG Image</a></p>
                            <p>Yue Wu*, Guotao Meng*, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Computer Vision (ICCV), 2021</p>
							<p><a href="https://yuewuhkust.github.io/iccv-2021-embedding/">Project Website</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/IICNet_ICCV2021.pdf">IICNet: A Generic Framework for Reversible Image Conversion</a></p>
                            <p>Ka Leong Cheng*, Yueqi Xie*, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Computer Vision (ICCV), 2021</p>
							<p><a href="https://github.com/felixcheng97/IICNet">Source Code</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Normalized_Human_Pose_Features_ICCV2021.pdf">Normalized Human Pose Features for Human Action Video Alignment</a></p>
                            <p>Jingyuan Liu, Mingyi Shi, <b>Qifeng Chen</b>, Hongbo Fu, and Chiew-Lan Tai</p>
                            <p>International Conference on Computer Vision (ICCV), 2021</p>
							<p>Full Oral Presentation (3.4% acceptance rate)</p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Invertible_Image_Compression_ACMMM2021.pdf">Enhanced Invertible Encoding for Learned Image Compression</a></p>
                            <p>Yueqi Xie*, Ka Leong Cheng*, and <b>Qifeng Chen</b></p>
                            <p>ACM International Conference on Multimedia (ACM MM), 2021</p>
							<p>Full Oral Presentation (9% acceptance rate)</p>
							<p><a href="https://github.com/xyq7/InvCompress">Source Code</a></p>
                        </div>
                    </div>


					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><font color="red">Deep Generative Priors with Non-deterministic Degradation</font></p>
							<p><a href="papers/Portrait_Shadow_Removal_ACMMM2021.pdf">Unsupervised Portrait Shadow Removal via Generative Priors</a></p>
                            <p>Yingqing He*, Yazhou Xing*, Tianjia Zhang, and <b>Qifeng Chen</b></p>
                            <p>ACM International Conference on Multimedia (ACM MM), 2021</p>
							<p>Full Oral Presentation (9% acceptance rate)</p>
							<p><a href="https://github.com/yingqinghe/shadow-removal-via-generative-priors">Source Code</a></p>
                        </div>
                    </div>


					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Stereo_Waterdrop_Removal_IROS21.pdf">Stereo Waterdrop Removal with Row-wise Dilated Attention</a></p>
                            <p>Zifan Shi, Na Fan, Dit-Yan Yeung, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Intelligent Robots and Systems (IROS), 2021</p>
							<p><a href="https://github.com/VivianSZF/Stereo-Waterdrop-Removal">Source Code</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/ToF_Depth_Normal_IROS2021.pdf">Joint Depth and Normal Estimation from Real-world Time-of-flight Raw Data</a></p>
                            <p>Rongrong Gao*, Na Fan*, Changlin Li, Wentao Liu, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Intelligent Robots and Systems (IROS), 2021</p>
							<p>Please email Na Fan &lt;nfanaa@connect.ust.hk&gt; for the ToF-100 dataset (for academic purpose only).</p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><a href="papers/Stereo_Matching_Multiscopic_Vision_IROS2021.pdf">Stereo Matching by Self-supervision of Multiscopic Vision</a></p>
                            <p>Weihao Yuan, Yazhan Zhang, Bingkun Wu, Siyu Zhu, Ping Tan, Michael Yu Wang, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Intelligent Robots and Systems (IROS), 2021</p>
                        </div>
                    </div>

					
					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
							<p><font color="red">Efficient internal learning for image manipulation (33x faster than SinGAN)</font></p>
                            <p><a href="papers/SinIR_ICML2021.pdf">SinIR: Efficient General Image Manipulation with Single Image Reconstruction</a></p>
                            <p>Jihyeong Yoo and <b>Qifeng Chen</b></p>
                            <p>International Conference on Machine Learning (ICML), 2021</p>
							<p><a href="papers/SinIR_Supplement_ICML2021.pdf">Supplementary Material</a></p>
							<p><a href="https://github.com/YooJiHyeong/SinIR">Source Code</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Invertible_ISP_CVPR2021.pdf">Invertible Image Signal Processing</a></p>
                            <p>Yazhou Xing*, Zian Qian*, and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2021</p>
							<p><a href="https://yzxing87.github.io/InvISP/index.html">Project Website</a></p>
							<p><a href="https://github.com/yzxing87/Invertible-ISP">Source Code</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Flash_Only_Cures_CVPR2021.pdf">Robust Reflection Removal with Reflection-free Flash-only Cues</a></p>
                            <p>Chenyang Lei and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2021</p>
							<p><a href="https://github.com/ChenyangLEI/flash-reflection-removal">Source Code</a></p>
							<p><a href="https://alexzhao-hugga.github.io/Real-World-Reflection-Removal/">Dataset</a></p>
                        </div>
                    </div>


					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Neural_Camera_Simulators_CVPR2021.pdf">Neural Camera Simulators</a></p>
                            <p>Hao Ouyang*, Zifan Shi*, Chenyang Lei, Ka Lung Law, and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2021</p>
							<p><a href="https://github.com/ken-ouyang/neural_image_simulator">Source Code</a></p>
                        </div>
                    </div>
					
					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/TPCN_CVPR2021.pdf">TPCN: Temporal Point Cloud Networks for Motion Forecasting</a></p>
                            <p>Maosheng Ye, Tongyi Cao, and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2021</p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Image_Inpainting_Monochromic_Bottleneck_CVPR2021.pdf">Image Inpainting with External-internal Learning and Monochromic Bottleneck</a></p>
                            <p>Tengfei Wang*, Hao Ouyang*, and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2021</p>
							<p><a href="https://tengfei-wang.github.io/EII/index.html">Project Website</a></p>
							<p><a href="https://github.com/Tengfei-Wang/external-internal-inpainting">Source Code</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Involution_CVPR2021.pdf">Involution: Inverting the Inherence of Convolution for Visual Recognition</a></p>
                            <p>Duo Li, Jie Hu, Changhu Wang, Xiangtai Li, Qi She, Lei Zhu, Tong Zhang, and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2021</p>
							<p><a href="https://github.com/d-li14/involution">Source Code</a></p>
                        </div>
                    </div>


					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/FFB6D_CVPR2021.pdf">FFB6D: A Full Flow Bidirectional Fusion Network for 6D Pose Estimation</a></p>
                            <p>Yisheng He, Haibin Huang, Haoqiang Fan, <b>Qifeng Chen</b>, and Jian Sun</p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2021</p>
							<p>Full Oral Presentation (4% acceptance rate)</p>
							<p><a href="https://github.com/ethnhe/FFB6D">Source Code</a></p>
                        </div>
                    </div>


                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="https://arxiv.org/abs/2011.07002">Learning to Denoise Astronomical Images with U-nets
</a></p>
                            <p>Antonia Vojtekova, Maggie Lieu, Ivan Valtchanov, Bruno Altieri, Lyndsay Old, <b>Qifeng Chen</b>, Filip Hroch</p>
                            <p>Monthly Notices of the Royal Astronomical Society (MNRAS), 2021</p>
							<p><a href="https://github.com/Sponka/Astro_U-net">Source Code</a></p>
                        </div>
                    </div>

					<div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Deep_Video_Prior_NeurIPS2020.pdf">Blind Video Temporal Consistency via Deep Video Prior</a></p>
                            <p>Chenyang Lei*, Yazhou Xing*, and <b>Qifeng Chen</b></p>
                            <p>Conference on Neural Information Processing Systems (NeurIPS), 2020</p>
							<p><a href="https://youtu.be/07A3aRF4s0g">Demo Video</a></p>
                            <p><a href="https://github.com/ChenyangLEI/deep-video-prior">Source Code</a></p>
							<p><a href="https://chenyanglei.github.io/DVP/index.html">Project Website</a></p>
							<p><a href="supplement/NeurIPS2020_Slides.pptx">Slides</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Self-supervised_Dance_Video_Synthesis_ACMMM2020.pdf">Self-supervised Dance Video Synthesis Conditioned on Music</a></p>
                            <p>Xuanchi Ren, Haoran Li, Zijian Huang, and <b>Qifeng Chen</b></p>
                            <p>ACM International Conference on Multimedia (ACM MM), 2020</p>
                            <p><b>Full Oral Presentation (9% acceptance rate)</b></p>
                            <p><a href="https://youtu.be/UNHv7uOUExU">Demo Video</a>, <a href="https://youtu.be/0rMuFMZa_K4">Demo Video 2</a></p>
                            <p><a href="https://github.com/xrenaa/Music-Dance-Video-Synthesis">Source Code</a></p>
                            <p><i>Xuanchi, Haoran, and Zijian are HKUST undergraduates.</i></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="https://arxiv.org/abs/2102.05257">Robust Federated Learning with Attack-Adaptive Aggregation
</a></p>
                            <p>Ching Pui Wan and <b>Qifeng Chen</b></p>
							<p>arXiv:2102.05257</p>
                            <p>FTL-IJCAI Workshop 2021</p>
							<p>Best Paper Award</p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Planning-informed_Trajectory_Prediction_ECCV2020.pdf">PiP: Planning-informed Trajectory Prediction for Autonomous Driving</a></p>
                            <p>Haoran Song, Wenchao Ding, Yuxuan Chen, Shaojie Shen, Michael Yu Wang, and <b>Qifeng Chen</b></p>
                            <p>European Conference on Computer Vision (ECCV), 2020</p>
                            <p><a href="http://song-haoran.com/planning-informed-prediction/">Project Website</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Scalable_Input_Images_ECCV2020.pdf">Learning to Learn Parameterized Classification Networks for Scalable Input Images</a></p>
                            <p>Duo Li, Anbang Yao, and <b>Qifeng Chen</b></p>
                            <p>European Conference on Computer Vision (ECCV), 2020</p>
                            <p><a href="https://github.com/d-li14/SAN">Source Code</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Poly-Scale_Convolutional_Layer_ECCV2020.pdf">PSConv: Squeezing Feature Pyramid into One Compact Poly-Scale Convolutional Layer</a></p>
                            <p>Duo Li, Anbang Yao, and <b>Qifeng Chen</b></p>
                            <p>European Conference on Computer Vision (ECCV), 2020</p>
                            <p><a href="https://github.com/d-li14/PSConv">Source Code</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Continuous_Sign_Language_Recognition_ECCV2020.pdf">Fully Convolutional Networks for Continuous Sign Language Recognition</a></p>
                            <p>Ka Leong CHENG, Zhaoyang Yang, <b>Qifeng Chen</b>, and Yu-Wing Tai</p>
                            <p>European Conference on Computer Vision (ECCV), 2020</p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Video_Depth_Estimation_IROS2020.pdf">Video Depth Estimation by Fusing Flow-to-Depth Proposals</a></p>
                            <p>Jiaxin Xie, Chenyang Lei, Zhuwen Li, Li Erran Li, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Intelligent Robots and Systems (IROS), 2020</p>
							<p><a href="supplement/Video_Depth_Estimation_IROS2020.mp4">Demo Video</a></p>
							<p><a href="https://jiaxinxie97.github.io/Jiaxin-Xie/FDNet/FDNet">Project Website</a></p>
							<p><a href="https://github.com/jiaxinxie97/Video-depth-estimation">Source Code</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Self-supervised_Object_Tracking_IROS2020.pdf">Self-supervised Object Tracking with Cycle-consistent Siamese Networks</a></p>
                            <p>Weihao Yuan, Michael Yu Wang, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Intelligent Robots and Systems (IROS), 2020</p>
                            <p><a href="https://github.com/weihaosky/CycleSiam">Source Code</a></p>
                        </div>
                    </div>
                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Depth_Sensing_Beyond_LiDAR_Range_CVPR2020.pdf">Depth Sensing Beyond LiDAR Range</a></p>
                            <p>Kai Zhang, Jiaxin Xie, Noah Snavely, and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2020</p>
                            <p><a href="https://kai-46.github.io/DepthSensing/">Project website</a></p>
                            <p><a href="https://github.com/Kai-46/DepthSensingBeyondLiDARRange">Source Code</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Polarized_Reflection_Removal_CVPR2020.pdf">Polarized Reflection Removal with Perfect Alignment in the Wild</a></p>
                            <p>Chenyang Lei, Xuhua Huang, Mengdi Zhang, Qiong Yan, Wenxiu Sun, and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2020</p>
                            <p><a href="https://leichenyang.weebly.com/project-polarized.html">Project website</a></p>
							<p><a href="https://github.com/ChenyangLEI/CVPR2020-Polarized-Reflection-Removal-with-Perfect-Alignment">Source Code</a></p>
							<p><a href="https://alexzhao-hugga.github.io/Real-World-Reflection-Removal/">Dataset</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Future_Video_Synthesis_With_Object_Motion_Prediction_CVPR2020.pdf">Future Video Synthesis with Object Motion Prediction</a></p>
                            <p>Yue Wu, Rongrong Gao, Jaesik Park, and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2020</p>
							<p><a href="supplement/Video_Prediction_CVPR2020.mp4">Demo Video</a></p>
                            <!--<p><a href="https://youtu.be/3zGXWuMLQ5o">YouTube link (compressed video)</a></p>-->
                            <p><a href="papers/Future_Video_Synthesis_Supplement_CVPR2020.pdf">Supplementary Material</a></p>
							<p><a href="https://github.com/YueWuHKUST/FutureVideoSynthesis">Source Code</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="https://arxiv.org/pdf/1912.11464.pdf">Attack-Resistant Federated Learning with Residual-based Reweighting</a></p>
                            <p>Shuhao Fu, Chulin Xie, Bo Li, and <b>Qifeng Chen</b></p>
                            <p>AAAI 2021 Workshop</p>
                            <p><a href="https://github.com/fushuhao6/Attack-Resistant-Federated-Learning">Source Code</a></p>
                        </div>
                    </div>
                    
                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/MFuseNet_ICRA2020.pdf">MFuseNet: Robust Depth Estimation with Learned Multiscopic Fusion</a></p>
                            <p>Weihao Yuan, Rui Fan, Michael Yu Wang, and <b>Qifeng Chen</b></p>
                            <p> International Conference on Robotics and Automation (ICRA), 2020</p>
                            <p>IEEE Robotics and Automation Letters, 2020</p>
                            <p><a href="https://sites.google.com/view/multiscopic">Project Website</a></p>
                            <p><a href="supplement/MFuseNet_ICRA2020.mp4">Demo Video</a></p>
                            <p><a href="https://github.com/weihaosky/MFuseNet">Source Code</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Hiding_Video_In_Audio_ICCV2019.pdf">Hiding Video in Audio via Reversible Generative Models</a></p>
                            <p>Hyukyrul Yang*, Hao Ouyang*, Vladlen Koltun, and <b>Qifeng Chen</b></p>
                            <p>International Conference on Computer Vision (ICCV), 2019</p>
							<p><a href="ppt/stegnography.pptx">Slides</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><font color="red">High-quality video reconstruction from raw sensor data.</font></p>
                            <p><a href="papers/Seeing_Motion_In_The_Dark_ICCV2019.pdf">Seeing Motion in the Dark</a></p>
                            <p>Chen Chen, <b>Qifeng Chen</b>, Minh Do, and Vladlen Koltun</p>
                            <p>International Conference on Computer Vision (ICCV), 2019</p>
                            <p>Full Oral Presentation (4.3% acceptance rate)</p>
                            <p><a href="https://www.youtube.com/watch?v=YeaHVrPLSro">Demo Video</a></p>
                            <p><a href="https://github.com/cchen156/Seeing-Motion-in-the-Dark">Source Code</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><font color="red">The first dedicated video colorization method without any user input.</font></p>
                            <p><a href="papers/Fully_Automatic_Video_Colorization_CVPR2019.pdf">Fully Automatic Video Colorization with Self-Regularization and Diversity</a></p>
                            <p>Chenyang Lei and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2019</p>
                            <p><a href="https://leichenyang.weebly.com/project-color.html">Project Website</a></p>
                            <p><a href="https://www.youtube.com/watch?v=Y15uv2jnK-4">Demo Video</a></p>
                            <!--<a href="supplement/Fully_Automatic_Video_Colorization_CVPR2019.mp4">Supplemantary Video</a>-->
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><font color="red">A novel loss (CoBi) for slightly misalighned image-to-image translation.</font></p>
                            <p><a href="papers/Zoom_To_Learn_CVPR2019.pdf">Zoom to Learn, Learn to Zoom</a></p>
                            <p>Xuaner Zhang, <b>Qifeng Chen,</b> Ren Ng, and Vladlen Koltun</p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2019</p>
                            <p><a href="https://ceciliavision.github.io/project-pages/project-zoom.html">Project Website</a></p>
                            <p><a href="papers/Zoom_To_Learn_Supplement_CVPR2019.pdf">Supplement</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/RGBD_Future_Prediction_CVPR2019.pdf">3D Motion Decomposition for RGBD Future Dynamic Scene Synthesis</a></p>
                            <p>Xiaojuan Qi*, Zhengzhe Liu*, <b>Qifeng Chen,</b> and  Jiaya Jia</p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2019</p>
                            <p><a href="supplement/Video_Prediction_CVPR2019.mp4">Supplementary Video</a></p>
                            <p><i>Send an email to Xiaojuan or me for the source code.</i></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="https://arxiv.org/pdf/1810.10659.pdf">Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search</a></p>
                            <p>Zhuwen Li, <b>Qifeng Chen,</b> and Vladlen Koltun</p>
                            <p>Conference on Neural Information Processing Systems (NeurIPS), 2018</p>
                            <p><a href="https://github.com/IntelVCL/NPHard">Source code</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/SIMS_CVPR2018.pdf">Semi-parametric Image Synthesis</a></p>
                            <p>Xiaojuan Qi, <b>Qifeng Chen,</b> Jiaya Jia, and Vladlen Koltun</p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2018</p>
                            <p><b>Full Oral Presentation (2.1% acceptance rate)</b></p>
                            <p><a href="https://github.com/xjqicuhk/SIMS">Code and data</a></p>
                            <p><a href="https://youtu.be/U4Q98lenGLQ">Demo Video</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Interactive_Image_Segmentation_CVPR2018.pdf">Interactive Image Segmentation with Latent Diversity</a></p>
                            <p>Zhuwen Li, <b>Qifeng Chen,</b> and Vladlen Koltun</p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2018</p>
                            <p><a href="https://github.com/IntelVCL/Intseg">Source code</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Reflection_Separation_CVPR2018.pdf">Single Image Reflection Separation with Perceptual Losses</a></p>
                            <p>Xuaner Zhang, Ren Ng, and <b>Qifeng Chen</b></p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2018</p>
                            <p><a href="papers/Reflection_Separation_Supplementary_Material_CVPR2018.pdf">Supplementary Material</a></p>
                            <p><a href="https://github.com/ceciliavision/perceptual-reflection-removal">Source code</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/See_In_The_Dark_CVPR2018.pdf">Learning to See in the Dark</a></p>
                            <p>Chen Chen, <b>Qifeng Chen,</b> Jia Xu, and Vladlen Koltun</p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2018</p>
                            <p><a href="https://cchen156.github.io/SID.html">Project website</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="https://arxiv.org/pdf/1806.10522.pdf">Speech Denoising with Deep Feature Losses</a></p>
                            <p>Francois G Germain, <b>Qifeng Chen,</b> and Vladlen Koltun</p>
                            <p>Interspeech 2019</p>
                            <p>arXiv preprint arXiv:1806.10522</p>
                            <p><a href="https://github.com/francoisgermain/SpeechDenoisingWithDeepFeatureLosses">Source Code</a> </p>
                            <p><a href="https://ccrma.stanford.edu/~francois/SpeechDenoisingWithDeepFeatureLosses/"> Project Website</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Photographic_Image_Synthesis_ICCV2017.pdf">Photographic Image Synthesis with Cascaded Refinement Networks</a></p>
                            <p><b>Qifeng Chen</b> and Vladlen Koltun</p>
                            <p>International Conference on Computer Vision (ICCV), 2017</p>
                            <p><b>Full Oral Presentation (2.1% acceptance rate)</b></p>
                            <p><a href="ImageSynthesis">Project website</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Fast_Image_Processing_ICCV2017.pdf">Fast Image Processing with Fully-Convolutional Networks</a></p>
                            <p><b>Qifeng Chen*,</b> Jia Xu*, and Vladlen Koltun</p>
                            <p>International Conference on Computer Vision (ICCV), 2017</p>
                            <p><a href="ImageProcessing">Project website</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Full_Flow_CVPR2016.pdf">Full Flow: Optical Flow Estimation By Global Optimization over Regular Grids</a></p>
                            <p><b>Qifeng Chen</b> and Vladlen Koltun<br />
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2016<br />
                            <p><b>Full Oral Presentation (3.9% acceptance rate)</b><br />
                            <p><a href="fullflow">Project website (with source code)</a>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Dense_Monocular_Depth_CVPR2016.pdf">Dense Monocular Depth Estimation in Complex Dynamic Scenes</a><br />
                            <p>Ren&eacute; Ranftl, Vibhav Vineet, <b>Qifeng Chen,</b> and Vladlen Koltun</p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2016</p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Robust_Nonrigid_Registration_ICCV2015.pdf">Robust Nonrigid Registration by Convex Optimization</a></p>
                            <p><b>Qifeng Chen</b> and Vladlen Koltun</p>
                            <p>International Conference on Computer Vision (ICCV), 2015</p>
                            <p><b>Full Oral Presentation (3.3% acceptance rate)</b></p>
                            <p><a href="convex">Project website (with Matlab source code)</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Fast_MRF_Optimization_CVPR2014.pdf">Fast MRF Optimization with Application to Depth Reconstruction</a></p>
                            <p><b>Qifeng Chen</b> and Vladlen Koltun</p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2014</p>
                            <p><a href="fastMRF">Project website (with C++ and Matlab source code)</a></p>
                        </div>
                    </div>
                    <!--
                                                <a  data-cke-saved-href="http://arxiv.org/pdf/1409.6155v3.pdf" href="http://arxiv.org/pdf/1409.6155v3.pdf">1-HKUST: Object Detection in ILSVRC 2014</a><br>
                                                Cewu Lu, Hao Chen, Qifeng Chen, Hei Law, Yao Xiao, and Chi-Keung Tang<br>
                                                arXiv, 2014<br>
                                                <a  data-cke-saved-href="http://visgraph.cse.ust.hk/ilsvrc/1-HKUST.htm" href="http://visgraph.cse.ust.hk/ilsvrc/1-HKUST.htm">Project website</a><br><br><br>
                    -->

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/Intrinsic_Decomposition_ICCV2013.pdf">A Simple Model for Intrinsic Image Decomposition with Depth Cues</a></p>
                            <p><b>Qifeng Chen</b> and Vladlen Koltun</p>
                            <p>International Conference on Computer Vision (ICCV), 2013</p>
                            <p><a href="code/intrinsic_image_decomposition_source_code.zip">Matlab source code (updated on 2 Dec 2015)</a> <br/>
                            <a href="papers/Intrinsic_Decomposition_Supplementary_Material_ICCV2013.pdf">Supplementary material</a> &nbsp;
                            <a href="papers/Intrinsic_Decomposition_Poster_ICCV2013.pdf">Poster</a></p>
                            <p><i>Please email to sintel@tue.mpg.de for the MPI Sintel dataset.</i></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/KNN_Video_Matting_ICCV2013.pdf">Motion-Aware KNN Laplacian for Video Matting</a></p>
                            <p>Dingzeyu Li, <b>Qifeng Chen,</b> and Chi-Keung Tang</p>
                            <p>International Conference on Computer Vision (ICCV), 2013</p>
                            <p><a href="http://www.cs.columbia.edu/~dli/projects/knnvideomatting/">Project website</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/KNN_Matting_TPAMI2013.pdf">KNN Matting (with extension to layer color estimation)</a></p>
                            <p><b>Qifeng Chen,</b> Dingzeyu Li, and Chi-Keung Tang</p>
                            <p>Transactions on Pattern Analysis and Machine Intelligence (PAMI), 2013</p>
                            <p><a href="code/knn_matting_layer_estimation_source_code.zip">Matlab source code (for layer color estimation)</a></p>
                        </div>
                    </div>

                    <div class="paper">
                        <div class="image"></div>
                        <div class="content overlay">
                            <p><a href="papers/KNN_Matting_CVPR2012.pdf">KNN Matting</a></p>
                            <p><b>Qifeng Chen,</b> Dingzeyu Li, and Chi-Keung Tang</p>
                            <p>Conference on Computer Vision and Pattern Recognition (CVPR), 2012</p>
                            <p><a href="http://www.cs.columbia.edu/~dli/projects/knn/">Project website (with Matlab source code)</a></p>
                        </div>
                    </div>

                </div>
		</div>		

	</body>

</html>