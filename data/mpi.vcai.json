{
    "370": "<td width=\"130\">\n\t\t\t\t\t</td>\n\t\t\t\t",
    "369": "<td>\n\t\t\t\t\t\t<a href=\"https://xingangpan.github.io/\">X. Pan</a>,\n\t\t\t\t\t\t<a href=\"https://ayushtewari.com/\">A. Tewari</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~tleimkue/\">T. Leimk&#195;&#188;hler</a>,\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>,\n\t\t\t\t\t\t<a href=\"https://www.meka.page/\">A. Meka</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a><br/>\n\t\t\t\t\t\t<i>Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold</i><br/>\n\t\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH), 2023<br/> \n\t\t\t\t\t\t<a href=\"\">[paper coming soon]</a> \n\t\t\t\t\t\n\t\t\t\t\t</td>\n\t\t\t\t",
    "368": "<td>\n\t\t\t\t\t\t<a href=\"https://scholar.google.at/citations?user=jeasMB0AAAAJ&amp;hl=en\">B. Kerbl</a>,\n\t\t\t\t\t\t<a href=\"https://grgkopanas.github.io/\">G. Kopanas</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~tleimkue/\">T. Leimk&#195;&#188;hler</a> and\n\t\t\t\t\t\t<a href=\"http://www-sop.inria.fr/members/George.Drettakis/\">G. Drettakis</a><br/>\n\t\t\t\t\t\t<i>3D Gaussian Splatting for Real-Time Radiance Field Rendering</i><br/>\n\t\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH), 2023<br/>\n\t\t\t\t\t\t<a href=\"https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/\">[project page]</a> \n\t\t\t\t\t\t<a href=\"https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/3d_gaussian_splatting_high.pdf\">[paper]</a> \n\t\t\t\t\t\n\t\t\t\t\t</td>\n\t\t\t\t",
    "367": "<td>\n\t\t\t\t\t\t\t<a href=\"\">M. Farina</a>,\n\t\t\t\t\t\t<a href=\"https://scholar.google.com/citations?user=dF3qKXMAAAAJ&amp;hl=it&amp;oi=ao\">L. Magri</a>,\n\t\t\t\t\t\t<a href=\"https://scholar.google.com/citations?hl=it&amp;user=31ha1LgAAAAJ\">W. Menapace</a>,\n\t\t\t\t\t\t<a href=\"https://scholar.google.com/citations?hl=it&amp;user=xf1T870AAAAJ\">E. Ricci</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a> and\n\t\t\t\t\t\t<a href=\"https://scholar.google.com/citations?hl=it&amp;user=bzBtqfQAAAAJ\">F. Arrigoni</a><br/>\n\t\t\t\t\t\t<i>Quantum Multi-Model Fitting</i><br/>\n\t\t\t\t\t\tComputer Vision and Pattern Recognition (CVPR), 2023 <br/>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2303.15444.pdf\">[paper]</a>\n\t\t\t\t\t\t<a href=\"https://github.com/FarinaMatteo/qmmf\">[code]</a>\n\t\t\t\t\t\n\t\t\t\t\t</td>\n\t\t\t\t",
    "366": "<td>\n\t\t\t\t\t\t\t<a href=\"\">X. Long</a>,\n\t\t\t\t\t\t<a href=\"\">C. Lin</a>,\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>,\n\t\t\t\t\t\t<a href=\"\">Y. Liu</a>,\n\t\t\t\t\t\t<a href=\"\">P. Wang</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>,\n\t\t\t\t\t\t<a href=\"\">T. Komura</a> and\n\t\t\t\t\t\t<a href=\"\">W. Wang</a><br/>\n\t\t\t\t\t\t<i>NeuralUDF: Learning Unsigned Distance Fields for Multi-view Reconstruction of Surfaces with Arbitrary Topologies</i><br/>\n\t\t\t\t\t\tComputer Vision and Pattern Recognition (CVPR), 2023 <br/>\n\t\t\t\t\t\t<a href=\"https://www.xxlong.site/NeuralUDF/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2211.14173.pdf\">[paper]</a>\n\t\t\t\t\t\t<a href=\"https://github.com/xxlong0/NeuralUDF\">[code]</a>\n\t\t\t\t\t\n\t\t\t\t\t</td>\n\t\t\t\t",
    "365": "<td>\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jianwang/\">J. Wang</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~dluvizon/\">D. Luvizon</a>,\n\t\t\t\t\t\t<a href=\"https://sites.google.com/view/xuweipeng\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>,\n\t\t\t\t\t\t<a href=\"https://scholar.google.ca/citations?user=riuczTYAAAAJ&amp;hl=en\">K. Sarkar</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a><br/>\n\t\t\t\t\t\t<i>Scene-aware Egocentric 3D Human Pose Estimation</i><br/>\n\t\t\t\t\t\tComputer Vision and Pattern Recognition (CVPR), 2023 <br/>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jianwang/projects/sceneego/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jianwang/projects/sceneego/data/camera_ready.pdf\">[paper]</a>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jianwang/projects/sceneego/data/supp_mat.pdf\">[supplement]</a>\n\t\t\t\t\t\t<a href=\"https://nextcloud.mpi-klsb.mpg.de/index.php/s/Ritzm3ycioAADSH\">[dataset]</a>\n\t\t\t\t\t\n\t\t\t\t\t</td>\n\t\t\t\t\t",
    "364": "<td> \n\t\t\t\t\t\t\t<a href=\"\">L. Jiang</a>,\n\t\t\t\t\t\t\t<a href=\"\">Z. Yang</a>,\n\t\t\t\t\t\t\t<a href=\"\">S. Shi</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>,\n\t\t\t\t\t\t\t<a href=\"\">D. Dai </a> and\n\t\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele/\">B. Schiele </a><br/>\n\t\t\t\t\t\t\t<i>Self-supervised Pre-training with Masked Shape Prediction for 3D Scene Understanding</i><br/>\n\t\t\t\t\t\t\tComputer Vision and Pattern Recognition (CVPR), 2023 <br/>\n\t\t\t\t\t\t\t<a href=\"\">[paper coming soon]</a> \n\t\t\t\t\t\t\n\t\t\t\t\t\t</td>\n\t\t\t\t\t",
    "363": "<td>\n\t\t\t\t\t\t\t<a href=\"\">L. Xu*</a>,\n\t\t\t\t\t\t\t<a href=\"\">Y. Xiangli*</a>,\n\t\t\t\t\t\t\t<a href=\"\">S. Peng</a>,\n\t\t\t\t\t\t\t<a href=\"https://xingangpan.github.io/\">X. Pan</a>,\n\t\t\t\t\t\t\t<a href=\"\">N. Zhao</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>,\n\t\t\t\t\t\t\t<a href=\"\">B. Dai</a> and\n\t\t\t\t\t\t\t<a href=\"\">D. Lin</a><br/>\n\t\t\t\t\t\t\t<i>Grid-guided Neural Radiance Fields for Large Urban Scenes</i><br/>\n\t\t\t\t\t\t\tComputer Vision and Pattern Recognition (CVPR), 2023 <br/>\n\t\t\t\t\t\t\t<a href=\"https://city-super.github.io/gridnerf/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2303.14001\">[paper]</a>\n\t\t\t\t\t\t<a href=\"https://city-super.github.io/gridnerf/img/supp.pdf\">[supplement]</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t</td>\n\t\t\t\t\t\t",
    "362": "<td>\n\t\t\t\t\t\t\t<a href=\"\">R. Dabral</a>,\n\t\t\t\t\t\t\t<a href=\"\">M. Hamza Mughal</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a> and\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a><br/>\n\t\t\t\t\t\t\t<i>MoFusion: A Framework for Denoising-Diffusion-based Motion Synthesis</i><br/>\n\t\t\t\t\t\tComputer Vision and Pattern Recognition (CVPR), 2023 (Hightlight)<br/>\n\t\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/MoFusion/\">[project page]</a>\n\t\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/MoFusion/data/paper.pdf\">[paper]</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t</td>\n\t\t\t\t\t",
    "361": "<td>\n\t\t\t\t\t\t\t<a href=\"\">J. Zhang</a>,\n\t\t\t\t\t\t<a href=\"https://fnzhan.com/\">F. Zhan</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"\">S. Lu</a><br/>\n\t\t\t\t\t\t<i>Regularized Vector Quantization for Tokenized Image Synthesis</i><br/>\n\t\t\t\t\t\tComputer Vision and Pattern Recognition (CVPR), 2023 <br/>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2303.06424.pdf\">[paper]</a>\n\t\t\t\t\t\n\t\t\t\t\t</td>\n\t\t\t\t\t",
    "360": "<td>\n\t\t\t\t\t\t\t\t<a href=\"https://vrudnev.me/\">V. Rudnev</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\">M. Elgharib</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a><br/>\n\t\t\t\t\t\t\t<i>EventNeRF: Neural Radiance Fields from a Single Colour Event Camera</i><br/>\n\t\t\t\t\t\t\tComputer Vision and Pattern Recognition (CVPR), 2023 <br/>\n\t\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/EventNeRF/\">[project page]</a>\n\t\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2206.11896.pdf\">[paper]</a>\n\t\t\t\t\t\t\t<a href=\"https://nextcloud.mpi-klsb.mpg.de/index.php/s/xDqwRHiWKeSRyes\">[dataset]</a>\n\t\t\t\t\t\t\t<a href=\"https://github.com/r00tman/EventNeRF\">[code]</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t</td>\n\t\t\t\t\t",
    "359": "<td>\n\t\t\t\t\t\t\t\t<a href=\"https://scholar.google.com/citations?user=8rU1AaQAAAAJ&amp;hl=en&amp;oi=sra\">H. Bhatia</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~tretschk/\">E. Tretschk</a>,\n\t\t\t\t\t\t\t<a href=\"https://zorah.github.io/\">Z. L&#228;hner</a>,\n\t\t\t\t\t\t\t<a href=\"https://www.vsa.informatik.uni-siegen.de/en/seelbach-marcel\">M. S. Benkner</a>,\n\t\t\t\t\t\t\t<a href=\"https://sites.google.com/site/michaelmoellermath/\">M. Moeller</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a><br/>\n\t\t\t\t\t\t\t<i>CCuantuMM: Cycle-Consistent Quantum-Hybrid Matching of Multiple Shapes</i><br/>\n\t\t\t\t\t\t\tComputer Vision and Pattern Recognition (CVPR), 2023 <br/>\n\t\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/CCuantuMM/\">[project page]</a>\n\t\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2303.16202\">[paper]</a>\n\t\t\t\t\t\t\t<a href=\"https://github.com/HarshilBhatia/CCuantuMM\">[code]</a>\n\t\t\t\t\t\t</td>\n\t\t\t\t\t",
    "358": "<td>\n\t\t\t\t\t\t\t<a href=\"\">Z. Li</a>,\n\t\t\t\t\t\t\t<a href=\"\">X. Wang</a>,\n\t\t\t\t\t\t\t<a href=\"\">E. Stengel-Eskin</a>,\n\t\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\">A. Kortylewski</a>,\n\t\t\t\t\t\t\t<a href=\"\">W. Ma</a>,\n\t\t\t\t\t\t\t<a href=\"\">B. V. Durme</a> and\n\t\t\t\t\t\t\t<a href=\"\">A. Yuille</a><br/>\n\t\t\t\t\t\t\t<i>Super-CLEVR: A Virtual Benchmark to Diagnose Domain Robustness in Visual Reasoning</i><br/>\n\t\t\t\t\t\t\tComputer Vision and Pattern Recognition (CVPR), 2023 (Highlight)<br/>\n\t\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2212.00259.pdf\">[paper]</a>\n\t\t\t\t\t\t</td>\n\t\t\t\t\t",
    "357": "<td>\n\t\t\t\t\t\t\t\t<a href=\"\">P. Wang*</a>,\n\t\t\t\t\t\t\t<a href=\"\">Y. Liu*</a>,\n\t\t\t\t\t\t\t<a href=\"\">Z. Chen</a>,\n\t\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>,\n\t\t\t\t\t\t\t<a href=\"\">Z. Liu</a>,\n\t\t\t\t\t\t\t<a href=\"\">T. Komura</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t\t<a href=\"\">W. Wang</a><br/>\n\t\t\t\t\t\t\t<i>F2-NeRF: Fast Neural Radiance Field Training with Free Camera Trajectories</i><br/>\n\t\t\t\t\t\t\tComputer Vision and Pattern Recognition (CVPR), 2023 (Highlight)<br/>\n\t\t\t\t\t\t\t<a href=\"https://totoro97.github.io/projects/f2-nerf/\">[project page]</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t</td>\n\t\t\t\t\t\t",
    "356": "<td>\n\t\t\t\t\t\t\t\t\t<a href=\"\">C. Li</a>,\n\t\t\t\t\t\t\t\t<a href=\"\">A. Morel-Forster</a>,\n\t\t\t\t\t\t\t\t<a href=\"\">T. Vetter</a>,\n\t\t\t\t\t\t\t\t<a href=\"\">B. Egger</a> and\n\t\t\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\">A. Kortylewski</a><br/>\n\t\t\t\t\t\t\t\t<i>Robust Model-based Face Reconstruction through Weakly-Supervised Outlier Segmentation</i><br/>\n\t\t\t\t\t\t\t\tComputer Vision and Pattern Recognition (CVPR), 2023 <br/>\n\t\t\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2106.09614.pdf\">[paper]</a>\n\t\t\t\t\t\t\t\t<a href=\"https://github.com/unibas-gravis/Occlusion-Robust-MoFA\">[code]</a>\n\t\t\t\t\t\t\t</td>\n\t\t\t\t\t\t\t",
    "355": "<td>\n\t\t\t\t\t\t\t\t\t<a href=\"\">Q. Liu</a>,\n\t\t\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\">A. Kortylewski</a> and\n\t\t\t\t\t\t\t\t<a href=\"\">A. Yuille</a><br/>\n\t\t\t\t\t\t\t\t<i>PoseExaminer: Automated Testing of Out-of-Distribution Robustness in Human Pose and Shape Estimation</i><br/>\n\t\t\t\t\t\t\t\tComputer Vision and Pattern Recognition (CVPR), 2023 <br/>\n\t\t\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2303.07337.pdf\">[paper]</a>\n\t\t\t\t\t\t\t\t<a href=\"https://github.com/qihao067/PoseExaminer\">[code]</a>\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t</td>\n\t\t\t\t\t",
    "354": "<td> \n\t\t\t\t\t\t\t<a href=\"https://www.ecmjohnson.com/\">E. C.M. Johnson</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~sshimada/\">S. Shimada</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a> and\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a><br/>\n\t\t\t\t\t\t\t<i>Unbiased 4D: Monocular 4D Reconstruction with a Neural Deformation Model</i><br/>\n\t\t\t\t\t\t\tComputer Vision and Pattern Recognition Workshop (CVPRW), 2023 <br/>\n\t\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/Ub4D/\">[project page]</a>\n\t\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2206.08368.pdf\">[paper]</a>\n\t\t\t\t\t\t\t<a href=\"https://github.com/ecmjohnson/ub4d/\">[code]</a>\n\t\t\t\t\t\t\t<a href=\"https://drive.google.com/drive/folders/1lFhLqeNjslqgIuRpQnUlHbd5-56vaDNE\">[data]</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t</td>\n\t\t\t\t\t",
    "353": "<td>\n\t\t\t\t\t\t\t\t\t<a href=\"\">A. Wang</a>,\n\t\t\t\t\t\t\t\t<a href=\"\">P. Wang</a>,\n\t\t\t\t\t\t\t\t<a href=\"\">J. Sun</a>,\n\t\t\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\">A. Kortylewski</a> and\n\t\t\t\t\t\t\t\t<a href=\"\">A. Yuille</a><br/>\n\t\t\t\t\t\t\t\t<i>VoGE: A Differentiable Volume Renderer using Gaussian Ellipsoids for Analysis-by-Synthesis</i><br/>\n\t\t\t\t\t\t\t\tInternational Conference on Learning Representations (ICLR), 2023 <br/>\n\t\t\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2205.15401.pdf\">[paper]</a>\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t</td>\n\t\t\t\t\t",
    "352": "<td>\n\t\t\t\t\t\t\t<a href=\"https://fnzhan.com/\">F. Zhan</a>,\n\t\t\t\t\t\t\t<a href=\"\">L. Liu</a>,\n\t\t\t\t\t\t\t<a href=\"\">A. Kortylewski</a> and\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a><br/>\n\t\t\t\t\t\t\t<i>General Neural Gauge Fields</i><br/>\n\t\t\t\t\t\t\tInternational Conference on Learning Representations (ICLR), 2023 <br/>\n\t\t\t\t\t\t\t<a href=\"https://fnzhan.com/neural-gauge-fields/\">[project page]</a>\n\t\t\t\t\t\t\t<a href=\"https://openreview.net/pdf?id=XWkWK2UagFR\">[paper]</a>\n\t\t\t\t\t\t\t<a href=\"https://drive.google.com/drive/folders/128yBriW1IG_3NJ5Rp7APSTZsJqdJdfc1\">[dataset]</a>\n\t\t\t\t\t\t\t<a href=\"https://github.com/fnzhan/Neural-Gauge-Fields\">[code]</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t</td>\n\t\t\t\t\t",
    "351": "<td>\n\t\t\t\t\t\t\t\t<a href=\"https://www.vsa.informatik.uni-siegen.de/en/seelbach-marcel\">M. S. Benkner</a>,\n\t\t\t\t\t\t\t<a href=\"https://scholar.google.com/citations?user=Dg5q7-QAAAAJ&amp;hl=en&amp;oi=ao\">M. Krahn</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~tretschk/\">E. Tretschk</a>,\n\t\t\t\t\t\t\t<a href=\"https://zorah.github.io/\">Z. L&#228;hner</a>,\n\t\t\t\t\t\t\t<a href=\"https://sites.google.com/site/michaelmoellermath/\">M. Moeller</a> and\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a><br/>\n\t\t\t\t\t\t\t<i>QuAnt: Quantum Annealing with Learnt Couplings</i><br/>\n\t\t\t\t\t\t\tInternational Conference on Learning Representations (ICLR), 2023 (spotlight)<br/>\n\t\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/QuAnt/\">[project page]</a>\n\t\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2210.08114\">[paper]</a>\n\t\t\t\t\t\t\t<a href=\"https://openreview.net/forum?id=isiQ5KIXbjj\">[supplement]</a>\n\t\t\t\t\t\t\t<a href=\"https://openreview.net/forum?id=isiQ5KIXbjj\">[dataset]</a>\n\t\t\t\t\t\t\t<a href=\"https://github.com/MSeelbach/QuAnt\">[code]</a>\n\t\t\t\t\t\t</td>\n\t\t\t\t\t",
    "350": "<td>\n\t\t\t\t\t\t\t<a href=\"\">T. Wu</a>,\n\t\t\t\t\t\t\t<a href=\"\">J. Wang</a>,\n\t\t\t\t\t\t\t<a href=\"https://xingangpan.github.io/\">X. Pan</a>,\n\t\t\t\t\t\t\t<a href=\"\">X. Xu</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>,\n\t\t\t\t\t\t\t<a href=\"\">Z. Liu</a> and\n\t\t\t\t\t\t\t<a href=\"\">D. Lin</a><br/>\n\t\t\t\t\t\t\t<i>Voxurf: Voxel-based Efficient and Accurate Neural Surface Reconstruction</i><br/>\n\t\t\t\t\t\t\tInternational Conference on Learning Representations (ICLR), 2023 (spotlight)<br/>\n\t\t\t\t\t\t\t<a href=\"https://wutong16.github.io/publication/10_iclr2023_voxurf/\">[project page]</a>\n\t\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2208.12697\">[paper]</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t</td>\n\t\t\t\t",
    "349": "<td>\n\t\t\t\t\t\t\t<a href=\"https://clementjambon.github.io/\">C. Jambon</a>,\n\t\t\t\t\t\t<a href=\"https://www.cg.tuwien.ac.at/staff/BernhardKerbl\">B. Kerbl</a>,\n\t\t\t\t\t\t<a href=\"https://grgkopanas.github.io/\">G. Kopanas</a>,\n\t\t\t\t\t\t<a href=\"https://www.sdiolatz.info/\">S. Diolatzis</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~tleimkue/\">T. Leimk&#252;hler</a> and\n\t\t\t\t\t\t<a href=\"http://www-sop.inria.fr/members/George.Drettakis/\">G. Drettakis</a><br/>\n\t\t\t\t\t\t<i>NeRFshop: Interactive Editing of Neural Radiance Fields</i><br/>\n\t\t\t\t\t\tACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D), 2023 <br/>\n\t\t\t\t\t\t<a href=\"https://repo-sam.inria.fr/fungraph/nerfshop/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"http://www-sop.inria.fr/reves/Basilic/2023/JKKDLD23/nerfshop.pdf\">[paper]</a>\n\t\t\t\t\t\n\t\t\t\t\t</td>\n\t\t\t\t\t",
    "348": "<td>\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~tretschk/\">E. Tretschk*</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~nkairand/\">N. Kairanda*</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mbr/\">M. B R</a>,\n\t\t\t\t\t\t<a href=\"https://www.cse.iitb.ac.in/~rdabral/\">R. Dabral</a>,\n\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\">A. Kortylewski</a>,\n\t\t\t\t\t\t<a href=\"https://www.ki.fau.de/speakers/prof-dr-bernhard-egger/\">B. Egger</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\n\t\t\t\t\t\t<a href=\"https://people.epfl.ch/pascal.fua/bio?lang=en\">P. Fua</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a><br/>\n\t\t\t\t\t\t<i>State of the Art in Dense Monocular Non-Rigid 3D Reconstruction</i><br/>\n\t\t\t\t\t\tEurographics, 2023 (STAR)<br/>\n\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/star_monocular_nr3d/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2210.15664\">[paper]</a>\n\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/star_monocular_nr3d/data/Survey_MONO_NONRIGID_3D_extended_2.pdf\">[extended version]</a>\n\t\t\t\t\t\n\t\t\t\t\t</td>\n\t\t\t\t",
    "347": "<td>\n\t\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~dluvizon/\">D. C. Luvizon</a>,\n\t\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\n\t\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>,\n\t\t\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\">A. Kortylewski</a> and\n\t\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a><br/>\n\t\t\t\t\t\t\t\t<i>Scene-Aware 3D Multi-Human Motion Capture from a Single Camera</i><br/>\n\t\t\t\t\t\t\t\tEurographics, 2023 <br/>\n\t\t\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/scene-aware-3d-multi-human/\">[project page]</a>\n\t\t\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2301.05175\">[paper]</a>\n\t\t\t\t\t\t\t\t<a href=\"https://github.com/dluvizon/scene-aware-3d-multi-human\">[code]</a>\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t</td>\n\t\t\t\t\t",
    "346": "<td>\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~anghosh/\">A. Ghosh</a>,\n\t\t\t\t\t\t\t<a href=\"https://www.cse.iitb.ac.in/~rdabral/\">R. Dabral</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t\t<a href=\"https://graphics.cg.uni-saarland.de/people/slusallek.html\">P. Slusallek</a><br/>\n\t\t\t\t\t\t\t<i>IMoS: Intent-Driven Full-Body Motion Synthesis for Human-Object Interactions</i><br/>\n\t\t\t\t\t\t\tEurographics, 2023 <br/>\n\t\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/IMoS/\">[project page]</a>\n\t\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2212.07555.pdf\">[paper]</a>\n\t\t\t\t\t\t\t<a href=\"https://github.com/anindita127/IMoS\">[code]</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t</td>\n\t\t\t\t\t",
    "345": "<td width=\"130\">\n\t\t\t\t\t</td>\n\t\t\t\t",
    "344": "<td> \n\t\t\t\t\t\t<a href=\"https://scholar.google.com/citations?user=8rU1AaQAAAAJ&amp;hl=en&amp;oi=sra\">H. Bhatia</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~tretschk/\">E. Tretschk</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>  \n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t<br/>\n\t\t\t\t\t\t<i>Generation of Truly Random Numbers on a Quantum Annealer</i><br/> \n\t\t\t\t\t\tIEEE Access, 2022<br/>\n\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/QRNG/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9923932\">[paper]</a>   \n\t\t\t\t\t\t<a href=\"https://github.com/HarshilBhatia/QRNG/\">[code]</a>   \n\t\t\t\t\t</td>\n\t\t\t\t",
    "343": "<td> \n\t\t\t\t\t\t<a href=\"https://cong-yi.github.io/\">C. Zhang</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\">M. Elgharib</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~gfox/\">G. Fox</a>,\n\t\t\t\t\t\t<a href=\"https://facdent.hku.hk/about/staff-profile.php?shortname=drgumin\">M. Gu </a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html\">W.  Wang</a> \n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t<br/>\n\t\t\t\t\t\t<i>An Implicit Parametric Morphable Dental Model</i><br/> \n\t\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH Asia), 2022<br/>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/DMM/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/DMM/data/paper_lowres.pdf\">[paper]</a>   \n\t\t\t\t\t\t<a href=\"https://github.com/cong-yi/DMM\">[code]</a>   \n\t\t\t\t\t</td>\n\t\t\t\t",
    "342": "<td>\t\t\n\t\t\t\t\t\t<a href=\"https://grgkopanas.github.io/\">G. Kopanas</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~tleimkue/\">T. Leimk&#252;hler</a>,\n\t\t\t\t\t\t<a href=\"https://scholar.google.com/citations?user=uRSdPokAAAAJ&amp;hl=en\">G. Rainer</a>,\n\t\t\t\t\t\t<a href=\"https://clementjambon.github.io/\">C. Jambon</a> and\n\t\t\t\t\t\t<a href=\"http://www-sop.inria.fr/members/George.Drettakis/\">G. Drettakis</a> \n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t<br/>\n\t\t\t\t\t\t<i>Neural Point Catacaustics for Novel-View Synthesis of Reflections</i><br/> \n\t\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH Asia), 2022<br/>\n\t\t\t\t\t\t<a href=\"https://repo-sam.inria.fr/fungraph/neural_catacaustics/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://repo-sam.inria.fr/fungraph/neural_catacaustics/neural-catacaustics_small.pdf\">[paper]</a>   \n\t\t\t\t\t</td>\n\t\t\t\t",
    "341": "<td>\t\t\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jwang/\">J. Wang</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~dluvizon/\">D. Luvizon</a>,\n\t\t\t\t\t\t<a href=\"https://franziska-mueller.github.io/\">F. Mueller</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~fbernard/\">F. Bernard</a>,\n\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\">A. Kortylewski</a>,\n\t\t\t\t\t\t<a href=\"https://dancasas.github.io/\">D. Casas</a>\n\t\t\t\t\t\t and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> \n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t<br/>\n\t\t\t\t\t\t<i>HandFlow: Quantifying View-Dependent 3D Ambiguity in Two-Hand Reconstruction with Normalizing Flow</i><br/> \n\t\t\t\t\t\tSymposium on Vision, Modeling, and Visualization (VMV), 2022 (Best Paper Honorable Mention)<br/>\n\t\t\t\t\t\t<a href=\"https://handtracker.mpi-inf.mpg.de/projects/HandFlow/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://handtracker.mpi-inf.mpg.de/projects/HandFlow/content/HandFlow.pdf\">[paper]</a>   \n\t\t\t\t\t</td>\n\t\t\t\t",
    "340": "<td>\t\t\n\t\t\t\t\t\t<a href=\"\">P. Rao</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mbr/\">M. B R</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~gfox/\">G. Fox</a>,\n\t\t\t\t\t\t<a href=\"\">T. Weyrich</a>,\n\t\t\t\t\t\t<a href=\"\">B. Bickel</a>,\n\t\t\t\t\t\t<a href=\"\">H. Pfister</a>,\n\t\t\t\t\t\t<a href=\"\">W. Matusik</a>,\n\t\t\t\t\t\t<a href=\"https://ayushtewari.com/\">A. Tewari</a>, \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\">M. Elgharib</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> \n\t\t\t\t\t\t  \n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i>\tVoRF: Volumetric Relightable Faces</i><br/> \n\t\t\t\t\t\tBritish Machine Vision Conference (BMVC), 2022 (Best Paper Award Honourable Mention)<br/>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/VoRF/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"\">[paper (coming soon)]</a>   \n\t\t\t\t\t</td>\n\t\t\t\t",
    "339": "<td>\t\t\n\t\t\t\t\t\t<a href=\"https://yuejiang-nj.github.io/\">Y. Jiang</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> \n\t\t\t\t\t\t  \n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i>HiFECap: Monocular High-Fidelity and Expressive Capture of Human Performances.</i><br/> \n\t\t\t\t\t\tBritish Machine Vision Conference (BMVC), 2022<br/>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2022-HiFECap/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2022-HiFECap/data/paper.pdf\">[paper]</a>  \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2022-HiFECap/data/supp.pdf\">[supplement]</a> \n\t\t\t\t\t</td>\n\t\t\t\t",
    "338": "<td>\t\t\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/zhi-li/\">Z. Li</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~sshimada/\">S. Shimada</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/bernt-schiele/\">B. Schiele</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>\n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i>MoCapDeform: Monocular 3D Human Motion Capture in Deformable Scenes</i><br/> \n\t\t\t\t\t\tInternational Conference on 3D Vision (3DV), 2022, (Best Student Paper Award)<br/>\n\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/MoCapDeform/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2208.08439.pdf\">[paper]</a>  \n\t\t\t\t\t\t<a href=\"https://github.com/Malefikus/MoCapDeform\">[code]</a>  \n\t\t\t\t\t</td>\n\t\t\t\t",
    "337": "<td>\t\t\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mbr/\">M. B R</a>,\n\t\t\t\t\t\t<a href=\"https://ayushtewari.com/\">A. Tewari</a>,\n\t\t\t\t\t\t<a href=\"https://xingangpan.github.io/\">X. Pan</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\">M. Elgharib</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i>gCoRF: Generative Compositional Radiance Fields</i><br/> \n\t\t\t\t\t\tInternational Conference on 3D Vision (3DV), 2022<br/>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/gCoRF/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/gCoRF/data/paper.pdf\">[paper]</a>   \n\t\t\t\t\t</td>\n\t\t\t\t",
    "336": "<td>\t\t\n\t\t\t\t\t\t<a href=\"https://xingangpan.github.io/\">X. Pan</a>,\n\t\t\t\t\t\t<a href=\"https://ayushtewari.com/\">A. Tewari</a>,\n\t\t\t\t\t\t<a href=\"https://www.xxlong.site/\">X. Long</a>,\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i>GAN2X: Non-Lambertian Inverse Rendering of Image GANs</i><br/> \n\t\t\t\t\t\tInternational Conference on 3D Vision (3DV), 2022<br/>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/GAN2X/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/GAN2X/data/paper.pdf\">[paper]</a>  \n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/GAN2X/data/supplementary.pdf\">[supplement]</a> \n\t\t\t\t\t</td>\n\t\t\t\t",
    "335": "<td>\t\t\n\t\t\t\t\t\t<a href=\" \">J. Wang</a>,\n\t\t\t\t\t\t<a href=\"https://totoro97.github.io/about.html\">P. Wang</a>,\n\t\t\t\t\t\t<a href=\"https://www.xxlong.site/\">X. Long</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>,\n\t\t\t\t\t\t<a href=\"https://www.cs.hku.hk/index.php/people/academic-staff/taku\">T. Komura</a>,\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a> and\n\t\t\t\t\t\t<a href=\"https://www.cs.hku.hk/people/academic-staff/wenping\">W. Wang</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t  \n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i>NeuRIS: Neural Reconstruction of Indoor Scenes Using Normal Priors</i><br/> \n\t\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2022<br/>\n\t\t\t\t\t\t<a href=\"https://jiepengwang.github.io/NeuRIS/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2206.13597\">[paper]</a>  \n\t\t\t\t\t\t<a href=\"https://github.com/jiepengwang/NeuRIS\">[code]</a> \n\t\t\t\t\t</td>\n\t\t\t\t",
    "334": "<td>\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~llyu/\">L. Lyu </a>,\n\t\t\t\t\t\t<a href=\"https://ayushtewari.com/\">A. Tewari</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~tleimkue/\">T. Leimkuehler</a>,  \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann  </a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t  \n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i>Neural Radiance Transfer Fields for Relightable Novel-view Synthesis with Global Illumination</i><br/> \n\t\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2022 (Oral)<br/>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2022-NRTF/index.htm\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2022-NRTF/data/paper.pdf\">[paper]</a>  \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2022-NRTF/data/supp.pdf\">[supplement]</a> \n\t\t\t\t\t</td>\n\t\t\t\t",
    "333": "<td>\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~sshimada/\">S. Shimada</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/zhi-li\">Z. Li</a>,  \n\t\t\t\t\t\t<a href=\"https://ptrckprz.github.io/\">P. P&#195;&#169;rez</a>,\n\t\t\t\t\t\t<a href=\"https://sites.google.com/view/xuweipeng\">W. Xu</a>,  and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t  \n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i>HULC: 3D HUman Motion Capture with Pose Manifold Sampling and Dense Contact Guidance</i><br/> \n\t\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2022<br/>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/HULC/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/HULC/data/paper_light.pdf\">[paper]</a>  \n\t\t\t\t\t</td>\n\t\t\t\t",
    "332": "<td>\t\t\n\t\t\t\t\t\t<a href=\"https://www.deib.polimi.it/eng/people/details/765978\">F. Arrigoni</a>,\n\t\t\t\t\t\t<a href=\"https://www.willimenapace.com/\">W. Menapace</a>,\n\t\t\t\t\t\t<a href=\"https://www.vsa.informatik.uni-siegen.de/en/seelbach-marcel\">M.S. Benkner</a>,  \n\t\t\t\t\t\t<a href=\"http://elisaricci.eu/\">E. Ricci</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>\n\t\t\t\t\t\t  \n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i>Quantum Motion Segmentation</i><br/> \n\t\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2022<br/>\n\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/QuMoSeg/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2203.13185.pdf\">[paper]</a> \n\t\t\t\t\t\t<a href=\"https://github.com/federica-arrigoni/QuMoSeg\">[code]</a> <br/>\n\t\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t\t</td>\n\t\t\t\t",
    "331": "<td>\t\t\n\t\t\t\t\t\t<a href=\"http://labusers.net/~hakada/\">H. Akada</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jianwang/\">J. Wang</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~sshimada/\">S. Shimada</a>,  \n\t\t\t\t\t\t<a href=\"https://www.st.keio.ac.jp/en/tprofile/sd/takahashi.html\">M. Takahashi</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>\n\t\t\t\t\t\t  \n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i> UnrealEgo: A New Dataset for Robust Egocentric 3D Human Motion Capture</i><br/> \n\t\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2022<br/>\n\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/UnrealEgo/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2208.01633\">[paper]</a> \n\t\t\t\t\t\t<a href=\"https://github.com/hiroyasuakada/UnrealEgo\">[code]</a> <br/>\n\t\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t\t</td>\n\t\t\t\t",
    "330": "<td>\t\t\n\t\t\t\t\t\t<a href=\"https://twitter.com/realr00tman\">V. Rudnev</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\">M. Elgharib</a>,\n\t\t\t\t\t\t<a href=\"https://www-users.cs.york.ac.uk/wsmith/\">W. Smith</a>,  \n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> \n\t\t\t\t\t\t \n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i> Neural Radiance Fields for Outdoor Scene Relighting</i><br/> \n\t\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2022<br/>\n\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/NeRF-OSR/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2112.05140.pdf\">[paper]</a> \n\t\t\t\t\t\t<a href=\"https://github.com/r00tman/NeRF-OSR\">[code]</a> <br/>\n\t\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t\t</td>\n\t\t\t\t",
    "329": "<td>\t\t\n\t\t\t\t\t\t<a href=\"\">J. He</a>,\n\t\t\t\t\t\t<a href=\"\">S. Yang</a>,\n\t\t\t\t\t\t<a href=\"\">S. Yang</a>,  \n\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\">A. Kortylewski</a>,\n\t\t\t\t\t\t<a href=\"\">X. Yuan</a>, \n\t\t\t\t\t\t<a href=\"\">J.N. Chen</a>, \n\t\t\t\t\t\t<a href=\"\">S. Liu</a>, \n\t\t\t\t\t\t<a href=\"\">C. Yang</a> and\n\t\t\t\t\t\t<a href=\"\">A. Yuille</a>  \n\t\t\t\t\t\t \n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i> PartImageNet: A Large, High-Quality Dataset of Parts</i><br/> \n\t\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2022<br/> \n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2112.00933\">[paper]</a> \n\t\t\t\t\t\t<a href=\"https://github.com/TACJu/PartImageNet\">[dataset]</a> <br/>\n\t\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t\t</td>\n\t\t\t\t",
    "328": "<td>\t\t\n\t   \n\t\t\t\t\t\t<a href=\"\">W. Ma</a>,\n\t\t\t\t\t\t<a href=\"\">A. Wang</a>, \n\t\t\t\t\t\t<a href=\"\">A. Yuille</a> and\n\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\">A. Kortylewski</a>\n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i>Robust Category-Level 6D Pose Estimation with Coarse-to-Fine Rendering of Neural Features</i><br/> \n\t\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2022<br/>\n\t\t\t\t\t\t<a href=\"\">[project page (coming soon)]</a> \n\t\t\t\t\t</td>\n\t\t\t\t",
    "327": "<td>\t\t\n\t  \n\t\t\t\t\t\t<a href=\"\">B. Zhao</a>,  \n\t\t\t\t\t\t<a href=\"\">S. Yu</a>, \n\t\t\t\t\t\t<a href=\"\">W. Ma</a>, \n\t\t\t\t\t\t<a href=\"\">M. Yu</a>, \n\t\t\t\t\t\t<a href=\"\">S. Mei</a>, \n\t\t\t\t\t\t<a href=\"\">A. Wang</a>,\n\t\t\t\t\t\t<a href=\"\">J. He</a>,\n\t\t\t\t\t\t<a href=\"\">A. Yuille</a> and\n\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\">A. Kortylewski</a>\n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i> OOD-CV: A Benchmark for Robustness to Out-of-Distribution Shifts of Individual Nuisances in Natural Images</i><br/> \n\t\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2022 (Oral)<br/>\n\t\t\t\t\t\t<a href=\"https://bzhao.me/ROBIN/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2111.14341.pdf\">[paper]</a> \n\t\t\t\t\t\t<a href=\"https://github.com/eccv22-ood-workshop/ROBIN-datasetF\">[code]</a> <br/>\n\t\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t\t</td>\n\t\t\t\t",
    "326": "<td>\t\t\n\t  \n\t\t\t\t\t\t<a href=\"\">Y. Xiangli</a>,  \n\t\t\t\t\t\t<a href=\"\">L. Xu</a>, \n\t\t\t\t\t\t<a href=\"https://xingangpan.github.io/\">X. Pan</a>, \n\t\t\t\t\t\t<a href=\"\">N. Zhao</a>, \n\t\t\t\t\t\t<a href=\"\">A. Rao</a>, \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>,\n\t\t\t\t\t\t<a href=\"\">B. Dai</a> and\n\t\t\t\t\t\t<a href=\"\">D. Lin</a>\n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i> BungeeNeRF: Progressive Neural Radiance Field for Extreme Multi-scale Scene Rendering</i><br/> \n\t\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2022<br/>\n\t\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"https://city-super.github.io/citynerf/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://city-super.github.io/citynerf/img/1947.pdf\">[paper]</a> \n\t\t\t\t\t\t<a href=\"https://city-super.github.io/citynerf/img/supp.pdf\">[supplement]</a> \n\t\t\t\t\t\t<a href=\"https://github.com/city-super/BungeeNeRF\">[code]</a> <br/>\n\t\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t\t</td>\n\t\t\t\t",
    "325": "<td>\t\t\n\t  \n\t\t\t\t\t\t<a href=\"https://scholar.google.com/citations?user=dv1IuQUAAAAJ&amp;hl=zh-CN\">Y. Wu</a>,  \n\t\t\t\t\t\t<a href=\"https://jiahaoplus.github.io//\">J. Wang</a>, \n\t\t\t\t\t\t<a href=\"https://yz-cnsdqz.github.io//\">Y. Zhang</a>, \n\t\t\t\t\t\t<a href=\"https://vlg.inf.ethz.ch/team/Siwei-Zhang.html\">S. Zhang</a>, \n\t\t\t\t\t\t<a href=\"https://ait.ethz.ch/people/hilliges/\">O. Hilliges</a>, \n\t\t\t\t\t\t<a href=\"https://www.yf.io/\">F. Yu</a> and\n\t\t\t\t\t\t<a href=\"https://inf.ethz.ch/people/person-detail.MjYyNzgw.TGlzdC8zMDQsLTg3NDc3NjI0MQ==.html\">S. Tang</a>\n\t\t\t\t\t\t  <br/>\n\t\t\t\t\t\t<i> SAGA: Stochastic Whole-Body Grasping with Contact</i><br/> \n\t\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2022<br/>\n\t\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"https://jiahaoplus.github.io/SAGA/saga.html\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2112.10103\">[paper]</a> \n\t\t\t\t\t\t<a href=\"https://github.com/JiahaoPlus/SAGA\">[code]</a> <br/>\n\t\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t\t</td>\n\t\t\t\t",
    "324": "<td> \n\t\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/~ihabibie/\" target=\"_blank\">I. Habibie</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\"> M. Elgharib</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~ksarkar/\" target=\"_blank\">K. Sarkar</a>,\n\t\t\t\t\t\t\t<a href=\"https://scholar.google.com/citations?user=4vWXwhsAAAAJ&amp;hl=en\" target=\"_blank\">A. Abdullah</a>,\n\t\t\t\t\t\t\t<a href=\"https://simnyatsanga.github.io/\" target=\"_blank\">S. Nyatsanga</a>,\n\t\t\t\t\t\t\t<a href=\"https://web.cs.ucdavis.edu/~neff/\" target=\"_blank\">M. Neff</a> and\n\t\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t\t\t<br/>\n\n\t\t\t\t\t\t\t<i> A Motion Matching-based Framework for Controllable Gesture Synthesis from Speech </i> <br/>\n\t\t\t\t\t\t\t\tProc. of SIGGRAPH 2022<br/> \t\n\t\t\t\t\t\t\t\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/SpeechGestureMatching/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/SpeechGestureMatching/data/paper.pdf\">[paper]</a> \n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/SpeechGestureMatching/data/supp.pdf\">[supplementary]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/SpeechGestureMatching/data/video.mp4\">[video]</a> \n\t\t\t\t\t</td>  \n\t\t\t\t",
    "323": "<td>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mchu/\" target=\"_blank\">M. Chu</a>,\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\" target=\"_blank\">L. Liu</a>, \n\t\t\t\t\t\t<a href=\"https://quan-zheng.github.io/\">Q. Zheng</a>,\n\t\t\t\t\t\t<a href=\"https://ge.in.tum.de/about/erik-franz/\" target=\"_blank\">E. Franz</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H.P. Seidel</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~rzayer/\" target=\"_blank\">R. Zayer</a>    \n\t\t\t\t\t\t<br/>                               \n\t\t\t\t\t\t<i>Physics Informed Neural Fields for Smoke Reconstruction with Sparse Data</i><br/>\n\t\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH 2022)<br/>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/PI-NeRF/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/PI-NeRF/content/PINeRF.pdf\">[paper]</a>  \n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/PI-NeRF/content/supplementary/ClickMe.html\">[supplementary] </a>   \n\t\t\t\t\t</td>\n\t\t\t\t",
    "322": "<td>\n\t\t\t\t\t\t<a href=\"https://ayushtewari.com/\" target=\"_blank\">A. Tewari</a>,\n\t\t\t\t\t\t<a href=\"https://justusthies.github.io/\" target=\"_blank\">J. Thies</a>,\n\t\t\t\t\t\t<a href=\"https://bmild.github.io/\" target=\"_blank\">B. Mildenhall</a>,\n\t\t\t\t\t\t<a href=\"https://pratulsrinivasan.github.io/\" target=\"_blank\">P. Srinivasan</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~tretschk/\">E. Tretschk</a>,\n\t\t\t\t\t\t<a href=\"https://yifita.github.io/\" target=\"_blank\">Y. Wang</a>,\n\t\t\t\t\t\t<a href=\"https://christophlassner.de/\" target=\"_blank\">C. Lassner</a>,\n\t\t\t\t\t\t<a href=\"https://www.vincentsitzmann.com/\" target=\"_blank\">V. Sitzmann</a>,\n\t\t\t\t\t\t<a href=\"http://ricardomartinbrualla.com/\" target=\"_blank\">R.M. Brualla</a>,\n\t\t\t\t\t\t<a href=\"https://stephenlombardi.github.io/\" target=\"_blank\">S. Lombardi</a>,\n\t\t\t\t\t\t<a href=\"http://www.cs.cmu.edu/~tsimon/\" target=\"_blank\">T. Simon</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>,\n\t\t\t\t\t\t<a href=\"http://www.niessnerlab.org/members/matthias_niessner/profile.html\" target=\"_blank\">M. Nie&#223;ner</a>,\n\t\t\t\t\t\t<a href=\"https://jonbarron.info/\" target=\"_blank\">J. Barron</a>,\n\t\t\t\t\t\t<a href=\"http://web.stanford.edu/~gordonwz/\" target=\"_blank\">G. Wetzstein</a>,\n\t\t\t\t\t\t<a href=\"http://zollhoefer.com/\" target=\"_blank\">M. Zollhoefer</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik</a>\n\n\t\t\t\t\t\t<br/>                               \n\t\t\t\t\t\t<i>Advances in Neural Rendering</i><br/>\n\t\t\t\t\t\tComputer Graphics Forum (Eurographics STAR report), 2022<br/>\n\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/star_neural_rendering/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2111.05849\">[paper]</a>  \n\t\n\t\t\t\t\t</td>\n\t\t\t\t",
    "321": "<td>\n\t\t\t\t\t\t<a href=\"https://ayushtewari.com/\" target=\"_blank\">A. Tewari</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mbr/\" target=\"_blank\">M. B R</a>,\n\t\t\t\t\t\t<a href=\"https://xingangpan.github.io/\" target=\"_blank\"> X. Pan</a>,\n\t\t\t\t\t\t\t<a href=\"https://www.ohadf.com/\" target=\"_blank\">O. Fried</a>,\n\t\t\t\t\t\t\t<a href=\"http://graphics.stanford.edu/~maneesh/\" target=\"_blank\">M. Agrawala</a> and\n\t\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t<br/>                               \n\t\t\t\t\t\t<i>Disentangled3D: Learning a 3D Generative Model with Disentangled Geometry and Appearance from Monocular Images</i><br/>\n\t\t\t\t\t\t  Computer Vision and Pattern Recognition (CVPR), 2022 <br/>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/D3D/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/D3D/data/paper.pdf\">[paper]</a> \n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/D3D/data/supp.pdf\">[supplementary]</a>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/D3D/data/video.mp4\">[video]</a>\n\t\n\t\t\t\t\t</td>\n\t\t\t\t",
    "320": "<td> \t\t\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">X. Yi</a>,  \n\t\t\t\t\t\t<a href=\"https://calciferzh.github.io/\" target=\"_blank\">Y. Zhou</a>,  \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/\" target=\"_blank\">M. Habermann</a>,\t\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~sshimada/\" target=\"_blank\">S. Shimada</a>, \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>,\n\t\t\t\t\t\tand \n\t\t\t\t\t\t<a href=\"http://xufeng.site/\" target=\"_blank\">F. Xu</a> <br/>            \n\t\t\t\t\t\t<i>Physical Inertial Poser (PIP): Physics-aware Real-time Human Motion Tracking from Sparse Inertial Sensors</i><br/>\n\t\t\t\t\t\t Computer Vision and Pattern Recognition (CVPR), 2022 (best paper finalist) <br/>\n\t\t\t\t\t\t<a href=\"https://xinyu-yi.github.io/PIP/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2203.08528\">[paper]</a>   \n\t\t\t\t\t\t<a href=\"https://xinyu-yi.github.io/PIP/videos/PIP.mp4\">[video]</a>  \n\t\t\t\t\t</td>\n\t\t\t\t",
    "319": "<td>\n\t\t\t\t\t\t\t<a href=\"\">H. Chen</a>,\t\t\t\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~tretschk/\">E. Tretschk</a>,\n\t\t\t\t\t\t\t<a href=\"\" target=\"_blank\">T. Stuyck</a>,\n\t\t\t\t\t\t\t<a href=\"\">L. Kavan</a>,\n\t\t\t\t\t\t\t<a href=\"\">E. Vouga</a> and\n\t\t\t\t\t\t\t<a href=\"\">C. Lassner</a>\n\t\t\t\t\t\t<br/>                               \n\t\t\t\t\t\t<i>VEOs: Virtual Elastic Objects</i><br/>\n\t\t\t\t\t\t  Computer Vision and Pattern Recognition (CVPR), 2022 <br/>\n\t\t\t\t\t\t<a href=\"https://hsiaoyu.github.io/VEO/\">[project page]</a> \n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2201.04623\">[paper]</a> \n\t\t\t\t\t\t<a href=\"https://github.com/facebookresearch/plush_dataset\">[dataset]</a> \n\t\t\t\t\t\t\n\t\t\t\t\t</td>\n\t\t\t\t",
    "318": "<td>\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jianwang/\">J. Wang</a>,\t\t\t\n\t\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>,\n\t\t\t\t\t\t\t<a href=\"https://sites.google.com/view/xuweipeng \" target=\"_blank\">W. Xu</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~ksarkar/\">K. Sarkar</a>,\n\t\t\t\t\t\t\t<a href=\"https://dluvizon.github.io/\">D. Luvizon</a> and\n\t\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t<br/>                               \n\t\t\t\t\t\t<i>Estimating Egocentric 3D Human Pose in the Wild with External Weak Supervision</i><br/>\n\t\t\t\t\t\t  Computer Vision and Pattern Recognition (CVPR), 2022 <br/>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jianwang/projects/egopw/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jianwang/projects/egopw/data/egopw.pdf\">[paper]</a>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jianwang/projects/egopw/data/supp_mat.pdf\">[supplementary]</a>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jianwang/projects/egopw/data/camera_ready.mp4\">[video]</a>\n\t\t\t\t\t\t<a href=\"https://nextcloud.mpi-klsb.mpg.de/index.php/s/5yikSw26sXy3wrR\">[dataset]</a> \n\t\t\t\t\t</td>\n\t\t\t\t",
    "317": "<td> \t\t\n\t\t\t\t\t\t<a href=\"https://www.willimenapace.com/\" target=\"_blank\">W. Menapace</a>,  \n\t\t\t\t\t\t<a href=\"https://stelat.eu/\" target=\"_blank\">S. Lathuili&#232;re</a>,  \n\t\t\t\t\t\t<a href=\"https://github.com/AliaksandrSiarohin\" target=\"_blank\">A. Siarohin</a>,\t\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>,\n\t\t\t\t\t\t<a href=\"http://www.stulyakov.com/\" target=\"_blank\">S. Tulyakov</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik</a>\n\t\t\t\t\t\tand \n\t\t\t\t\t\t<a href=\"http://elisaricci.eu/\" target=\"_blank\">E. Ricci</a> <br/>            \n\t\t\t\t\t\t<i>Playable Environments: Video Manipulation in Space and Time</i><br/>\n\t\t\t\t\t\t Computer Vision and Pattern Recognition (CVPR), 2022 <br/>\n\t\t\t\t\t\t<a href=\"https://willi-menapace.github.io/playable-environments-website/style_manipulation.html\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2203.01914\">[paper]</a>   \n\t\t\t\t\t\t<a href=\"https://willi-menapace.github.io/playable-environments-website/supplementary.pdf\">[supplementary]</a> \n\t\t\t\t\t\t<a href=\"https://github.com/willi-menapace/PlayableEnvironments\">[code]</a>   \n\t\t\t\t\t</td>\n\t\t\t\t",
    "316": "<td> \t\t\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~nkairand/\" target=\"_blank\">N. Kairanda</a>,  \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~tretschk/\" target=\"_blank\">E. Tretschk</a>,  \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a>,\t\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik</a><br/>            \n\t\t\t\t\t\t<i>&#966;-SfT: Shape-from-Template with a Physics-Based Deformation Model</i><br/>\n\t\t\t\t\t\t Computer Vision and Pattern Recognition (CVPR), 2022 <br/>\n\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/phi-SfT/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/phi-SfT/data/paper.pdf\">[paper]</a>     \n\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/phi-SfT/data/phi-SfT-supplement.pdf\">[supplementary]</a>\n\t\t\t\t\t\t<a href=\"https://drive.google.com/drive/folders/1gpzp5k64S6TnDbl8ZW8lgSmDE_nzHdh9\">[dataset]</a> \n\t\t\t\t\t</td>\n\t\t\t\t",
    "315": "<td>\n\t\t\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/people/Bhatnagar.html\" target=\"_blank\">B.L. Bhatnagar</a>,\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">X. Xie</a>, \n\t\t\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/people/Petrov.html\" target=\"_blank\">I. Petrov</a>,\n\t\t\t\t\t\t<a href=\"https://research.google/people/CristianSminchisescu/\" target=\"_blank\">C. Sminchisescu</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and \n\t\t\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/people/pons-moll.html\">G. Pons-Moll</a>\n\t\t\t\t\t\t<br/>                               \n\t\t\t\t\t\t<i>BEHAVE: Dataset and Method for Tracking Human Object Interactions</i><br/>\n\t\t\t\t\t\t  Computer Vision and Pattern Recognition (CVPR), 2022 <br/>\n\t\t\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/behave/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/papers/bhatnagar22behave/behave.pdf\">[paper]</a> \n\t\t\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/papers/bhatnagar22behave/behave_supplementary.pdf\">[supplementary]</a> \n\t\n\t\t\t\t\t</td>\n\t\t\t\t",
    "314": "<td>\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">Y. Sun</a>,\n\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\" target=\"_blank\">A. Kortylewski</a> and \n\t\t\t\t\t\t<a href=\"\">A. Yuille</a>  \n\t\t\t\t\t\t<br/>                               \n\t\t\t\t\t\t<i>Amodal Segmentation through Out-of-Task and Out-of-Distribution Generalization with a Bayesian Model</i><br/>\n\t\t\t\t\t\t  Computer Vision and Pattern Recognition (CVPR), 2022 (Oral)<br/> \n\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2010.13175.pdf\">[paper]</a> \n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2010.13175\">[arXiv]</a> \n\t\t\t\t\t\t<a href=\"https://github.com/YihongSun/Bayesian-Amodal\">[code]</a> \n\t\n\t\t\t\t\t</td>\n\t\t\t\t",
    "313": "<td>\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">Q. Liu</a>,\n\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\" target=\"_blank\">A. Kortylewski</a>, \n\t\t\t\t\t\t \n\t\t\t\t\t\t<a href=\"\">Z. Zhang</a>,\n\t\t\t\t\t\t<a href=\"\">Z. Li</a>,\n\t\t\t\t\t\t<a href=\"\">M. Guo</a>,\n\t\t\t\t\t\t<a href=\"\">Q. Liu</a>,\n\t\t\t\t\t\t<a href=\"\">X. Yuan</a>,\n\t\t\t\t\t\t<a href=\"\">J. Mu</a>,\n\t\t\t\t\t\t<a href=\"\">W. Qiu</a> and \n\t\t\t\t\t\t<a href=\"\">A. Yuille</a>  \n\t\t\t\t\t\t<br/>                               \n\t\t\t\t\t\t<i>Learning Part Segmentation through Unsupervised Domain Adaptation from Synthetic Vehicles</i><br/>\n\t\t\t\t\t\t  Computer Vision and Pattern Recognition (CVPR), 2022 (Oral)<br/> \n\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2103.14098.pdf\">[paper]</a> \n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2103.14098\">[arXiv]</a> \n\t\t\t\t\t\t<a href=\"https://github.com/qliu24/udapart/blob/gh-pages/index.md\">[dataset]</a> \n\t\n\t\t\t\t\t</td>\n\t\t\t\t",
    "312": "<td>\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">N. Ruiz</a>,\n\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\" target=\"_blank\">A. Kortylewski</a>,\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">W. Qiu</a>, \n\t\t\t\t\t\t<a href=\"\">C. Xie</a>,\n\t\t\t\t\t\t<a href=\"\">S.A. Bargal</a>,\n\t\t\t\t\t\t<a href=\"\">A. Yuille</a> and \n\t\t\t\t\t\t<a href=\"\">S. Sclaroff</a> \n\t\t\t\t\t\t<br/>                               \n\t\t\t\t\t\t<i>Simulated Adversarial Testing of Face Recognition Models</i><br/>\n\t\t\t\t\t\t  Computer Vision and Pattern Recognition (CVPR), 2022 <br/> \n\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2106.04569.pdf\">[paper]</a> \n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2106.04569\">[arXiv]</a> \n\t\n\t\t\t\t\t</td>\n\t\t\t\t",
    "311": "<td>\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">V. Gupta</a>,\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">Z. Li</a>,\n\t\t\t\t\t\t<a href=\"https://generativevision.mpi-inf.mpg.de/\" target=\"_blank\">A. Kortylewski</a>,\n\t\t\t\t\t\t<a href=\"\">C. Zhang</a>,\n\t\t\t\t\t\t<a href=\"\">Y. Li</a> and \n\t\t\t\t\t\t<a href=\"\">A. Yuille</a> \n\t\t\t\t\t\t<br/>                               \n\t\t\t\t\t\t<i>SwapMix: Diagnosing and Regularizing the Over-reliance on Visual Context in Visual Question Answering</i><br/>\n\t\t\t\t\t\t  Computer Vision and Pattern Recognition (CVPR), 2022 <br/> \n\t\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2204.02285.pdf\">[paper]</a> \n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/2204.02285\">[arXiv]</a> \n\t\n\t\t\t\t\t</td>\n\t\t\t\t",
    "310": "<td> \t\t\n\t\t\t\t\t\t\t<a href=\"http://jiataogu.me/\" target=\"_blank\">J. Gu</a>, \n\t\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/#home\" target=\"_blank\">L. Liu</a>, \n\t\t\t\t\t\t\t<a href=\"https://totoro97.github.io/about.html\" target=\"_blank\">P. Wang</a> and\n\t\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>  \n\t\t\t\t\t\t<br/>                               \n\t\t\t\t\t\t<i>StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis</i><br/>\n\t\t\t\t\t\tInternational Conference on Learning Representations (ICLR), 2022 <br/>\n\t\t\t\t\t\t<a href=\"http://jiataogu.me/style_nerf/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"http://jiataogu.me/style_nerf/files/StyleNeRF.pdf\">[paper]</a>   \n\t\t\t\t\t</td>\n\t\t\t\t",
    "309": "<td width=\"130\">\n\t\t\t\t\t</td>\n\t\t\t\t",
    "308": "<td> \t\t\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~ihabibie/\" target=\"_blank\">H. Ikhsanul</a>,  \n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">W. Xu</a>, \n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">D. Mehta</a>, \n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\" target=\"_blank\">L. Liu</a>, \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H.P. Seidel</a>, \n\t\t\t\t\t\t<a href=\"https://virtualhumans.mpi-inf.mpg.de/people/pons-moll.html\" target=\"_blank\">G. P. Moll</a>,\t\t\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a> and \t\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> <br/>            \n\t\t\t\t\t\t<i>Learning Speech-driven 3D Conversational\n\t\t\t\t\t\t\tGestures from Video</i><br/>\n\t\t\t\t\t\t\tACM International Conference on Intelligent Virtual Agents (IVA), 2021 (best paper)<br/>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/3d_speech_driven_gesture/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/3d_speech_driven_gesture/data/paper.pdf\">[paper]</a>   \n\t\t\t\t\t\t<a href=\"https://nextcloud.mpi-klsb.mpg.de/index.php/s/7LzxGSepzrndg2x\">[dataset]</a>   \n\t\t\t\t\t</td>\n\t\t\t\t",
    "307": "<td> \t\t\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">J. Malik</a>,  \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~sshimada/\" target=\"_blank\">S. Shimada</a>, \n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">A. Elhayek</a>, \n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">S. A. Ali</a>, \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik</a>,\t\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and \n\t\t\t\t\t\t<a href=\"https://av.dfki.de/members/stricker/\">D. Stricker</a> \t\t\t\t\t<br/>            \n\t\t\t\t\t\t<i>HandVoxNet++: 3D Hand Shape and Pose Estimation using Voxel-Based Neural Networks</i><br/>\n\t\t\t\t\t\tIEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2021 <br/>\n\t\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/HandVoxNet++/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://ieeexplore.ieee.org/document/9599544\">[paper]</a>   \n\t\t\t\t\t</td>\n\t\t\t\t",
    "306": "<td> \t\t\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/#home\" target=\"_blank\">L. Liu</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/\" target=\"_blank\">M. Habermann</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~vrudnev/\" target=\"_blank\">V. Rudnev</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~ksarkar//\">K. Sarkar</a>,\n\t\t\t\t\t\t<a href=\"http://jiataogu.me/\">J. Gu</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>  \n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control</i><br/>\n\t\t\t\t\t   ACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2021)<br/>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/NeuralActor/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/abs/2106.02019\">[paper]</a>  \n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/NeuralActor/mp4/main_video_arxiv3.mp4\">[video]</a>  \n\t\t\t\t</td>\n\t\t\t\t",
    "305": "<td>\n\t\t\t\t\t\t<a href=\"https://totoro97.github.io/about.html\">P. Wang</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/#home\" target=\"_blank\">L. Liu</a>,\n\t\t\t\t\t\t<a href=\"https://liuyuan-pal.github.io/\" target=\"_blank\">Y. Liu</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>,\n\t\t\t\t\t\t<a href=\"https://www.cs.hku.hk/index.php/people/academic-staff/taku\" target=\"_blank\">T. Komura</a> and\n\t\t\t\t\t\t<a href=\"https://www.cs.hku.hk/people/academic-staff/wenping\" target=\"_blank\">W. Wang</a> \n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction</i><br/>\n\t\t\t\t\t  Advances in Neural Information Processing Systems (NeurIPS), 2021 (Spotlight)<br/>\n\t\t\t\t\t<a href=\"https://lingjie0206.github.io/papers/NeuS/index.htm\">[project page]</a>\n\t\t\t\t\t<a href=\"https://lingjie0206.github.io/papers/NeuS/paper.pdf\">[paper]</a>  \n\t\t\t\t\t<a href=\"https://github.com/Totoro97/NeuS\">[code]</a>  \n\t\t\t\t</td>\n\t\t\t\t",
    "304": "<td>\n\t\t\t\t\t\t<a href=\"https://xingangpan.github.io/\">X. Pan</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"https://sheldontsui.github.io/\" target=\"_blank\">X. Xu</a>,\n\t\t\t\t\t\t<a href=\"http://personal.ie.cuhk.edu.hk/~ccloy/\" target=\"_blank\">C.C. Loy</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"http://daibo.info/\" target=\"_blank\">B. Dai</a> \n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>A Shading-Guided Generative Implicit Model for Shape-Accurate 3D-Aware Image Synthesis</i><br/>\n\t\t\t\t\t  Advances in Neural Information Processing Systems (NeurIPS), 2021 <br/>\n\t\t\t\t\t<a href=\"https://xingangpan.github.io/projects/ShadeGAN.html\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/abs/2110.15678\">[paper]</a>  \n\t\t\t\t\t<a href=\"https://github.com/XingangPan/ShadeGAN\">[code]</a>  \n\t\t\t\t</td>\n\t\t\t\t",
    "303": "<td>\n\t\t\t\t\t\t\t<a href=\"https://charliememory.github.io/\">L. Ma</a>,\t\t\t\n\t\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/#home\" target=\"_blank\">L. Liu</a>, \n\t\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>  and\n\t\t\t\t\t\t\t<a href=\"https://people.ee.ethz.ch/~vangool/\">L.V. Gool</a>\n\t\t\t\t\t\t<br/>                               \n\t\t\t\t\t\t<i>Direct Dense Pose Estimation</i><br/>\n\t\t\t\t\t\t  International Conference on 3D Vision (3DV), 2021<br/> \n\t\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/DirectDensePose/paper.pdf\">[paper]</a>  \n\t\t\t\t\t</td>\n\t\t\t\t",
    "302": "<td>\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~ksarkar//\">Y. Li</a>,\t\t\t\n\t\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mhaberma/\" target=\"_blank\">M.  Habermann</a>,\n\t\t\t\t\t\t\t<a href=\"hhttps://n.ethz.ch/~bthomasz/\" target=\"_blank\">B. Thomaszewski</a>,\n\t\t\t\t\t\t\t<a href=\"http://crl.ethz.ch/people/coros/index.html\" target=\"_blank\">S. Coros</a>,\n\t\t\t\t\t\t\t<a href=\"https://thabobeeler.com/\" target=\"_blank\">T. Beeler</a>  and\n\t\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t<br/>                               \n\t\t\t\t\t\t<i>Deep Physics-aware Inference of Cloth Deformation for Monocular Human Performance Capture</i><br/>\n\t\t\t\t\t\t  International Conference on 3D Vision (3DV), 2021<br/>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2021-deepphyscloth/\">[project page]</a>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2021-deepphyscloth/data/paper.pdf\">[paper]</a>  \n\t\t\t\t\t</td>\n\t\t\t\t",
    "301": "<td>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~ksarkar//\">K. Sarkar</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/#home\" target=\"_blank\">L. Liu</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>HumanGAN: A Generative Model of Human Images</i><br/>\n\t\t\t\t\t  International Conference on 3D Vision (3DV), 2021 (Oral)<br/>\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~ksarkar/humangan/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2103.06902.pdf\">[paper]</a>  \n\t\t\t\t</td>\n\t\t\t\t",
    "300": "<td>\n\t\t\t\t\t\t<a href=\"https://abdallahdib.github.io/\">A. Dib</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">C. Th&#233;bault</a>,\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">J. Ahn</a>,\n\t\t\t\t\t\t<a href=\"https://scholar.google.fr/citations?user=uSpXQckAAAAJ&amp;hl=en\" target=\"_blank\">P-H. Gosselin</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"https://scholar.google.fr/citations?hl=ja&amp;user=hC_BTU8AAAAJ&amp;view_op=list_works&amp;sortby=pubdate\" target=\"_blank\">L. Chevallier</a>  \n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>Towards High Fidelity Monocular Face Reconstruction with Rich Reflectance using Self-supervised Learning and Ray Tracing</i><br/>\n\t\t\t\t\t  International Conference on Computer Vision (ICCV), 2021<br/> \n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2103.15432.pdf\">[paper]</a>  \n\t\t\t\t</td>\n\t\t\t\t",
    "299": "<td>\n\t\t\t\t\t\t<a href=\"https://www.dfki.de/web/ueber-uns/mitarbeiter/person/angh01/\">A. Ghosh</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~ncheema/\" target=\"_blank\">N. Cheema</a>,\n\t\t\t\t\t\t<a href=\"https://www.dfki.de/web/ueber-uns/mitarbeiter/person/ceog01/\" target=\"_blank\">C. Oguz</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"https://www.dfki.de/web/ueber-uns/mitarbeiter/person/phsl01/\" target=\"_blank\">P. Slusallek</a>  \n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>Synthesis of Compositional Animations from Textual Descriptions</i><br/>\n\t\t\t\t\t  International Conference on Computer Vision (ICCV), 2021<br/>\n\t\t\t\t\t<a href=\"https://www.dfki.de/web/forschung/projekte-publikationen/publikationen-filter/publikation/11782\">[project page]</a>\n\t\t\t\t\t<a href=\"https://openaccess.thecvf.com/content/ICCV2021/papers/Ghosh_Synthesis_of_Compositional_Animations_From_Textual_Descriptions_ICCV_2021_paper.pdf\">[paper]</a>  \n\t\t\t\t</td>\n\t\t\t\t",
    "298": "<td>\n\t\t\t\t\t\t<a href=\"https://www.cse.iitb.ac.in/~rdabral/\">R. Dabral</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~sshimada/\" target=\"_blank\">S. Shimada</a>,\n\t\t\t\t\t\t<a href=\"https://arjunjain.co.in/\" target=\"_blank\">A. Jain</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik</a>  \n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>Gravity-Aware Monocular 3D Human-Object Reconstruction</i><br/>\n\t\t\t\t\t  International Conference on Computer Vision (ICCV), 2021<br/>\n\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/GraviCap/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2108.08844.pdf\">[paper]</a> \n\t\t\t\t\t<a href=\"https://github.com/rishabhdabral/gravicap\">[code]</a>\n\t\t\t\t\t<a href=\"https://drive.google.com/file/d/1qkcoWot9V4ydFTvilaLo5ahAW-fslnQQ/view\">[dataset]</a>\n\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/GraviCap/data/GraviCap.mp4\">[video]</a> \n\t\t\t\t</td>\n\t\t\t\t",
    "297": "<td>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~vrudnev/\">V. Rudnev</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jwang/\" target=\"_blank\">J. Wang</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H-P. Seidel</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~frmueller/\" target=\"_blank\">F. Mueller</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a>  and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>EventHands: Real-Time Neural 3D Hand Reconstruction from an Event Stream</i><br/>\n\t\t\t\t\t  International Conference on Computer Vision (ICCV), 2021<br/>\n\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/EventHands/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2012.06475.pdf\">[paper]</a> \n\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/EventHands/data/video.mp4\">[video]</a> \n\t\t\t\t</td>\n\t\t\t\t",
    "296": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~tretschk/\">E. Tretschk</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~atewari/\">A. Tewari</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik</a>,\n\t\t\t\t\t\t<a href=\"http://zollhoefer.com/\" target=\"_blank\">M. Zollhoefer</a>,\n\t\t\t\t\t\t<a href=\"https://christophlassner.de/\" target=\"_blank\">C. Lassner</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>Non-Rigid Neural Radiance Fields: Reconstruction and Novel View Synthesis of a Dynamic Scene From Monocular Video</i><br/>\n\t\t\t\t\t  International Conference on Computer Vision (ICCV), 2021<br/>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/nonrigid_nerf/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/abs/2012.12247\">[paper]</a> \n\t\t\t\t\t<a href=\"https://github.com/facebookresearch/nonrigid_nerf\">[code]</a> \n\t\t\t\t</td>\n\t\t\t\t",
    "295": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~llyu/\">L. Lyu</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\" target=\"_blank\"> L. Liu</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mbr/\" target=\"_blank\">M. B R</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>Efficient and Differentiable Shadow Computation for Inverse Problems</i><br/>\n\t\t\t\t\t  International Conference on Computer Vision (ICCV), 2021<br/>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/DifferentiableShadows/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2105.02878.pdf\">[paper]</a> \n\n\t\t\t\t</td>\n\t\t\t\t",
    "294": "<td>\n\t\t\t\t\t\t<a href=\"https://www.vsa.informatik.uni-siegen.de/en/seelbach-marcel\">M. S. Benkner</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"https://zorah.github.io/\">Z. L&#195;&#164;hner</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik</a>,\n\t\t\t\t\t\t<a href=\"https://www.physik.uni-siegen.de/quantenoptik/arbeitsgruppe/cwunderlich/index.html.en?lang=en\" target=\"_blank\">C. Wunderlich</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"https://sites.google.com/site/michaelmoellermath/\">M. Moeller</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>Q-Match: Iterative Shape Matching via Quantum Annealing</i><br/>\n\t\t\t\t\t  International Conference on Computer Vision (ICCV), 2021<br/>\n\t\t\t\t\t<a href=\"https://4dqv.mpi-inf.mpg.de/QMATCH/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2105.02878.pdf\">[paper]</a> \n\n\t\t\t\t</td>\n\t\t\t\t",
    "293": "<td>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jianwang/\">J. Wang</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>,\n\t\t\t\t\t\t<a href=\"https://sites.google.com/view/xuweipeng \" target=\"_blank\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~ksarkar/\">K. Sarkar</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>Estimating Egocentric 3D Human Pose in Global Space</i><br/>\n\t\t\t\t\t  International Conference on Computer Vision (ICCV), 2021 (Oral)<br/>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/globalegomocap/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/globalegomocap/data/global_egomocap.pdf\">[paper]</a>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/globalegomocap/data/global_egomocap.mp4\">[video]</a>\n\n\t\t\t\t</td>\n\t\t\t\t",
    "292": "<td>\n\t\t\t\t\t\t<a href=\" \">T. Hu</a>,\t\t\t \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~ksarkar/\" target=\"_blank\">K. Sarkar</a>,\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/#home\" target=\"_blank\">L. Liu</a>,\n\t\t\t\t\t\t<a href=\"https://www.cs.umd.edu/~zwicker/\">M. Zwicker</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t \n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>EgoRenderer: Rendering Human Avatars from Egocentric Camera Images</i><br/>\n\t\t\t\t\t  International Conference on Computer Vision (ICCV), 2021<br/>\n\t\t\t\t\t<a href=\" \">[project page coming soon]</a>\n\t\t\t\t\t<a href=\"\">[paper  coming soon]</a>  \n\t\t\t\t</td>\n\t\t\t\t",
    "291": "<td>\n\t\t\t\t\t\t<a href=\"https://www.xxlong.site/\">X. Long</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"https://clinplayer.github.io/\">C. Lin</a>,\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/#home\" target=\"_blank\">L. Liu</a>,\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">W. Li</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>,\n\t\t\t\t\t\t<a href=\"https://www.engr.uky.edu/directory/yang-ruigang\">R. Yang</a> and\n\t\t\t\t\t\t<a href=\"https://www.cs.hku.hk/people/academic-staff/wenping\" target=\"_blank\">W. Wang</a>\n\t\t\t\t\t\t \n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>Adaptive Surface Normal Constraint for Depth Estimation</i><br/>\n\t\t\t\t\t  International Conference on Computer Vision (ICCV), 2021<br/>\n\t\t\t\t\t<a href=\" \">[project page coming soon]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/abs/2103.15483\">[paper]</a>  \n\t\t\t\t</td>\n\t\t\t\t",
    "290": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~gfox/\">G. Fox </a>,\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~atewari/\">A. Tewari</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/gerard-pons-moll/\">G. Pons-Moll</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>StyleVideoGAN: A Temporal Generative Model using a Pretrained StyleGAN</i><br/>\n\t\t\t\t\t     British Mashine Vision conference (BMVC), 2021<br/>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/stylevideogan/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://www.bmvc2021-virtualconference.com/assets/papers/0872.pdf\">[paper]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2107.07224.pdf\">[arXiv]</a>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/stylevideogan/data/video_clean.mp4\">[video]</a>\n\t\t\t\t</td>\n\t\t\t\t",
    "289": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"https://sites.google.com/view/xuweipeng\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"https://zollhoefer.com/ \" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/gerard-pons-moll/\">G. Pons-Moll</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>A Deeper Look into DeepCap</i><br/>\n\t\t\t\t\t  IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) <br/>\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2021-tpami-deeperdeepcap/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2021-tpami-deeperdeepcap/data/paper.pdf\">[paper]</a>\n\t\t\t\t\t<a href=\"https://gvv-assets.mpi-inf.mpg.de/\">[dataset]</a>\n\n\t\t\t\t</td>\n\t\t\t\t",
    "288": "<td>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~sshimada/\">S. Shimada</a>,\t\t \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>,\n\t\t\t\t\t\t<a href=\"https://sites.google.com/view/xuweipeng\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"https://ptrckprz.github.io/\" target=\"_blank\">P. P&#233;rez</a>, and\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>  <br/>\n\t\t\t\t<i>Neural Monocular 3D Human Motion Capture with Physical Awareness</i> <br/>\n\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH 2021) <br/> \n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/PhysAware/\">[project page]</a> \n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/PhysAware/data/PhysAware.pdf\">[paper]</a> \n\t\t\t\t<a href=\"https://arxiv.org/abs/2105.01057\">[arXiv]</a>\n\n\t\t\t\t</td>  \n\t\t\t\t",
    "287": "<td>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mchu/\">M. Chu</a>,\t\t \n\t\t\t\t\t\t<a href=\"https://ge.in.tum.de/about/n-thuerey/\">N. Thuerey</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H-P. Seidel</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~rzayer/\">R. Zayer</a>  <br/>\n\t\t\t\t<i>Learning Meaningful Controls for Fluids</i> <br/>\n\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH 2021) <br/> \n\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mchu/gvv-den2vel/den2vel.html\">[project page]</a> \n\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mchu/gvv-den2vel/data/paper.pdf\">[paper]</a> \n\t\t\t\t<a href=\"https://github.com/RachelCmy/den2vel\">[code]</a>\n\n\t\t\t\t</td>  \n\t\t\t\t",
    "286": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>,\n\t\t\t\t\t\t<a href=\"https://sites.google.com/view/xuweipeng\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"https://zollhoefer.com/ \" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/gerard-pons-moll/\">G. Pons-Moll</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>Real-time Deep Dynamic Characters</i> <br/>\n\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH 2021) <br/> \n\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2021-ddc/\">[project page]</a> \n\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2021-ddc/data/paper.pdf\">[paper]</a> \n\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2021-ddc/data/video.mp4\">[video]</a>\n\n\t\t\t\t</td>  \n\t\t\t\t",
    "285": "<td>\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mbr/\" target=\"_blank\">M. B R</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a>,\n\t\t\t\t\t\t\t<a href=\"https://www.interdigital.com/talent/?id=38\" target=\"_blank\">A. Dib</a>,\n\t\t\t\t\t\t\t<a href=\"http://reality.cs.ucl.ac.uk/weyrich.html\" target=\"_blank\">T. Weyrich</a>,\n\t\t\t\t\t\t\t<a href=\"http://berndbickel.com/\" target=\"_blank\">B. Bickel</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H-P. Seidel</a> \n\t\t\t\t\t\t\t<a href=\"https://vcg.seas.harvard.edu/people/hanspeter-pfister\" target=\"_blank\">H. Pfister</a>,\n\t\t\t\t\t\t\t<a href=\"https://cdfg.csail.mit.edu/wojciech\" target=\"_blank\">W. Matusik</a>,\n\t\t\t\t\t\t\t<a href=\"https://scholar.google.fr/citations?user=hC_BTU8AAAAJ&amp;hl=en\" target=\"_blank\">L. Chevalier</a>, \n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a> and\n\t\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a><br/>\n\n\t\t\t\t\t\t\t<i> PhotoApp: Photorealistic Appearance Editing of Head Portraits </i> <br/>\n\t\t\t\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH 2021)<br/> \t\n\t\t\t\t\t\t\t\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/PhotoApp/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/PhotoApp/data/paper.pdf\">[paper]</a>\n\t\t\t\t\t</td>  \n\t\t\t\t",
    "284": "<td>\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mbr/\" target=\"_blank\">M. B R</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a>,\n\t\t\t\t\t\t\t<a href=\"https://scholar.google.com/citations?user=dMCBjeIAAAAJ&amp;hl=en\" target=\"_blank\">T-H. Oh</a>,\n\t\t\t\t\t\t\t<a href=\"https://reality.cs.ucl.ac.uk/weyrich.html\" target=\"_blank\">T. Weyrich</a>,\n\t\t\t\t\t\t\t<a href=\"https://berndbickel.com/\" target=\"_blank\">B. Bickel</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H-P. Seidel</a>,\n\t\t\t\t\t\t\t<a href=\"https://vcg.seas.harvard.edu/people/hanspeter-pfister\" target=\"_blank\">H. Pfister</a>,\n\t\t\t\t\t\t\t<a href=\"https://cdfg.csail.mit.edu/wojciech\" target=\"_blank\">W. Matusik</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a> and\n\t\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a><br/>\n\n\t\t\t\t\t\t\t<i>  Monocular Reconstruction of Neural Face Reflectance Fields  </i> <br/>\n\t\t\t\t\t\t\t\t Computer Vision and Pattern Recognition (CVPR), 2021<br/> \t\n\t\t\t\t\t\t\t\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/FaceReflectanceFields/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/FaceReflectanceFields/data/paper.pdf\">[paper]</a>\n\t\t\t\t\t</td>  \n\t\t\t\t",
    "283": "<td>\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mbr/\" target=\"_blank\">M. B R</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H-P. Seidel</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a> and\n\t\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a><br/>\n\n\t\t\t\t\t\t\t<i>  Learning Complete 3D Morphable Face Models from Images and Videos  </i> <br/>\n\t\t\t\t\t\t\t\t Computer Vision and Pattern Recognition (CVPR), 2021<br/> \t\n\t\t\t\t\t\t\t\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/LeMoMo/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/LeMoMo/data/paper.pdf\">[paper]</a>\n\t\t\t\t\t</td>  \n\t\t\t\t",
    "282": "<td>\n\t\t\t\t\t\t\t<a href=\"https://calciferzh.github.io/\" target=\"_blank\">Y. Zhou</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/\" target=\"_blank\">M. Habermann</a>,\n\t\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/~ihabibie/\" target=\"_blank\">I. Habibie</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~atewari/\" target=\"_blank\"> A. Tewari</a>,\n\t\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t\t\t<a href=\"http://cgcad.thss.tsinghua.edu.cn/xufeng/\" target=\"_blank\">F. Xu</a><br/>\n\n\t\t\t\t\t\t\t<i>  Monocular Real-time Full Body Capture with Inter-part Correlations  </i> <br/>\n\t\t\t\t\t\t\t\t Computer Vision and Pattern Recognition (CVPR), 2021<br/> \t\n\t\t\t\t\t\t\t\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2021-cvpr-full-body-capture/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2021-cvpr-full-body-capture/data/main.pdf\">[paper]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/abs/2012.06087\">[arXiv]</a>\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/projects/2021-cvpr-full-body-capture/data/supp.pdf\">[supplementary]</a>\n\t\t\t\t\t<a href=\"https://www.youtube.com/embed/pAcywTUTv-E\">[video]</a>\n\t\t\t\t\t</td>  \n\t\t\t\t",
    "281": "<td>\n\t\t\t\t\t\t\t<a href=\"http://tbirdal.me/\" target=\"_blank\">T. Birdal*</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik*</a>,\n\t\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t\t\t<a href=\"https://geometry.stanford.edu/member/guibas/\" target=\"_blank\">L. Guibas</a><br/>\n\n\t\t\t\t\t\t\t<i>  Quantum Permutation Synchronization  </i> <br/>\n\t\t\t\t\t\t\t\t(* denotes equal contribution)<br/>\n\t\t\t\t\t\t\t\t Computer Vision and Pattern Recognition (CVPR), 2021<br/> \t\n\t\t\t\t\t\t\t\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/QUANTUMSYNC/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/QUANTUMSYNC/data/QuantumSync_CVPR2021.pdf\">[paper]</a>\n\t\t\t\t\t</td>  \n\t\t\t\t",
    "280": "<td>\n\t\t\t\t\t\t\t<a href=\"https://graphics.tu-bs.de/people/kappel\" target=\"_blank\">M. Kappel</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a>,\n\t\t\t\t\t\t\t<a href=\"https://graphics.tu-bs.de/people/henningson\" target=\"_blank\">J-O. Henningson</a>,\n\t\t\t\t\t\t\t<br/>\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H-P. Seidel</a>,\n\t\t\t\t\t\t\t<a href=\"https://graphics.tu-bs.de/people/castillo\" target=\"_blank\">S. Castillo</a>,\n\t\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t\t\t<a href=\"https://graphics.tu-bs.de/people/magnor\" target=\"_blank\">M. Magnor</a><br/>\n\n\t\t\t\t\t\t\t<i>  High-Fidelity Neural Human Motion Transfer from Monocular Video  </i> <br/>\n\t\t\t\t\t\t\t\t Computer Vision and Pattern Recognition (CVPR), 2021 (Oral)<br/> \t\n\t\t\t\t\t\t\t\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/NHMT/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2012.10974.pdf\">[paper]</a>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/NHMT/data/video.mp4\">[video]</a>\n\t\t\t\t\t</td>  \n\t\t\t\t",
    "279": "<td>\n\t\t\t\t\t\t\t<a href=\"https://www-users.cs.umn.edu/~jsyoon/\" target=\"_blank\">J. S. Yoon</a>,\n\t\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\" target=\"_blank\">L. Liu</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~ksarkar/\" target=\"_blank\">K. Sarkar</a>,\n\t\t\t\t\t\t\t<a href=\"https://www-users.cs.umn.edu/~hspark/\" target=\"_blank\">H. S. Park</a> and\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a><br/>\n\n\t\t\t\t\t\t\t<i>  Pose-Guided Human Animation from a Single Image in the Wild  </i> <br/>\n\t\t\t\t\t\t\t\t Computer Vision and Pattern Recognition (CVPR), 2021<br/> \t\n\t\t\t\t\t\t\t\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/PoseGuidedHumanAnimation/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2012.03796.pdf\">[paper]</a>\n\t\t\t\t\t</td>  \n\t\t\t\t",
    "278": "<td>\n\t\t\t\t\t\t\t<a href=\"https://de.linkedin.com/in/jalees-nehvi-8596a4127\" target=\"_blank\">J. Nehvi</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\" target=\"_blank\">V. Golyanik</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~frmueller/\" target=\"_blank\">F. Mueller</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H-P. Seidel</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a> and\n\t\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a><br/>\n\n\t\t\t\t\t\t\t<i>  Differentiable Event Stream Simulator for Non-Rigid 3D Tracking  </i> <br/>\n\t\t\t\t\t\t\t\t Computer Vision and Pattern Recognition Workshops (Event-based Vision Workshop), 2021<br/> \t\n\t\t\t\t\t\t\t\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/Event-based_Non-rigid_3D_Tracking/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/Event-based_Non-rigid_3D_Tracking/data/Nehvi_etal_2021.pdf\">[paper]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2104.15139.pdf\">[arXiv]</a>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/Event-based_Non-rigid_3D_Tracking/data/Nehvi_etal_2021_supp.pdf\">[supplementary]</a>\n\t\t\t\t\t</td>  \n\t\t\t\t",
    "277": "<td>\n\t\t\t\t\t\t\t<a href=\"https://vision.in.tum.de/members/yenamand\" target=\"_blank\">T. Yenamandra</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a>,\n\t\t\t\t\t\t\t<a href=\"https://sites.google.com/site/fbernardpi/\" target=\"_blank\">F. Bernard</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H-P. Seidel</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a>,\n\t\t\t\t\t\t\t<a href=\"https://vision.in.tum.de/members/cremers\" target=\"_blank\">D. Cremers</a> and\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a><br/>\n\n\t\t\t\t\t\t\t<i>  i3DMM: Deep Implicit 3D Morphable Model of Human Heads  </i> <br/>\n\t\t\t\t\t\t\t\t Computer Vision and Pattern Recognition (CVPR), 2021 (Oral)<br/> \t\n\t\t\t\t\t\t\t\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/i3DMM/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/i3DMM/data/paper.pdf\">[paper]</a>\n\t\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/i3DMM/data/video.mp4\">[video]</a>\n\t\t\t\t\t</td>  \n\t\t\t\t",
    "276": "<td>\n\t\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~gfox/\" target=\"_blank\">G. Fox</a>,\t\t\t\t\t\t\n\t\t\t\t\t\t\t<a href=\"\" target=\"_blank\">W. Liu</a>,\n\t\t\t\t\t\t\t<a href=\"\" target=\"_blank\">H. Kim</a>,\n\t\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H-P. Seidel</a>,\n\t\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a> and\n\t\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a><br/>\n\t\t\t\t\t\t\t<i>  VideoForensicsHQ: Detecting High-quality Manipulated Face Videos  </i> <br/>\n\t\t\t\t\t\t\t\tInternational Conference on Multimedia and Expo (ICME), 2021 <br/> \t\n\t\t\t\t\t\t\t\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/VForensicsHQ/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2005.10360.pdf\">[paper]</a>\n\t\t\t\t\t</td>  \n\t\t\t\t",
    "275": "<td>\n\t\t\t\t\t  <a href=\"https://www.meka.page/\" target=\"_blank\">A. Meka</a>,\n\t\t\t\t\t  <a href=\"\" target=\"_blank\">M. Shafiei</a>,\n\t\t\t\t\t  <a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&#246;fer</a>,\n\t\t\t\t\t  <a href=\"http://richardt.name/\" target=\"_blank\">C. Richardt</a> and\n\t\t\t\t\t  <a href=\"http://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a><br/>\n\t\t\t\t<i> Real-time Global Illumination Decomposition of Videos </i> <br/>\n\t\t\t\tACM Transactions on Graphics (to be presented at SIGGRAPH 2021) <br/> \t\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/LiveIlluminationDecomposition/\">[project page]</a> \n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/LiveIlluminationDecomposition/Real-Time%20Global%20Illumination%20Decomposition%20of%20Videos.pdf\">[paper]</a> \n\t\t\t\t<a href=\"https://arxiv.org/pdf/1908.01961.pdf\">[arXiv]</a> \n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/LiveIlluminationDecomposition/Real-Time%20Global%20Illumination%20Decomposition%20of%20Videos_Supplementary.pdf\">[supplementary]</a> \n\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=5ntLiAYsMm4\">[video]</a-->\n\t\t\t\t</td>  \n\t\t\t\t",
    "274": "<td width=\"130\">\n\t\t\t\t\n\t\t\t\t</td>",
    "273": "<td>\t\t\n \t\t\t\t\t<a href=\"https://virtualhumans.mpi-inf.mpg.de/people/Bhatnagar.html\">B.L. Bhatnagar</a>,\n\t\t\t\t\t<a href=\"\">C. Sminchisescu</a>, \n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> \n \t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://virtualhumans.mpi-inf.mpg.de/people/pons-moll.html\">G. Pons-Moll</a>   \n \t\t\t\t\t<br/> \n\t\t\t\t\t<i> LoopReg: Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration </i><br/> \n\t\t\t\t\tAdvances in Neural Information Processing Systems (NeurIPS), 2020 (Oral)<br/>\n\t\t\t\t\t<a href=\"https://virtualhumans.mpi-inf.mpg.de/loopreg/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://virtualhumans.mpi-inf.mpg.de/papers/bhatnagar2020loopreg/bhatnagar2020loopreg.pdf\">[paper]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/abs/2010.12447\">[arXiv]</a>\n\t\t\t\t\t<a href=\"https://virtualhumans.mpi-inf.mpg.de/papers/bhatnagar2020loopreg/bhatnagar2020loopreg_supplementary.pdf\">[supplementary]</a> \n\t\t\t\t\t<a href=\"https://github.com/bharat-b7/LoopReg\">[code]</a>\n\t\t\t\t\t<br/>\n\t\t\t\t</td>\n\t\t\t\t",
    "272": "<td>\t\t\n \n\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>, \n \t\t\t\t\t<a href=\"http://jiataogu.me/\"> J. Gu</a>,\n \t\t\t\t\t<a href=\"\">K. Z. Lin</a>,\n\t\t\t\t\t<a href=\"https://www.chuatatseng.com/\">T-S. Chua</a>\n \t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>   \n \t\t\t\t\t<br/> \n\t\t\t\t\t<i> Neural Sparse Voxel Fields </i><br/> \n\t\t\t\t\tAdvances in Neural Information Processing Systems (NeurIPS), 2020 (Spotlight)<br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/NSVF/index.htm\">[project page]</a> \n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2007.11571.pdf\">[paper]</a> \n\t\t\t\t\t<a href=\"https://www.youtube.com/watch?v=RFqPwH7QFEI&amp;list=PLCAViLbA8Ml6KXzGTENfELX8wcPiXWVT8&amp;ab_channel=ChristianTheobalt\">[video]</a>\n\t\t\t\t\t<a href=\"https://github.com/facebookresearch/NSVF\">[code &amp; data]</a>\n\t\t\t\t\t<br/>\n\t\t\t\t</td>\n\t\t\t\t",
    "271": "<td>\t\t\n \t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>, \n\t\t\t\t\t<a href=\"\">A. Jonas</a>, \n\t\t\t\t\t<a href=\"https://av.dfki.de/members/stricker/\">D. Stricker</a>\n \t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> \n \t\t\t\t\t<br/> \n\t\t\t\t\t<i>Intrinsic Dynamic Shape Prior for Dense Non-Rigid Structure from Motion </i><br/> \n\t\t\t\t\t3DV, 2020<br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DSPR/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DSPR/data/Intrinsic%20Dynamic%20Shape%20Prior%20for%20Dense%20Non-Rigid%20Structure%20from%20Motion.pdf\">[paper]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/1909.02468.pdf\">[arXiv]</a> \n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DSPR/data/DSPR_3DV2020_POSTER.pdf\">[poster]</a> \n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DSPR/data/ACTOR_MOCAP.zip\">[dataset]</a> \n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DSPR/data/DSPR_VIDEO.mp4\">[video]</a>\n\t\t\t\t\t<br/>\n\t\t\t\t</td>\n\t\t\t\t",
    "270": "<td>\t\t\n \t\t\t\t\t<a href=\"https://www.vsa.informatik.uni-siegen.de/en/seelbach-marcel\">M. S. Benker</a>,\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>, \n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> \n \t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://sites.google.com/site/michaelmoellermath/\">M. M&#246;ller</a>   \n \t\t\t\t\t<br/> \n\t\t\t\t\t<i> Adiabatic Quantum Graph Matching with Permutation Matrix Constraints </i><br/> \n\t\t\t\t\t3DV, 2020<br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/QGM/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/QGM/data/SeelbachBenkner_etal.pdf\">[paper]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/QGM/data/SeelbachBenkner_etal-supp.pdf\">[supplementary]</a> \n\t\t\t\t\t\n\t\t\t\t\t<br/>\n\t\t\t\t</td>\n\t\t\t\t",
    "269": "<td>\t\t\n \n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>, \n \t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~sshimada/\">S. Shimada</a>\n \t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>   \n \t\t\t\t\t<br/> \n\t\t\t\t\t<i> Fast Simultaneous Gravitational Alignment of Multiple Point Sets </i><br/> \n\t\t\t\t\t3DV, 2020 (Oral)<br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/MBGA/\">[project page]</a> \n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/MBGA/data/MBGA_3DV2020.pdf\">[paper]</a>\n\t\t\t\t\t<br/>\n\t\t\t\t</td>\n\t\t\t\t",
    "268": "<td>\t\t\n \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~elgharib/\">M. Elgharib</a>,\n \t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/VCAI_Projects.html\"> M. Mendiratta</a>,\n \t\t\t\t\t<a href=\"https://justusthies.github.io/\">J. Thies</a>,\n\t\t\t\t\t<a href=\"https://niessnerlab.org/members/matthias_niessner/profile.html\">M. Niessner</a>,\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\">H-P. Seidel</a>,\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~atewari/\">A. Tewari</a>,\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>\n \t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>   \n \t\t\t\t\t<br/> \n\t\t\t\t\t<i> Egocentric Videoconferencing </i><br/> \n\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2020)<br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/EgoChat/\">[project page]</a> \n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/EgoChat/data/Main.pdf\">[paper]</a> \n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/EgoChat/data/Main.mp4\">[video]</a><br/>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "267": "<td>\t\t\n \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~sshimada/\">S. Shimada</a>,\n \t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>,\n \t\t\t\t\t<a href=\"https://sites.google.com/view/xuweipeng\">W. Xu</a>\n \t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>   \n \t\t\t\t\t<br/> \n\t\t\t\t\t<i> PhysCap: Physically Plausible Monocular 3D Motion Capture in Real Time </i><br/> \n\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2020)<br/>\n\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/PhysCap/\">[project page]</a> \n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/PhysCap/data/physcap.pdf\">[paper]</a> \n\t\t\t\t\t<a href=\"https://arxiv.org/abs/2008.08880\">[arXiv]</a>  \n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/PhysCap/data/physcap.mp4\">[video]</a><br/>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "266": "<td>\t\t\n \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~atewari/\">A. Tewari</a>,\n \t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~elgharib/\">M. Elgharib</a>,\n \t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mbr/\">M. BR</a>,\n \t\t\t\t\t<a href=\"https://sites.google.com/site/fbernardpi/\">F. Bernard</a>,\n \t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\">H-P. Seidel</a>,\n \t\t\t\t\t<a href=\"https://ptrckprz.github.io/\">P. P&#233;rez</a>,\n\t\t\t\t\t<a href=\"http://www.zollhoefer.com/\">M. Zollh&#246;fer</a>\n \t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>   \n \t\t\t\t\t<br/> \n\t\t\t\t\t<i> PIE: Portrait Image Embedding for Semantic Control </i><br/> \n\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2020)<br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/PIE/\">[project page]</a> \n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/PIE/data/paper.pdf\">[paper]</a> \n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/PIE/data/supp.pdf\">[supplementary]</a> \n\t\t\t\t\t<a href=\"https://www.youtube.com/watch?v=UIvmUtVI77k\">[video]</a><br/>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "265": "<td>\t\t\n \n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jwang/\">J. Wang</a>,\n \t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~frmueller/\">F. Mueller</a>,\n \t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~fbernard/\">F. Bernard</a>,\n \t\t\t\t\t<a href=\"https://gestion2.urjc.es/pdi/ver/suzanne.sorli\">S. Sorli</a>,\n \t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~osotnych/\">O. Sotnychenko</a>,\n \t\t\t\t\t<a href=\"https://nengqian.github.io/\">N. Qian</a>,\n\t\t\t\t\t<a href=\"\">M. A. Otaduy</a>,\n \t\t\t\t\t<a href=\"https://dancasas.github.io/\">D. Casas</a>\n \t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>   \n \t\t\t\t\t<br/> \n\t\t\t\t\t<i> RGB2Hands: Real-Time Tracking of 3D Hand Interactions from Monocular RGB Video </i><br/> \n\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2020)<br/>\n\t\t\t\t\t<a href=\"https://handtracker.mpi-inf.mpg.de/projects/RGB2Hands/\">[project page]</a> \n\t\t\t\t\t<a href=\"https://handtracker.mpi-inf.mpg.de/projects/RGB2Hands/content/RGB2Hands_author_version.pdf\">[paper]</a> \n\t\t\t\t\t<a href=\"https://handtracker.mpi-inf.mpg.de/projects/RGB2Hands/content/RGB2Hands.mp4\">[video]</a>  \n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "264": "<td>\t\t\n \n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~ameka/\">A. Meka</a>,\n\t\t\t\t\t<a href=\"https://research.google/people/106687/\">R. Pandey</a>,\n\t\t\t\t\t<a href=\"https://www.google.com/\">C. Haene</a>,\n\t\t\t\t\t<a href=\"https://scholar.google.es/citations?user=dznX1DMAAAAJ&amp;hl=en\">S. Orts-Escolano</a>,\n\t\t\t\t\t<a href=\"https://www.google.com/\">P. Barnum</a>,\n\t\t\t\t\t<a href=\"https://www.google.com/\">P. Davidson</a>,\n\t\t\t\t\t<a href=\"https://www.google.com/\">D. Erickson</a>,\n\t\t\t\t\t<a href=\"https://www.google.com/\">Y. Zhang</a>,\n\t\t\t\t\t<a href=\"https://www.google.com/\">J. Taylor</a>,\n\t\t\t\t\t<a href=\"https://www.google.com/\">S. Bouaziz</a>,\n\t\t\t\t\t<a href=\"https://www.google.com/\">C. Legendre</a>,\n\t\t\t\t\t<a href=\"https://www.google.com/\">W. Ma</a>,\n\t\t\t\t\t<a href=\"https://www.google.com/\">R. Overbeck</a>,\n\t\t\t\t\t<a href=\"https://people.inf.ethz.ch/~dbeeler/\">T. Beeler</a>,\n\t\t\t\t\t<a href=\"https://www.pauldebevec.com/\">P. Debevec</a>,\n\t\t\t\t\t<a href=\"https://www.google.com/\">S. Izadi</a>,\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>,\n\t\t\t\t\t<a href=\"https://scholar.google.com/citations?user=5D0_pjcAAAAJ&amp;hl=en\">C. Rhemann</a>\n\t\t\t\t\tand\n\t\t\t\t\t<a href=\"http://www.seanfanello.it/\">S. Fanello</a>\n\n\n\t\t\t\t\t<br/> \n\t\t\t\t\t<i> Deep Relightable Textures: Volumetric Performance Capture with Neural Rendering </i><br/> \n\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2020)<br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DeepRelightableTextures/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DeepRelightableTextures/Deep_Relightable_Textures.pdf\">[paper]</a> <br/>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "263": "<td>\t\t\n \n\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>,  \n\t\t\t\t\t<a href=\"https://sites.google.com/view/xuweipeng\" target=\"_blank\">W. Xu</a>,\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\t\t\t\n\t\t\t\t\t<a href=\"http://zollhoefer.com/\" target=\"_blank\">M. Zollhoefer</a>, \n\t\t\t\t\t<a href=\"https://sites.google.com/site/fbernardpi/\" target=\"_blank\">F. Bernard</a>, \n\t\t\t\t\t<a href=\"\" target=\"_blank\">H. Kim</a>,\n\t\t\t\t\t<a href=\"https://www.cs.hku.hk/people/academic-staff/wenping\">W Wang</a> and \n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Etheobalt/\">C. Theobalt</a> <br/>\n\t\t\t\t\t\n\t\t\t\t\t<i> Neural Human Video Rendering by Learning Dynamic Textures and Rendering-to-Video Translation </i><br/> \n\t\t\t\t\tIEEE TVCG, 2020<br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/NeuralHumanVideoRendering/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2001.04947.pdf\">[paper]</a> \n\t\t\t\t\t<a href=\"https://www.youtube.com/watch?v=FcTDMlWzFSc&amp;feature=emb_logo\">[video]</a><br/>\n\t\t\t\t</td>\n\t\t\t\t",
    "262": "<td>\t\t\n \n\t\t\t\t\t<a>X. Long</a>,\n\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>,  \n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Etheobalt/\">C. Theobalt</a>\n\t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://www.cs.hku.hk/people/academic-staff/wenping\">W Wang</a> <br/>\n\t\t\t\t\t<i> Occlusion-Aware Depth Estimation with Adaptive Normal Constraints </i><br/> \n\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2020<br/>\n\t\t\t\t\t\n\t\t\t\t\t<a href=\"https://xxlong0.github.io/CNMNet/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/2004.00845.pdf\">[paper]</a> <br/>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "261": "<td>\t\t\n \n\t\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/people/Bhatnagar.html\">B.L. Bhatnagar</a>,  \n\t\t\t\t\t<a>C. Sminchisescu</a>, \n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Etheobalt/\">C. Theobalt</a>  \n\t\t\t\t\tand\n\t\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/people/pons-moll.html\" target=\"_blank\">G. Pons-Moll</a> <br/>\n\t\t\t\t\t<i> Combining Implicit Function Learning and Parametric Models for 3D Human Reconstruction </i><br/> \n\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2020 (Oral)<br/>\n\t\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/papers/bhatnagar2020ipnet/bhatnagar2020ipnet.pdf\">[paper]</a> \n\t\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/papers/bhatnagar2020ipnet/bhatnagar2020ipnet-supp.pdf\">[supplementary]</a><br/>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "260": "<td>\t\t\n \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~ksarkar/\">K. Sarkar</a>, \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~dmehta/\" target=\"_blank\">D. Mehta</a>,\n\t\t\t\t\t<a href=\"https://sites.google.com/view/xuweipeng\" target=\"_blank\">W. Xu</a>,\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Egolyanik/\" target=\"_blank\">V. Golyanik</a> \n\t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Etheobalt/\">C. Theobalt</a> <br/>\n\t\t\t\t\t<i> Neural Re-Rendering of Humans from a Single Image </i><br/> \n\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2020  <br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/NHRR/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/NHRR/data/1415.pdf\">[paper]</a><br/>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "259": "<td>\t\t\n \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~tretschk/\">E. Tretschk</a>, \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a>, \n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Egolyanik/\" target=\"_blank\">V. Golyanik</a>, \n\t\t\t\t\t<a href=\"http://zollhoefer.com/\" target=\"_blank\">M. Zollhoefer</a>, \n\t\t\t\t\t<a href=\"https://scholar.google.de/citations?user=ArKKNxwAAAAJ\" target=\"_blank\">C. Stoll</a> \n\t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Etheobalt/\">C. Theobalt</a> <br/>\n\t\t\t\t\t<i> PatchNets: Patch-Based Generalizable Deep Implicit 3D Shape Representations</i><br/> \n\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2020 <br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/PatchNets/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/PatchNets/data/patchnets.pdf\">[paper]</a><br/>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "258": "<td>\t\t\n \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~tretschk/\">E. Tretschk</a>, \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a>, \n\t\t\t\t\t<a href=\"http://zollhoefer.com/\" target=\"_blank\">M. Zollhoefer</a>, \n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Egolyanik/\" target=\"_blank\">V. Golyanik</a> \n\t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Etheobalt/\">C. Theobalt</a> <br/>\n\t\t\t\t\t<i> DEMEA: Deep Mesh Autoencoders for Non-Rigidly Deforming Objects </i><br/> \n\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2020 (Spotlight) <br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DEMEA/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DEMEA/data/demea.pdf\">[paper]</a><br/>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "257": "<td>\t\t\n \t\t\t\t\t<a href=\"https://www.linkedin.com/in/vikramjit-sidhu-16294887/?originalSubdomain=de\">V. Sidhu</a>,\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~tretschk/\">E. Tretschk</a>,  \n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Egolyanik/\" target=\"_blank\">V. Golyanik</a>,\n\t\t\t\t\t<a href=\"http://www.iri.upc.edu/people/aagudo/\" target=\"_blank\">A. Agudo</a> \n\t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Etheobalt/\">C. Theobalt</a> <br/>\n\t\t\t\t\t<i> Neural Dense Non-Rigid Structure from Motion with Latent Space Constraints </i><br/> \n\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2020 <br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/Neural_NRSfM/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/Neural_NRSfM/data/Sidhu_etal_ECCV_20.pdf\">[paper]</a><br/>\n \n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "256": "<td>\t\t\n \n\t\t\t\t\t<a>N. Qian</a>,\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Ejwang/\" target=\"_blank\">J. Wang</a>,\t\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Efrmueller/\">F. Mueller</a>, \n\t\t\t\t\t<a href=\"https://sites.google.com/site/fbernardpi/\" target=\"_blank\">F. Bernard</a>, \n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Egolyanik/\" target=\"_blank\">V. Golyanik</a> \n\t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Etheobalt/\">C. Theobalt</a> <br/>\n\t\t\t\t\t<i> HTML: A Parametric Hand Texture Model for 3D Hand Reconstruction and Personalization</i><br/> \n\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2020 <br/>\n\t\t\t\t\t<a href=\"https://handtracker.mpi-inf.mpg.de/projects/HandTextureModel/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://handtracker.mpi-inf.mpg.de/projects/HandTextureModel/content/HandTextureModel_ECCV2020.pdf\">[paper]</a><br/>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "255": "<td>\t\t\n\t\t\t\t\t<a href=\"https://justusthies.github.io/\" target=\"_blank\">J. Thies</a>,\t\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a>\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari,</a> \n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Etheobalt/\">C. Theobalt</a> <br/>\n\t\t\t\t\tand\n\t\t\t\t\t<a href=\"https://niessnerlab.org/\">M. Niessner</a> <br/>\n\t\t\t\t\t<i> Neural Voice Puppetry: Audio-driven Facial Reenactment </i><br/> \n\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2020 <br/>\n\t\t\t\t\t<a href=\"https://justusthies.github.io/posts/neural-voice-puppetry/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/1912.05566.pdf\">[paper]</a><br/>\n\t\t\t\t</td>\n\t\t\t\t",
    "254": "<td>\t\t\n\t\t\t\t\t<a href=\"\" target=\"_blank\">Y. Yu</a>,\t\n\t\t\t\t\t<a href=\"\">A. Meka</a>, \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a> \n\t\t\t\t\t<a href=\"\" target=\"_blank\">H.P. Seidel</a> \n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Etheobalt/\">C. Theobalt</a> <br/>\n\t\t\t\t\tand\n\t\t\t\t\t<a href=\"\">W. Smith</a> <br/>\n\t\t\t\t\t<i> Self-supervised Outdoor Scene Relighting </i><br/> \n\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2020 <br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/SelfRelight/\">[project page]</a> \n\t\t\t\t\t<a href=\"https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123670086.pdf\">[paper]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/SelfRelight/Supp.pdf\">[supplementary]</a>\n\t\t\t\t\t<br/>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "253": "<td>\n\t\t\t\t\t\t<a href=\"\">P. Wang</a>,\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"\">N. Chen</a>,\n\t\t\t\t\t\t<a href=\" \" target=\"_blank\">H-K. Chu</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"https://i.cs.hku.hk/~wenping/\">W. Wang</a> \n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>Vid2Curve: Simultaneous Camera Motion Estimation and Thin Structure Reconstruction from an RGB Video</i> <br/>\n\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH 2020)<br/>\n\t\t\t\t[<a href=\"https://arxiv.org/pdf/2005.03372.pdf\">paper</a>]\n\t\t\t\t[<a href=\"https://www.youtube.com/watch?v=dI2FZG_txN0\">video</a>]\n\t\t\t\t</td>  \n\t\t\t\t",
    "252": "<td>\n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~dmehta/\" target=\"_blank\">D. Mehta</a>,\n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~osotnych/\" target=\"_blank\">O. Sotnychenko</a>,\n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~frmueller/\" target=\"_blank\">F. Mueller</a>,\n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\" target=\"_blank\">W. Xu</a>,\n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a>,\n\t\t\t\t<a href=\"http://cvlab.epfl.ch/~fua\" target=\"_blank\">P. Fua</a>,\n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H.P. Seidel</a>,\n\t\t\t\t<a href=\"https://people.epfl.ch/helge.rhodin\" target=\"_blank\">H. Rhodin</a>,\t\t\n\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/people/pons-moll.html\" target=\"_blank\">G. Pons-Moll</a>  and\n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\t\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>XNect: Real-time Multi-person 3D Motion Capture with a Single RGB Camera</i> <br/>\n\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH 2020)<br/>\n\t\t\t\t[<a href=\"http://vcai.mpi-inf.mpg.de/projects/XNect\">project page</a>]\n\t\t\t\t[<a href=\"https://arxiv.org/abs/1907.00837\">paper</a>]\n\t\t\t\t[<a href=\"http://vcai.mpi-inf.mpg.de/projects/XNectDemoV2/\">Demo@CVPR19</a>]\n\t\t\t\t[<a href=\"https://github.com/mehtadushy/SelecSLS-Pytorch/\">SelecSLS-Pytorch</a>]\n\t\t\t\t</td>  \n\t\t\t\t",
    "251": "<td>\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jwang/\">J. Wang</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Efrmueller/\" target=\"_blank\">F. Mueller</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~fbernard/\">F. Bernard</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>    Generative Model-Based Loss to the Rescue: A Method to Overcome Annotation Errors for Depth-Based Hand Pose Estimation</i> <br/>\n\t\t\t\t\t\tFG 2020<br/>\n\t\t\t\t<a href=\"https://handtracker.mpi-inf.mpg.de/projects/DepthMoHA/\">[project page]</a> \n\t\t\t\t<a href=\"https://handtracker.mpi-inf.mpg.de/projects/DepthMoHA/content/FG2020.pdf\">[paper]</a> \n\t\t\t\t<a href=\"https://www.youtube.com/watch?v=GrhcN-b4Wj4\">[video]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "250": "<td>\n\t\t\t\t\t\t<a href=\"https://calciferzh.github.io/\" target=\"_blank\">Y. Zhou</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\">W. Xu</a>,\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/~ihabibie/\">I. Habibie</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"http://cgcad.thss.tsinghua.edu.cn/xufeng/\">F. Xu</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>Monocular Real-time Hand Shape and Motion Capture using Multi-modal Data</i> <br/>\n\t\t\t\tComputer Vision and Pattern Recognition  (CVPR), 2020 <br/>\n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/2020-cvpr-hands/\">[project page]</a> \n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/2020-cvpr-hands/data/paper.pdf\">[paper]</a> \n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/2020-cvpr-hands/data/video.mp4\">[video]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "249": "<td>\n\t\t\t\t\t\t<a href=\"https://www.xu-lan.com/ \" target=\"_blank\">L. Xu</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"http://www.luvision.net/\">L. Fang</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>EventCap: Monocular 3D Capture of High-Speed Human Motions using an Event Camera</i> <br/>\n\t\t\t\tComputer Vision and Pattern Recognition  (CVPR), 2020 (Oral) <br/>\n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/2020-cvpr-eventcap/\">[project page]</a> \n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/2020-cvpr-eventcap/data/paper.pdf\">[paper]</a> \n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/2020-cvpr-eventcap/data/video.mp4\">[video]</a>\n\n\t\t\t\t</td>  \n\t\t\t\t",
    "248": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"https://zollhoefer.com/ \" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/gerard-pons-moll/\">G. Pons-Moll</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>DeepCap: Monocular Human Performance Capture Using Weak Supervision</i> <br/>\n\t\t\t\tComputer Vision and Pattern Recognition  (CVPR), 2020 (Oral) <br/>\n\t\t\t\tRecipient of the CVPR 2020 Best Student Paper Honorable Mention Award <br/>\n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/2020-cvpr-deepcap/\">[project page]</a> \n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/2020-cvpr-deepcap/data/paper.pdf\">[paper]</a> \n\t\t\t\t<a href=\"https://www.youtube.com/watch?v=C4eDrvJ9aBs\">[video]</a>\n\n\t\t\t\t</td>  \n\t\t\t\t",
    "247": "<td>\n\t\t\t\t\t<a href=\"https://justusthies.github.io/\" target=\"_blank\">J. Thies</a>,\n\t\t\t\t\t<a href=\"http://zollhoefer.com/\" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>,\n\t\t\t\t\t<a href=\"http://lgdv.cs.fau.de/people/card/marc/stamminger/\" target=\"_blank\">M. Stamminger</a> and\n\t\t\t\t\t<a href=\"http://www.graphics.stanford.edu/~niessner/index.html\" target=\"_blank\">M. Nie&#223;ner</a>\n\t\t\t\t\t<br/>\n\t\t\t\t\t<i>\n\t\t\t\t\tImage-guided Neural Object Rendering\n\t\t\t\t\t</i><br/>\n\t\t\t\t\tInternational Conference on Learning Representations (ICLR), 2020 <br/>\n                    <a href=\"https://www.niessnerlab.org/projects/thies2020ignor.html\">[project page]</a> \n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/1811.10720.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"http://www.youtube.com/watch?v=s79HG9yn7QM\">[video]</a>\n\t\t\t\t</td>\n\t\t\t",
    "246": "<td width=\"130\">\n\t\t\t\t</td>",
    "245": "<td>\n\t\t\t\t\t\t<a href=\"https://gfx.uvic.ca/people/\">A. Bojja</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~frmueller/\">F. Mueller</a>,\n\t\t\t\t\t\t<a href=\"\">S. Malireddi</a>,\n\t\t\t\t\t\t<a href=\"https://www.tugraz.at/institute/icg/research/team-lepetit/people/markus-oberweger/\"> M. Oberweger</a>,\n\t\t\t\t\t\t<a href=\"https://www.tugraz.at/institutes/icg/research/team-lepetit/people/vincent-lepetit/\"> V. Lepetit</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>,\n\t\t\t\t\t\t<a href=\"https://vision.uvic.ca/people/kmyi/\"> K. Yi</a> and\n\t\t\t\t\t\t<a href=\"https://gfx.uvic.ca/people/ataiya/\">A. Tagliasacchi</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>HandSeg: An Automatically Labeled Dataset for Hand Segmentation from Depth Images</i> <br/>\n\t\t\t\tConference on Computer and Robot Vision (CRV), 2019<br/>\n\t\t\t\t<a href=\"https://vision.uvic.ca/pubs/2019/bojja2019handseg/page.md\">[project page]</a> \n\t\t\t\t<a href=\"https://arxiv.org/abs/1711.05944\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "244": "<td>\t\t\n \n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>, \n \t\t\t\t\t<a href=\"\">A. Jonas</a>, \n\t\t\t\t\t<a href=\"https://av.dfki.de/members/stricker/\">D. Stricker</a> and\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>   \n \t\t\t\t\t<br/> \n\t\t\t\t\t<i>  Intrinsic Dynamic Shape Prior for Dense Non-Rigid Structure from Motion </i><br/> \n\t\t\t\t\t3DV, 2020 <br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DSPR/\">[project page]</a> \n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~golyanik/04_DRAFTS/Intrinsic%20Dynamic%20Shape%20Prior%20for%20Dense%20Non-Rigid%20Structure%20from%20Motion.pdf\">[paper]</a>\n\t\t\t\t\t<br/>\n\t\t\t\t</td>\n\t\t\t\t",
    "243": "<td>\n\t\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~hkim/\" target=\"_blank\">H. Kim</a>,\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a>\t,\t\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"https://zollhoefer.com/ \" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H-P. Seidel</a>,\n\t\t\t\t\t\t<a href=\"https://graphics.ethz.ch/~dbeeler/ \" target=\"_blank\">T. Beeler</a>,\n\t\t\t\t\t\t<a href=\"http://richardt.name/\" target=\"_blank\">C. Richardt</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>     Neural Style-Preserving Visual Dubbing.  </i> <br/>\n\t\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2019)<br/>\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/NeuralStylePreservingVisualDubbing/\">[project page]</a> \n\t\t\t\t<a href=\"https://arxiv.org/pdf/1909.02518.pdf\">[paper]</a> \n\t\t\t\t<!--a href=\"http://people.mpi-inf.mpg.de/~golyanik/04_DRAFTS/GA_SCALE_SINGULARITIES_SUPP.pdf\">[supplemental]</a--> \n\t\t\t\t<a href=\"https://www.youtube.com/watch?v=p0muYUlQcJM\">[video]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "242": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>    Optimising for Scale in Globally Multiply-Linked Gravitational Point Set Registration Leads to Singularities.  </i> <br/>\n\t\t\t\t\t\tInternational Conference on 3DVision (3DV), 2019<br/>\n\t\t\t\t<!--a href=\"http://vcai.mpi-inf.mpg.de/projects/DispVoxNets/\">[project page]</a--> \n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/04_DRAFTS/GA_SCALING_SINGULARITIES.pdf\">[paper]</a> \n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/04_DRAFTS/GA_SCALE_SINGULARITIES_SUPP.pdf\">[supplemental]</a> \n\t\t\t\t<!--a href=http://vcai.mpi-inf.mpg.de/projects/DispVoxNets/data/video.mp4\">[video]</a--> \n\t\t\t\t</td>  \n\t\t\t\t",
    "241": "<td>\n\t\t\t\t\t\t<a href=\"https://www.dfki.de/en/web/about-us/employee/person/sosh01/\">S. Shimada</a>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~tretschk/\" target=\"_blank\">E. Tretschk</a>,\t\n\t\t\t\t\t\t<a href=\"https://av.dfki.de/members/stricker/\">D. Stricker</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>    DispVoxNets: Non-Rigid Point Set Alignment with Supervised Learning Proxies </i> <br/>\n\t\t\t\t\t\tInternational Conference on 3DVision (3DV), 2019<br/>\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DispVoxNets/\">[project page]</a> \n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DispVoxNets/data/paper.pdf\">[paper]</a> \n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DispVoxNets/data/video.mp4\">[video]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "240": "<td>\n\t\t\t\t\t\t<a href=\"\">T. Yenamandra</a>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~fbernard/\">F. Bernard</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~jwang/\">J. Wang</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Efrmueller/\" target=\"_blank\">F. Mueller</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>    Convex Optimisation for Inverse Kinematics</i> <br/>\n\t\t\t\t\t\tInternational Conference on 3DVision (3DV), 2019<br/>\n\t\t\t\t<a href=\"\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "239": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and \n\t\t\t\t\t\t<a href=\"https://av.dfki.de/members/stricker/\">D. Stricker</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>    Accelerated Gravitational Point Set Alignment with Altered Physical Laws.   </i> <br/>\n\t\t\t\t\t\tInternational Conference on Computer Vision (ICCV), 2019<br/>\n\t\t\t\t<!--a href=\"http://vcai.mpi-inf.mpg.de/projects/DispVoxNets/\">[project page]</a--> \n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/04_DRAFTS/Golyanik_etal_ICCV_2019.pdf\">[paper]</a> \n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/04_DRAFTS/Golyanik_etal_ICCV_2019-supp.pdf\">[supplemental]</a> \n\t\t\t\t<!--a href=http://vcai.mpi-inf.mpg.de/projects/DispVoxNets/data/video.mp4\">[video]</a--> \n\t\t\t\t</td>  \n\t\t\t\t",
    "238": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~fbernard/\">F. Bernard</a>\n\t\t\t\t\t\t<a href=\"https://sites.google.com/site/johanthunbergphd/\" target=\"_blank\">J. Thunberg</a>,\t\n\t\t\t\t\t\t<a href=\"http://paulswoboda.net/\" target=\"_blank\">P. Swoboda</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>   HiPPI: Higher-Order Projected Power Iterations for Scalable Multi-Matching</i> <br/>\n\t\t\t\t\t\tInternational Conference on Computer Vision (ICCV), 2019<br/>\n\t\t\t\t<a href=\"https://arxiv.org/pdf/1811.10541.pdf\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "237": "<td>\n \t\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/people/Bhatnagar.html\" target=\"_blank\">B. Bhatnagar</a>,\t\n\t\t\t\t\t<a href=\"\">G. Tiwari, \n\t\t\t\t\t</a><a href=\"http://people.mpi-inf.mpg.de/~theobalt/ \" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/gerard-pons-moll/\">G. Pons-Moll</a>\n\t\t\t\t <br/>\n\t\t\t\t<i>Multi-Garment Net: Learning to Dress 3D People from Images </i> <br/>\n\t\t\t\tInternational Conference on Computer Vision (ICCV), 2019<br/>\n\t\t\n\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/mgn/\">[project page]</a> \n\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/papers/bhatnagar2019mgn/bhatnagar2019mgn.pdf\">[paper]</a> \n\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=0ybLCfVeFL4\">[video]</a--> \n\t\t\t\t</td>",
    "236": "<td>\n\t\t\t\t  <a href=\"https://graphics.tu-bs.de/people/alldieck\">T. Alldieck, \n\t\t\t\t\t</a><a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/gerard-pons-moll/\">G. Pons-Moll</a>, \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/ \" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t<a href=\"https://graphics.tu-bs.de/people/magnor\" target=\"_blank\">M. Magnor</a>\n\t\t\t\t <br/>\n\t\t\t\t<i>Tex2Shape: Detailed Full Human Body Geometry from a Single Image </i> <br/>\n\t\t\t\tInternational Conference on Computer Vision (ICCV), 2019<br/>\n\t\t\n\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/tex2shape/\">[project page]</a> \n\t\t\t\t<a href=\"https://arxiv.org/abs/1904.08645\">[paper]</a> \n\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=0ybLCfVeFL4\">[video]</a--> \n\t\t\t\t</td>",
    "235": "<td>\n\t\t\t\t\t<a href=\"https://www.ohadf.com/\" target=\"_blank\">O. Fried</a>,\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~atewari/\">A. Tewari</a>,\n\t\t\t\t\t<a href=\"http://zollhoefer.com/\" target=\"_blank\">M. Zollho&#776;fer</a>,\n\t\t\t\t\t<a href=\"https://www.cs.princeton.edu/~af/\" target=\"_blank\">A. Finkelstein</a>,\n\t\t\t\t\t<a href=\"https://research.adobe.com/person/eli-shechtman/\" target=\"_blank\">E. Schectman</a>,\n\t\t\t\t\t<a href=\"http://www.danbgoldman.com/\" target=\"_blank\">D. Goldman</a>,\n\t\t\t\t\t<a href=\"http://www.kylegenova.com/\">K. Genova</a>, \n\t\t\t\t\t<a href=\"https://research.adobe.com/person/zeyu-jin/\" target=\"_blank\">Z. Jin</a>,\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Etheobalt/\" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t<a href=\"http://graphics.stanford.edu/~maneesh/\">M. Agrawala</a>\n\t\t\t\t\t<br/>\n\t\t\t\t<i>  Text-based Editing of Talking-head Video  </i> <br/>\n\t\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH 2019)  <br/>\n\t\t\t\t<a href=\"https://www.ohadf.com/projects/text-based-editing/\">[project page]</a> \n\t\t\t\t<a href=\"https://arxiv.org/pdf/1906.01524.pdf\">[paper]</a> \n\t\t\t\t<a href=\"https://www.youtube.com/watch?v=0ybLCfVeFL4\">[video]</a> \n\t\t\t\t\n\t\t\t\t\n\t\t\t\t</td>",
    "234": "<td>\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Efrmueller/\" target=\"_blank\">F. Mueller</a>,\n\t\t\t\t\t<a href=\"http://mslab.es/members/\" target=\"_blank\">M. Davis</a>,\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Efbernard/\" target=\"_blank\">F. Bernard</a>,\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Eosotnych/\" target=\"_blank\">O. Sotnychenko</a>,\n\t\t\t\t\t<a href=\"https://www.mverschoor.nl/wp/\" target=\"_blank\">M. Verschoor</a>,\n\t\t\t\t\t<a href=\"https://mslab.es/otaduy/\" target=\"_blank\">M. A. Otaduy</a>,\n\t\t\t\t\t<a href=\"https://dancasas.github.io/\" target=\"_blank\">D. Casas</a> and\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/%7Etheobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>  Real-time Pose and Shape Reconstruction of Two Interacting Hands With a Single Depth Camera  </i> <br/>\n\t\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH 2019)  <br/>\n\t\t\t\t<a href=\"https://handtracker.mpi-inf.mpg.de/projects/TwoHands/\">[project page]</a> \n\t\t\t\t<a href=\"https://handtracker.mpi-inf.mpg.de/projects/TwoHands/content/TwoHands_SIGGRAPH2019.pdf\">[paper]</a> \n\t\t\t\t<a href=\"https://handtracker.mpi-inf.mpg.de/projects/TwoHands/content/TwoHands_SIGGRAPH2019.mp4\">[video]</a> \n\t\t\t\t\n\t\t\t\t</td>",
    "233": "<td>\n\t        <a href=\"http://people.mpi-inf.mpg.de/~ameka/\" target=\"_blank\">A. Meka</a>,\t  \n\t\t<a href=\"http://www.google.com/\" target=\"_blank\">C. Haene</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">R. Pandey</a>, \n\t  <a href=\"http://zollhoefer.com/\" target=\"_blank\">M. Zollh&#195;&#182;fer</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">S. Fanello</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">G. Fyffe</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">A. Kowdle</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">X. Yu</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">J. Busch</a>, \n\t  <a href=\"http://www.google.com/\" target=\"_blank\">J. Dourgarian</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">P. Denny</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">S. Bouaziz</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">P. Lincoln</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">M. Whalen</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">G. Harvey</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">J. Taylor</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">S. Izadi</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">A. Tagliasacchi</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">P. Debevec</a>,\n\t  <a href=\"http://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>,\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">J. Valentin</a> and\n\t  <a href=\"http://www.google.com/\" target=\"_blank\">C. Rhemann</a> \n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>  Deep Reflectance Fields - High-Quality Facial Reflectance Field Inference From Color Gradient Illumination  </i> <br/>\n\t\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH 2019)  <br/>\n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/DeepReflectanceFields/\">[project page]</a> \n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/DeepReflectanceFields/DRF.pdf\">[paper]</a> \n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/DeepReflectanceFields/DRF.mp4\">[video]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "232": "<td>\n\t\t\t\t\t\t<a href=\"https://www.dfki.de/en/web/about-us/employee/person/sosh01/\">S. Shimada</a>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/\">V. Golyanik</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"https://av.dfki.de/members/stricker/\">D. Stricker</a> \n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>    IsMo-GAN: Adversarial Learning for Monocular Non-Rigid 3D Reconstruction.  </i> <br/>\n\t\t\t\t\t\tComputer Vision and Pattern Recognition Workshops (Photogrammetric Computer Vision Workshop), 2019; Oral.  <br/>\n\t\t\t\t<!--a href=\"http://vcai.mpi-inf.mpg.de/projects/DispVoxNets/\">[project page]</a--> \n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~golyanik/04_DRAFTS/Shimada_etal_2019.pdf\">[paper]</a> \n\t\t\t\t<!--a href=\"http://vcai.mpi-inf.mpg.de/projects/DispVoxNets/data/video.mp4\">[video]</a--> \n\t\t\t\t</td>  \n\t\t\t\t",
    "231": "<td>\n\t        <a href=\"http://people.mpi-inf.mpg.de/~ihabibie/\">I. Habibie, \n\t\t\t\t\t</a><a href=\"http://people.mpi-inf.mpg.de/~wxu/\">W. Xu</a>,\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~Dmetha/\">D. Mehta</a>,\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/gerard-pons-moll/\">G. Pons-Moll</a> and \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/ \" target=\"_blank\">C. Theobalt</a> \n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>  In the Wild Human Pose Estimation Using Explicit 2D Features and Intermediate 3D Representations </i> <br/>\n\t\t\t\t\t\tComputer Vision and Pattern Recognition  (CVPR), 2019 (Oral) <br/>\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/CVPR19Habibie/\">[project page]</a> \n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/CVPR19Habibie/data/paper.pdf\">[paper]</a> \n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/CVPR19Habibie/data/video.mp4\">[video]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "230": "<td>\n\t                <a href=\"https://graphics.tu-bs.de/people/alldieck\">T. Alldieck, \n\t\t\t\t\t</a><a href=\"https://graphics.tu-bs.de/people/magnor\" target=\"_blank\">M. Magnor</a>,\n\t\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/people/Bhatnagar.html\" target=\"_blank\">B. Bhatnagar</a>,\t\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/ \" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/gerard-pons-moll/\">G. Pons-Moll</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>  Learning to Reconstruct People in Clothing from a Single RGB Camera </i> <br/>\n\t\t\t\t\t\tComputer Vision and Pattern Recognition  (CVPR), 2019 <br/>\n\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/octopus/\">[project page]</a> \n\t\t\t\t<a href=\"http://virtualhumans.mpi-inf.mpg.de/papers/alldieck19cvpr/alldieck19cvpr.pdf\">[paper]</a> \n\t\t\t\t<a href=\"https://graphics.tu-bs.de/upload/publications/alldieck2019learning/alldieck2019learning.mp4\">[video]</a> \n\n\t\t\t\t</td>  \n\t\t\t\t",
    "229": "<td>\n\t\t\t\t\t\t<a href=\"http://paulswoboda.net/\" target=\"_blank\">P. Swoboda</a>,\t\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">A. Mokarian</a>,\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">D. Kainmueller</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~fbernard/\">F. Bernard</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>   A convex relaxation for multi-graph matching </i> <br/>\n\t\t\t\t\t\tComputer Vision and Pattern Recognition  (CVPR), 2019 (Oral)<br/>\n\t\t\t\t<a href=\"\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "228": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a>,\t\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"https://sites.google.com/site/fbernardpi/\" target=\"_blank\">F. Bernard</a>\t,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~pgarrido/\" target=\"_blank\">P. Garrido</a>\t,\n\t\t\t\t\t\t<a href=\"http://gauravbharaj.com/\" target=\"_blank\">G. Bharaj</a>\t\t,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~elgharib/\" target=\"_blank\">M. Elgharib</a>\t,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H-P. Seidel</a>\t,\n\t\t\t\t\t\t<a href=\"https://ptrckprz.github.io/\" target=\"_blank\">P. Perez</a>\t\t\t\t\t,\n\t\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&amp;oumlfer</a> and\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C.Theobalt</a>\t\t\t\t\t<br/>\n\t\t\t\t\t\t<i>  FML: Face Model Learning from Videos  </i> <br/>\n\n\t\t\t\t\t\tComputer Vision and Pattern Recognition  (CVPR), 2019 (Oral)<br/>\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/FML19/\">[project page]</a>\n\t\t\t\t<a href=\"https://arxiv.org/abs/1812.07603\">[paper]</a>\n\t\t\t\t<a href=\"https://www.youtube.com/watch?v=SG2BwxCw0lQ\">[video]</a>\n\t\t\t\t<!--[<a href=\"http://graphics.stanford.edu/projects/bundlefusion/\">data</a>],-->\n\t\t\t\t\n\t\t\t\t</td>\n\t\t\t\t",
    "227": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~Dmetha/\">D. Mehta</a>,\n\t\t\t\t\t\t<a href=\"https://researchportal.bath.ac.uk/en/persons/kwang-in-kim/\" target=\"_blank\">K. I. Kim</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> \t\t\t\t\t\n\t\t\t\t\t\t<br/>\n\t\t\t\t\t\t<i>  On Implicit Filter Level Sparsity in Convolutional Neural Networks  </i> <br/>\n\t\t\t\t\t\tComputer Vision and Pattern Recognition  (CVPR), 2019<br/>\n\t\t\t\t\t\t<a href=\"https://arxiv.org/abs/1811.12495\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "226": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~fbernard/\">F. Bernard</a>,\n\t\t\t\t\t\t<a href=\"https://sites.google.com/site/johanthunbergphd/\" target=\"_blank\">J. Thunberg</a>,\t\n\t\t\t\t\t\t<a href=\"https://wwwen.uni.lu/lcsb/research/systems_control \" target=\"_blank\">J. Goncalves</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> \t\t\t\t\t\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>  Synchronisation of Partial Multi-Matchings via Non-negative Factorisations </i> <br/>\n\t\t\t\tPattern Recognition, 2019<br/>\n\t\t\t\t<a href=\"https://arxiv.org/pdf/1803.06320.pdf\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "225": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~achatter/\" target=\"_blank\">A. Chatterjee</a>,\t\n\t\t\t\t\t\t<a href=\"https://zollhoefer.com/ \" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t\t<a href=\"https://people.epfl.ch/helge.rhodin\" target=\"_blank\">H. Rhodin</a>,\n\t\t\t\t\t\t<a href=\"https://people.epfl.ch/pascal.fua\">P. Fua</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~hpseidel/\">H-P. Seidel</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> \t\t\t\t\t\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i> Mo2Cap2: Real-time Mobile 3D Motion Capture with a Cap-mounted Fisheye Camera </i> <br/>\n\t\t\t\tIEEE Transactions on Visualization and Computer Graphics (Proc. IEEE VR, 2019)<br/>\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/wxu/Mo2Cap2/\">[project page]</a> \n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/wxu/HumanReenactment/content/main.pdf\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "224": "<td>\n\t\t\t\t\t<a href=\"http://lgdv.cs.fau.de/people/card/justus/thies/\" target=\"_blank\">J. Thies</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t<a href=\"http://lgdv.cs.fau.de/people/card/marc/stamminger/\" target=\"_blank\">M. Stamminger</a>,\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t<a href=\"http://www.graphics.stanford.edu/~niessner/index.html\" target=\"_blank\">M. Nie&#223;ner</a>\n\t\t\t\t\t<br/>\n\t\t\t\t\t<i>Face2Face: Real-time Face Capture and Reenactment of RGB Videos</i><br/>\n\t\t\t\t\tCommunications of the ACM 2019 <br/>\n                    <a href=\"http://zollhoefer.com/papers/CACM19_F2F/page.html\">[project page]</a> \n\t\t\t\t\t<a href=\"http://zollhoefer.com/papers/CACM19_F2F/paper.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"https://www.youtube.com/watch?time_continue=2&amp;v=PJs3rlCBk1E\">[video]</a>\n\t\t\t\t</td>\n\t\t\t",
    "223": "<td>\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"https://zollhoefer.com/ \" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~hkim/\" target=\"_blank\">H. Kim</a>,\t\n\t\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~fbernand/\" target=\"_blank\">F. Bernard</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\n\t\t\t\t\t\t<a href=\"https://i.cs.hku.hk/~wenping/\">W. Wang</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> \t\t\t\t\t\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>Neural Animation and Reenactment of Human Actor Videos</i> <br/>\n\t\t\t\tACM Transactions on Graphics(to be presented at SIGGRAPH 2019)<br/>\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/wxu/HumanReenactment/\">[project page]</a> \n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/wxu/HumanReenactment/content/main.pdf\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "222": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"https://zollhoefer.com/ \" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/gerard-pons-moll/\">G. Pons-Moll</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>LiveCap: Real-time Human Performance Capture from Monocular Video</i> <br/>\n\t\t\t\tACM Transactions on Graphics (to be presented at SIGGRAPH 2019)<br/>\n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/LiveCapV2/\">[project page]</a> \n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/LiveCapV2/data/livecap.pdf\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "221": "<td width=\"130\">\n\t\t\t\t</td>",
    "220": "<td>\n\t\t\t\t\t\t<a href=\"https://av.dfki.de/members/sarkar/\" target=\"_blank\">K. Sarkar</a>,\n\t\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~fbernand/\" target=\"_blank\">F. Bernard</a>,\n\t\t\t\t\t\t<a href=\"https://av.dfki.de/members/varanasi/\">K. Varanasi</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>,\n\t\t\t\t\t\t<a href=\"https://av.dfki.de/members/stricker/\">D. Stricker</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i> Denoising of point-clouds based on structured dictionary learning </i> <br/>\n\t\t\t\t  Symposium on Geometry Processing (SGP 2018 Invited Poster)<br/>\n\t\t\t\t<a href=\"https://diglib.eg.org/bitstream/handle/10.2312/sgp20181180/005-006.pdf\">[pdf]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "219": "<td>\n\t\t\t\t\t\t<a href=\"https://sites.google.com/site/johanthunbergphd/\" target=\"_blank\">J. Thunberg</a>,\n\t\t\t\t\t\t<a href=\"https://sites.google.com/site/johanmarkdahl/home\"> J. Markdahl,\n\t\t\t\t\t\t</a><a href=\"http://www.mpi-inf.mpg.de/~fbernand/\" target=\"_blank\">F. Bernard</a>\n\t\t\t\t\t\tand \n\t\t\t\t\t\t<a href=\"https://wwwen.uni.lu/lcsb/research/systems_control \" target=\"_blank\">J. Goncalves</a> \n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>  A lifting method for analyzing distributed synchronization on the unit sphere</i> <br/>\n\t\t\t\t Automatica<br/>\n\t\t\t\t<a href=\"https://www.sciencedirect.com/science/article/pii/S0005109818303534\">[pdf]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "218": "<td>\n\t\t\t\t\t\t<a href=\"\">M. Soliman</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~frmueller/\">F. Mueller</a>,\n\t\t\t\t\t\t<a href=\"\">L. Hegemann</a>,\n\t\t\t\t\t\t<a href=\"https://hci.cs.uni-saarland.de/people/joan-sol-roo/\">J. Sol Roo</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"https://hci.cs.uni-saarland.de/people/juergen-steimle/\">J. Steimle</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>FingerInput: Capturing Expressive Single-Hand Thumb-to-Finger Microgestures for On-Skin Input</i> <br/>\n\t\t\t\tACM International Conference on Interactive Surfaces and Spaces (ISS), 2018<br/>\n\t\t\t\t<a href=\"https://hci.cs.uni-saarland.de/research/fingerinput/\">[project page]</a> \n\t\t\t\t<a href=\"https://hci.cs.uni-saarland.de/files/2018/11/iss1111-solimanA.pdf\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "217": "<td>\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&#246;fer</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~fbernand/\" target=\"_blank\">F. Bernard</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~pgarrido/\" target=\"_blank\">P. Garrido</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~hkim/\" target=\"_blank\">H. Kim</a>,\n\t\t\t\t\t<a href=\"http://www.technicolor.com/en/patrick-perez/\" target=\"_blank\">P. Perez</a> and\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>High-Fidelity Monocular Face Reconstruction based on an Unsupervised Model-based Face Autoencoder</i><br/>\n\t\t\t\t\t  To appear in IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) <br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/TPAMI_Face/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/TPAMI_Face/paper.pdf\">[paper]</a>\n\t\t\t\t\t\t\t\t\t\t<a href=\"https://ieeexplore.ieee.org/document/8496850\">[IEEE]</a>\n\n\t\t\t\t</td>\n\t\t\t\t",
    "216": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mhaberma/\">M. Habermann</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"http://helge.rhodin.de/\" target=\"_blank\">H. Rhodin</a>,\n\t\t\t\t\t\t<a href=\"https://zollhoefer.com/ \" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/gerard-pons-moll/\">G. Pons-Moll</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>NRST: Non-rigid Surface Tracking from Monocular Video</i> <br/>\n\t\t\t\tGerman Conference on Pattern Recognition(GCPR), 2018<br/>\n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/NRST/\">[project page]</a> \n\t\t\t\t<a href=\"https://vcai.mpi-inf.mpg.de/projects/NRST/data/0016.pdf\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "215": "<td>\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/\">L. Liu</a>,\t\t\t\n\t\t\t\t\t\t<a href=\"https://lingjie0206.github.io/papers/curvefusion/\">N. Chen</a>,\n\t\t\t\t\t\t<a href=\"http://www.duygu-ceylan.com/ \" target=\"_blank\">D. Ceylan</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>, \t\t\t\t\t\n\t\t\t\t\t\t<a href=\"https://i.cs.hku.hk/~wenping/\">W. Wang</a> and.\n\t\t\t\t\t\t<a href=\"http://www0.cs.ucl.ac.uk/staff/n.mitra/index.html\">N. J. Mitra</a>\t\t\t\t\t\n\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>CurveFusion: Reconstructing Thin Structures from RGBD Sequences</i> <br/>\n\t\t\t\tACM Transactions on Graphics  (Proc. SIGGRAPH Asia 2018)<br/>\n\t\t\t\t<a href=\"https://lingjie0206.github.io/papers/curvefusion/\">[project page]</a> \n\t\t\t\t<a href=\"https://lingjie0206.github.io/papers/curvefusion/curvefusion.pdf\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "214": "<td>\n\t\t\t\t\t\t<a href=\"https://av.dfki.de/members/sarkar/\">K. Sarkar</a>,\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~fbernand/\" target=\"_blank\">F. Bernard</a>,\n\t\t\t\t\t\t<a href=\"https://av.dfki.de/members/varanasi/\">K. Varanasi</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and \n\t\t\t\t\t\t<a href=\"https://av.dfki.de/members/stricker/\">D. Stricker</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>Structured Low-Rank Matrix Factorization for Point-Cloud Denoising</i> <br/>\n\t\t\t\tInternational Conference on 3D Vision (3DV), 2018<br/>\n\t\t\t\t<a href=\"projects/3dv_denoising/sarkar_et_al-pointcloud_denoising_3dv_2018.pdf\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "213": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~dmetha/\">D. Mehta</a>,\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~osotnych/\">O. Sotnychenko</a>, \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~frmueller/\">F. Mueller</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~ssridhar/\">S. Sridhar</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/gerard-pons-moll/\">G. Pons-Moll</a>\n\t\t\t\t\t\tand\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>Single-Shot Multi-Person 3D Pose Estimation From Monocular RGB Input</i> <br/>\n\t\t\t\tInternational Conference on 3D Vision (3DV), 2018<br/>\n\t\t\t\t<a href=\"projects/SingleShotMultiPerson/\">[project page]</a> \n\t\t\t\t<a href=\"https://arxiv.org/abs/1712.03453\">[paper]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "212": "<td>\t\t\n \n\t                <a href=\"https://graphics.tu-bs.de/people/alldieck\">T. Alldieck, \n\t\t\t\t\t</a><a href=\"https://graphics.tu-bs.de/people/magnor\" target=\"_blank\">M. Magnor</a>,\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\" target=\"_blank\">W. Xu</a>,\t\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/ \" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/gerard-pons-moll/\">G. Pons-Moll</a><br/>\n\t\t\t\t\t<i> Detailed Human Avatars from Monocular Video</i><br/> \n\t\t\t\t\t International Conference on 3D Vision (3DV), 2018 <br/>\n\t\t\t\t\t<a href=\"https://graphics.tu-bs.de/publications/alldieck2018detailed\">[project page]</a>\n\t\t\t\t\t<a href=\"https://graphics.tu-bs.de/upload/publications/alldieck2018detailed.pdf\">[paper]</a><br/>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "211": "<td>\t\t\n \n\t                <a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/qianru-sun/\">Q. Sun</a>, \n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a>,\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\" target=\"_blank\">W. Xu</a>,\t\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/mario-fritz/\">Mario Fritz</a>, \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/ \" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/bernt-schiele/\">B. Schiele</a> <br/>\n\t\t\t\t\t<i> A Hybrid Model for Identity Obfuscation by Face Replacement</i><br/> \n\t\t\t\t\tEuropean Conference on Computer Vision (ECCV), 2018 <br/>\n\t\t\t\t\t<a href=\"projects/Obfuscation_ECCV/index.html\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/abs/1804.04779\">[paper]</a><br/>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "210": "<td>\t\t\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~hkim/\" target=\"_blank\">H. Kim</a>,\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~pgarrido/ \" target=\"_blank\">P. Garrido</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a>,\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\" target=\"_blank\">W. Xu</a>,\t\n\t\t\t\t\t<a href=\"http://www.niessnerlab.org/members/justus_thies/profile.html \" target=\"_blank\">J. Thies</a>,\n\t\t\t\t\t<a href=\"http://www.niessnerlab.org/members/matthias_niessner/profile.html \" target=\"_blank\">M. Nie&#195;&#159;ner</a>,\n\t\t\t\t\t<a href=\"http://www.technicolor.com/en/patrick-perez \" target=\"_blank\">P. Perez</a>,\n\t\t\t\t\t<a href=\"http://richardt.name/\" target=\"_blank\">C. Richardt</a>, \n\t\t\t\t\t<a href=\"https://zollhoefer.com/ \" target=\"_blank\">M. Zollh&amp;oumlfer</a> and\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/ \" target=\"_blank\">C. Theobalt</a> <br/>\n\t\t\t\t\t<i>   Deep Video Portraits     \t</i><br/>\n\t\t\t\t\t ACM Transactions on Graphics  (Proc. SIGGRAPH 2018)<br/>\n\t\t\t\t\t<a href=\"projects/DeepVideoPortraits/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/1805.11714.pdf\">[paper]</a>\n\t\t\t\t\t<a href=\"https://www.youtube.com/watch?v=qc5P2bvfl44\">[video]</a>\n\n\t\t\t\t</td>\n\t\t\t\t",
    "209": "<td>\t\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://www.niessnerlab.org/members/justus_thies/profile.html \" target=\"_blank\">J. Thies</a>,\n\t\t\t\t\t<a href=\"https://zollhoefer.com/ \" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/ \" target=\"_blank\">C. Theobalt</a>,\n\t\t\t\t\t<a href=\"https://lgdv.cs.fau.de/people/card/marc/stamminger/ \" target=\"_blank\">M. Stamminger</a> and \n\t\t\t\t\t<a href=\"http://www.niessnerlab.org/members/matthias_niessner/profile.html \" target=\"_blank\">M. Nie&#195;&#159;ner</a> <br/>\n\t\t\t\t\t<i>  HeadOn: Real-time Reenactment of Human Portrait Videos    \t</i><br/>\n\t\t\t\t\t ACM Transactions on Graphics  (Proc. SIGGRAPH 2018)<br/>\n\t\t\t\t\t<a href=\"projects/HeadOn/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/HeadOn/headOn.pdf\">[paper]</a>\n\t\t\t\t\t<a href=\"https://www.youtube.com/watch?v=KRIlyxqsBTM\">[video]</a>\n\t\t\t\t</td>\n\t\t\t\t",
    "208": "<td>\n\t\t\t\t\t\t<a href=\"https://zollhoefer.com/ \" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t\t<a href=\"http://www.niessnerlab.org/members/justus_thies/profile.html \" target=\"_blank\">J. Thies</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~pgarrido/ \" target=\"_blank\">P. Garrido</a>,\n\t\t\t\t\t\t<a href=\"http://zurich.disneyresearch.com/derekbradley/ \" target=\"_blank\">D. Bradley</a>,\n\t\t\t\t\t\t<a href=\"https://graphics.ethz.ch/~dbeeler/ \" target=\"_blank\">T. Beeler</a>,\n\t\t\t\t\t\t<a href=\"http://www.technicolor.com/en/patrick-perez \" target=\"_blank\">P. Perez</a>,\n\t\t\t\t\t\t<a href=\"http://www.niessnerlab.org/members/matthias_niessner/profile.html \" target=\"_blank\">M. Nie&#195;&#159;ner</a>,\n\t\t\t\t\t\t<a href=\"https://lgdv.cs.fau.de/people/card/marc/stamminger/ \" target=\"_blank\">M. Stamminger</a> and\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/ \" target=\"_blank\">C. Theobalt</a>\t<br/>\n\t\t\t\t\t<i> State of the Art on Monocular 3D Face Reconstruction, Tracking, and Applications   \t</i><br/>\n\t\t\t\t\t Computer Graphics Forum (presented at Eurographics, 2018)<br/>\n\t\t\t\t\t<a href=\"http://zollhoefer.com/papers/EG18_FaceSTAR/page.html\">[project page]</a>\n\t\t\t\t\t<a href=\"http://zollhoefer.com/papers/EG18_FaceSTAR/paper.pdf\">[pdf]</a>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "207": "<td>\n\t\t\t\t\t\t<a href=\"https://zollhoefer.com/ \" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t\t<a href=\"https://scholar.google.com/citations?user=nMLx_s0AAAAJ&amp;hl=en \" target=\"_blank\">P. Stotko</a>,\n\t\t\t\t\t\t<a href=\"http://www.cg.informatik.uni-siegen.de/de/goerlitz-andreas \" target=\"_blank\">A. G&amp;oumlrlitz</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/ \" target=\"_blank\">C. Theobalt</a>,\n\t\t\t\t\t\t<a href=\"http://www.niessnerlab.org/members/matthias_niessner/profile.html \" target=\"_blank\">M. Nie&#195;&#159;ner</a>,\n\t\t\t\t\t\t<a href=\"https://cg.cs.uni-bonn.de/en/people/prof-dr-reinhard-klein \" target=\"_blank\">R. Klein</a> and\n\t\t\t\t\t\t<a href=\"http://www.cg.informatik.uni-siegen.de/de/kolb-andreas \" target=\"_blank\">A. Kolb</a>\t\t\t<br/>                               \n\t\t\t\t\t<i> State of the Art on 3D Reconstruction with RGB-D Cameras  \t</i><br/>\n\t\t\t\t\t Computer Graphics Forum (presented at Eurographics, 2018)<br/>\n\t\t\t\t\t<a href=\"http://zollhoefer.com/papers/EG18_RecoSTAR/page.html\">[project page]</a>\n\t\t\t\t\t<a href=\"http://zollhoefer.com/papers/EG18_RecoSTAR/paper.pdf\">[pdf]</a>\n\t\t\t\t\t<!--a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a-->\n\t\t\t\t</td>\n\t\t\t\t",
    "206": "<td>\n\t\t\t\t\t\t<a href=\"https://graphics.tu-bs.de/people/alldieck\">T. Alldieck</a>,\n\t\t\t\t\t\t<a href=\"https://graphics.tu-bs.de/people/magnor\">M. Magnor</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\" target=\"_blank\">W. Xu</a>,\t\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/gerard-pons-moll/\">G. Pons-Moll</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>Video Based Reconstruction of 3D People Models \t</i><br/>\n\t\t\t\t\t Computer Vision and Pattern Recognition  (CVPR), 2018<br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/wxu/VideoAvatar/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/wxu/VideoAvatar/content/video_shapes.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"https://www.youtube.com/watch?v=Htry63oRIjQ\">[video]</a>\n\t\t\t\t</td>\n\t\t\t\t",
    "205": "<td>\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&#246;fer</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~pgarrido/\" target=\"_blank\">P. Garrido</a>  ,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~fbernand/\" target=\"_blank\">F. Bernard</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~hkim/\" target=\"_blank\">H. Kim</a>,\n\t\t\t\t\t<a href=\"http://www.technicolor.com/en/patrick-perez/\" target=\"_blank\">P. Perez</a> and\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>Self-supervised Multi-level Face Model Learning for Monocular Reconstruction at over 250 Hz \t</i><br/>\n\t\t\t\t\t Computer Vision and Pattern Recognition  (CVPR), 2018 (Oral)<br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/FML/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/FML/paper.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"https://www.youtube.com/watch?v=h8jWocE_3tI\">[video]</a>\n\t\t\t\t</td>\n\t\t\t\t",
    "204": "<td>\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~hkim/\" target=\"_blank\">H. Kim</a>,\n\t\t\t\t\t<a href=\"http://zollhoefer.com/\" target=\"_blank\">M. Zollh&#246;fer</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a>,\n\t\t\t\t\t<a href=\"http://www.niessnerlab.org/members/justus_thies/profile.html\" target=\"_blank\">J. Thies</a>, \n\t\t\t\t\t <a href=\"http://richardt.name/\" target=\"_blank\">C. Richardt</a> and\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>InverseFaceNet: Deep Single-Shot Inverse Face Rendering From A Single Image</i><br/>\n\t\t\t\t\t Computer Vision and Pattern Recognition  (CVPR), 2018<br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/InverseFaceNet/\">[project page]</a>\n\t\t\t\t\t<a href=\"https://arxiv.org/pdf/1703.10956.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"https://www.youtube.com/watch?v=ffN7lsXogGU\">[video]</a>\n\t\t\t\t</td>\n\t\t\t\t",
    "203": "<td>\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~fbernard/\" target=\"_blank\">F. Bernard</a>, \n\t\t\t\t\t  <a href=\"http://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and \n\t\t\t\t\t  <a href=\"http://www.vsa.informatik.uni-siegen.de/en/moeller-michael\">Michael Moeller</a><a>\n\t\t\t\t\t  <br/>\n\t\t\t\t<i>Tighter Lifting-Free Convex Relaxations for Quadratic Matching Problems</i> <br/>\n\t\t\t\tComputer Vision and Pattern Recognition  (CVPR), 2018  <br/> \t\n\t\t\t\t<!--a href=\"\">[project page]</a--> \n\t\t\t\t</a><a href=\"https://arxiv.org/pdf/1711.10733.pdf\">[pdf]</a> \n\t\t\t\t<!--a href=\"\">[video]</a-->\n\t\t\t\t</td>  \n\t\t\t\t",
    "202": "<td>\n\t\t\t\t\t  <a href=\"http://www.mpi-inf.mpg.de/~ameka/\" target=\"_blank\">A. Meka</a>,\n\t\t\t\t\t  <a href=\"\" target=\"_blank\">M. Maximov</a>,\n\t\t\t\t\t  <a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&#246;fer</a>,\n\t\t\t\t\t  <a href=\"http://people.mpi-inf.mpg.de/~achatter/\">A. Chatterjee</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~hpseidel/\">H-P. Seidel</a>,\n\t\t\t\t\t  <a href=\"http://richardt.name/\" target=\"_blank\">C. Richardt</a> and\n\t\t\t\t\t  <a href=\"http://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a><br/>\n\t\t\t\t<i>LIME: Live Intrinsic Material Estimation</i> <br/>\n\t\t\t\tComputer Vision and Pattern Recognition  (CVPR), 2018 (Spotlight) <br/> \t\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/LIME/\">[project page]</a> \n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/LIME/LIME.pdf\">[pdf]</a> \n\t\t\t\t<a href=\"https://www.youtube.com/watch?v=5ntLiAYsMm4\">[video]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "201": "<td>\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~frmueller/\">F. Mueller</a>,\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~fbernard/\" target=\"_blank\">F. Bernard</a>, \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~osotnych/\">O. Sotnychenko</a>, \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~dmetha/\">D. Mehta</a>,\t\t\t\t\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~ssridhar/\">S. Sridhar</a>,\n\t\t\t\t\t<a href=\"https://dancasas.github.io/\">D. Casas</a>\n\t\t\t\t\tand\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i> GANerated Hands for Real-Time 3D Hand Tracking from Monocular RGB </i><br/>\n\t\t\t\t\t Computer Vision and Pattern Recognition  (CVPR), 2018 (Spotlight)<br/>\n\t\t\t\t\t<a href=\"http://handtracker.mpi-inf.mpg.de/projects/GANeratedHands/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://handtracker.mpi-inf.mpg.de/projects/GANeratedHands/content/GANeratedHands_CVPR2018.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"https://www.youtube.com/watch?v=pHyNrYRhvSg\">[video]</a>\n\t\t\t\t</td>\n\t\t\t\t",
    "200": "<td>\n\t\t\t\t  \t\t<a href=\"http://www.niessnerlab.org/members/justus_thies/profile.html\" target=\"_blank\">J. Thies</a>, \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&amp;oumlfer</a>, \n\t\t\t\t\t\t<a href=\"http://lgdv.cs.fau.de/people/card/marc/stamminger/\" target=\"_blank\">M. Stamminger</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"http://www.graphics.stanford.edu/~niessner/index.html\" target=\"_blank\">M. Nie&amp;szligner</a>\t\t\n\t\t\t\t\t\t<br/>\n\t\t\t\t<i>FaceVR: Real-Time Facial Reenactment and Eye Gaze Control in Virtual Reality  </i> <br/>\n\t\t\t\tACM Transactions on Graphics  (presented at SIGGRAPH 2018) <br/> \t\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/FaceVR/\">[project page]</a> <a href=\"https://arxiv.org/pdf/1610.03151v1.pdf\">[pdf]</a>\n\t\t\t\t<a href=\"https://www.youtube.com/watch?v=jIlujM5avU8\">[video]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "199": "<td>\n\t\t\t\t  \t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\" target=\"_blank\">W. Xu</a>, \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~achatter/\" target=\"_blank\">A. Chatterjee</a>, \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&amp;oumlfer</a>, \n\t\t\t\t\t\t<a href=\"http://helge.rhodin.de/\" target=\"_blank\">H. Rhodin</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~dmetha/\" target=\"_blank\">D. Mehta</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~hpseidel/\">H-P. Seidel</a> and\t\t\t\t\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t\t<br/>\n\t\t\t\t<i>MonoPerfCap: Human Performance Capture from Monocular Video </i> <br/>\n\t\t\t\tACM Transactions on Graphics  (presented at  SIGGRAPH 2018) <br/> \t\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/wxu/MonoPerfCap/\">[project page]</a> <a href=\"http://vcai.mpi-inf.mpg.de/projects/wxu/MonoPerfCap/content/monoperfcap.pdf\">[pdf]</a>\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/wxu/MonoPerfCap/content/monoperfcap.mp4\">[video]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "198": "<td width=\"130\">\n\t\t\t\t</td>",
    "197": "<td>\n\t\t\t\t\t\t<a href=\"https://sites.google.com/site/johanthunbergphd/\" target=\"_blank\">J. Thunberg</a>,\n\t\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~fbernard/\" target=\"_blank\">F. Bernard</a> and \n\t\t\t\t\t\t<a href=\"https://wwwen.uni.lu/lcsb/research/systems_control \" target=\"_blank\">J. Goncalves</a> \n\t\t\t\t\t\t <br/>\n\t\t\t\t<i> Distributed Synchronization of Euclidean Transformations with Guaranteed Convergence</i> <br/>\n\t\t\t\t IEEE Conference on Decision and Control (CDC 2017)<br/>\n\t\t\t\t<a href=\"http://orbilu.uni.lu/bitstream/10993/34953/1/orbi_version.pdf\">[pdf]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "196": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~dmetha/\">D. Mehta</a>,\t\t\t\t\n\t\t\t\t\t\t<a href=\"https://people.epfl.ch/helge.rhodin\"> H. Rhodin</a>,\n\t\t\t\t\t\t<a href=\"https://dancasas.github.io/\">D. Casas</a>\n\t\t\t\t\t\t<a href=\"http://cvlab.epfl.ch/~fua\">P. Fua</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~osotnych/\">O. Sotnychenko</a>, \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\">W. Xu</a>,\n\t\t\t\t\t\tand\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>Monocular 3D Human Pose Estimation In The Wild Using Improved CNN Supervision</i> <br/>\n\t\t\t\tInternational Conference on 3D Vision (3DV 2017)<br/>\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/3dhp-dataset/\">[project page]</a>  <a href=\"https://arxiv.org/pdf/1611.09813.pdf\">[pdf]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "195": "<td>\n\t\t\t\t  \t\t<a href=\"http://cs.stanford.edu/~zdevito/\" target=\"_blank\">Z. DeVito</a>, \n\t\t\t\t\t\t<a href=\"http://stanford.edu/\" target=\"_blank\">M. Mara</a>, \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&amp;oumlfer</a>, \n\t\t\t\t\t\t<a href=\"http://www.gilbertbernstein.com/\" target=\"_blank\">G. Bernstein</a>, \n\t\t\t\t\t\t<a href=\"http://people.csail.mit.edu/jrk/\" target=\"_blank\">J. Ragan-Kelley</a>, \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>, \n\t\t\t\t\t\t<a href=\"https://graphics.stanford.edu/~hanrahan/\" target=\"_blank\">P. Hanrahan</a>, \n\t\t\t\t\t\t<a href=\"https://graphics.stanford.edu/~mdfisher/\" target=\"_blank\">M. Fisher</a> and \n\t\t\t\t\t\t<a href=\"http://www.graphics.stanford.edu/~niessner/index.html\" target=\"_blank\">M. Nie&amp;szligner</a>\n\t\t\t\t\t  <br/>\n\t\t\t\t<i>Opt: A Domain Specific Language for Non-linear Least Squares Optimization in Graphics and Imaging</i> <br/>\n\t\t\t\tACM Transactions on Graphics  <br/> \t\n\t\t\t\t<a href=\"http://optlang.org/\">[project page]</a> <a href=\"http://arxiv.org/pdf/1604.06525v1\">[pdf]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "194": "<td>\n\t\t\t\t\t<a href=\"http://jamestompkin.com/\">J. Tompkin</a>,\n\t\t\t\t\t<a href=\"http://vcg.seas.harvard.edu/people/hanspeter-pfister\">H. Pfister</a>, \n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~kkim/\">K.I. Kim</a> \n\t\t\t\t\tand\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i> Criteria Sliders: Learning Continuous Database Criteria via Interactive Ranking </i><br/>\n\t\t\t\t\t The British Machine Vision Conference (BMVC), 2017<br/>\n\t\t\t\t\t<a href=\"http://opus.bath.ac.uk/56530/\">[project page]</a>\n\t\t\t\t\t\n\t\t\t\t</td>\n\t\t\t\t",
    "193": "<td>\n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/alumni-and-former-members/leonid-pishchulin/\">L. Pishchulin</a>,\n\t\t\t\t\t<a href=\"http://morpheo.inrialpes.fr/~wuhrer/\">S. Wuhrer</a>,\t\t\t\t\n\t\t\t\t\t<a href=\"\">T. Helten</a>,\t\t\t\t\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and \n\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/people/bernt-schiele/\">B. Schiele</a>,\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i> Building statistical shape spaces for 3D human modeling </i><br/>\n\t\t\t\t\t Pattern Recognition<br/>\n\t\t\t\t\t<a href=\"https://hal.inria.fr/hal-01136221/file/human_shape_space_HAL_2.pdf\">[pdf]</a>\n\t\t\t\t\t\n\t\t\t\t</td>\n\t\t\t\t",
    "192": "<td>\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~frmueller/\">F. Mueller</a>,\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~dmetha/\">D. Mehta</a>,\t\t\t\t\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~osotnych/\">O. Sotnychenko</a>, \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~ssridhar/\">S. Sridhar</a>,\n\t\t\t\t\t<a href=\"https://dancasas.github.io/\">D. Casas</a>\n\t\t\t\t\tand\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i> Real-time Hand Tracking under Occlusion from an Egocentric RGB-D Sensor </i><br/>\n\t\t\t\t\t International Conference on Computer Vision (ICCV), 2017<br/>\n\t\t\t\t\t<a href=\"http://handtracker.mpi-inf.mpg.de/projects/OccludedHands/\">[project page]</a>\n\t\t\t\t\t<a href=\"http://handtracker.mpi-inf.mpg.de/projects/OccludedHands/content/OccludedHands_ICCV2017.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"http://handtracker.mpi-inf.mpg.de/projects/OccludedHands/content/OccludedHands_ICCV2017.mp4\">[video]</a>\n\t\t\t\t</td>\n\t\t\t\t",
    "191": "<td>\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~atewari/\" target=\"_blank\">A. Tewari</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&#246;fer</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~hkim/\" target=\"_blank\">H. Kim</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~pgarrido/\" target=\"_blank\">P. Garrido</a>  ,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~fbernand/\" target=\"_blank\">F. Bernard</a>,\n\t\t\t\t\t<a href=\"http://www.technicolor.com/en/patrick-perez/\" target=\"_blank\">P. Perez</a> and\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t<br/>                               \n\t\t\t\t\t<i>MoFA: Model-based Deep Convolutional Face Autoencoder for Unsupervised Monocular Reconstruction</i><br/>\n\t\t\t\t\t International Conference on Computer Vision (ICCV), 2017 (Oral)<br/>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/MZ/Papers/arXiv2017_FA/page.html\">[project page]</a>\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/MZ/Papers/arXiv2017_FA/paper.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"https://www.youtube.com/watch?v=uIMpHZYB8fI\">[video]</a>\n\t\t\t\t</td>\n\t\t\t\t",
    "190": "<td>\n\t\t\t\t\t<a href=\"http://lgdv.cs.fau.de/people/card/justus/thies/\" target=\"_blank\">J. Thies</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t<a href=\"http://lgdv.cs.fau.de/people/card/marc/stamminger/\" target=\"_blank\">M. Stamminger</a>,\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t<a href=\"http://www.graphics.stanford.edu/~niessner/index.html\" target=\"_blank\">M. Nie&#223;ner</a>\t\t\t\n\t\t\t\t<i> Demo of FaceVR:  Real-Time Facial Reenactment and Eye Gaze Control in Virtual Reality </i> <br/>\n\t\t\t\tSIGGRAPH 2017 Emerging Technologies<br/> \t\n\t\t\t\t <a href=\"http://s2017.siggraph.org/content/emerging-technologies\">[link]</a> <a href=\"http://vcai.mpi-inf.mpg.de/projects/MZ/Papers/arXiv2016_FV/page.html\">[project page]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "189": "<td>\n\t\t\t\t\t<a href=\"http://cs.stanford.edu/~adai/index.html\" target=\"_blank\">A. Dai</a>,\n\t\t\t\t\t<a href=\"http://www.graphics.stanford.edu/~niessner/index.html\" target=\"_blank\">M. Nie&#223;ner</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&#246;fer</a>,\n\t\t\t\t\t<a href=\"http://research.microsoft.com/en-us/people/shahrami/\" target=\"_blank\">S. Izadi</a> and \n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t<br/>\n\t\t\t\t\t<i>BundleFusion: Real-time Globally Consistent 3D Reconstruction using Online Surface Re-integration</i><br/>\n\t\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH 2017)<br/>\n\t\t\t\t\t<a href=\"projects/MZ/Papers/arXiv2016_BF//page.html\">[project page]</a>\n\t\t\t\t\t<a href=\"http://arxiv.org/pdf/1604.01093v1.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"projects/MZ/Papers/arXiv2016_BF/video.mp4\">[video]</a>\n\t\t\t\t</td>\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t",
    "188": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~dmetha/\">D. Mehta</a>,\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~ssridhar/\">S. Sridhar</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~osotnych/\">O. Sotnychenko</a>, \n\t\t\t\t\t\t<a href=\"https://people.epfl.ch/helge.rhodin\"> H. Rhodin</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~frmueller/\">F. Mueller</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"https://dancasas.github.io/\">D. Casas</a>\n\t\t\t\t\t\tand\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>Demo of VNect: Real-time 3D Human Pose Estimation with a Single RGB Camera</i> <br/>\n\t\t\t\tProc. Computer Vision and Pattern Recognition (Demo) (CVPR 2017)<br/>\n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~dmehta/VNectDemo/\">[project page]</a> \n\t\t\t\t</td>  \n\t\t\t\t",
    "187": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~dmetha/\">D. Mehta</a>,\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~ssridhar/\">S. Sridhar</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~osotnych/\">O. Sotnychenko</a>, \n\t\t\t\t\t\t<a href=\"https://people.epfl.ch/helge.rhodin\"> H. Rhodin</a>,\n\t\t\t\t\t\t<a href=\"\" target=\"_blank\">M. Shafiei</a>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~hpseidel/\">H-P. Seidel</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~wxu/\">W. Xu</a>,\n\t\t\t\t\t\t<a href=\"https://dancasas.github.io/\">D. Casas</a>\n\t\t\t\t\t\tand\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>VNect: Real-time 3D Human Pose Estimation with a Single RGB Camera</i> <br/>\n\t\t\t\t ACM Transactions on Graphics (Proc. of SIGGRAPH 2017) <br/> \t\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/VNect/\">[project page]</a> <a href=\"http://vcai.mpi-inf.mpg.de/projects/VNect/content/VNect_SIGGRAPH2017.pdf\">[pdf]</a> <a href=\"https://www.youtube.com/watch?v=W1ZNFfftx2E\">[video]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "186": "<td>\n\t\t\t\t\t  <a href=\"http://www.mpi-inf.mpg.de/~ameka/\" target=\"_blank\">A. Meka</a>,\n\t\t\t\t\t  <a href=\"\" target=\"_blank\">G. Fox</a>,\n\t\t\t\t\t  <a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&#246;fer</a>,\n\t\t\t\t\t  <a href=\"http://richardt.name/\" target=\"_blank\">C. Richardt</a> and\n\t\t\t\t\t  <a href=\"http://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a><br/>\n\t\t\t\t<i>Live User-guided Intrinsic Video For Static Scenes</i> <br/>\n\t\t\t\tIEEE Transactions on Visualization and Computer Graphics (to be presented at ISMAR 2017).  <br/> \t\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/InteractiveIntrinsicAR/\">[project page]</a> <a href=\"http://vcai.mpi-inf.mpg.de/projects/InteractiveIntrinsicAR/LiveUserGuidedIntrinsicVideoForStaticScenes.pdf\">[pdf]</a> <a href=\"https://www.youtube.com/watch?v=Eh65mD6CPyw\">[video]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "185": "<td>\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~nroberti/\"> N. Robertini</a>,\n\t\t\t\t\t\t<a href=\"http://dancasas.github.io\">D. Casas</a>,\n\t\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~edeaguia/\">E. de Aguiar</a> and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t  <br/>\n\t\t\t\t<i>Multi-view Performance Capture of Surface Details</i> <br/>\n\t\t\t\tInternational Journal of Computer Vision (IJCV) 2017. <br/> \t\n\t\t\t\t<a href=\"\">[project page]</a> <a href=\"http://dx.doi.org/10.1007/s11263-016-0979-1\">[pdf]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "184": "<td>\n\t\t\t\t  \t\t<a href=\"http://people.mpi-inf.mpg.de/~ssridhar/\">S. Sridhar</a>,\n\t\t\t\t\t\t<a href=\"https://dk.linkedin.com/in/amarkussen\">A. Markussen</a>,\n\t\t\t\t\t\t<a href=\"http://users.comnet.aalto.fi/oulasvir/\">A. Oulasvirta</a>, \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t\t<a href=\"http://www.sebastianboring.com/\">S. Boring</a>.\n\t\t\t\t\t  <br/>\n\t\t\t\t<i>WatchSense: On- and Above-Skin Input Sensing through a Wearable Depth Sensor</i> <br/>\n\t\t\t\tACM Conference on Human Factors in Computing Systems (CHI) 2017, Denver, USA <br/> \t\n\t\t\t\t<a href=\"http://handtracker.mpi-inf.mpg.de/projects/WatchSense/\">[project page]</a> <a href=\"http://handtracker.mpi-inf.mpg.de/projects/WatchSense/content/WatchSense_CHI2017.pdf\">[pdf]</a> <a href=\"https://www.youtube.com/watch?v=nCbv65Fjoks\">[video]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "183": "<td>\n\t\t\t\tA. Elhayek, E. Aguiar, A. Jain, J. Tompson, L. Pishchulin, M. Andriluka, C. Bregler, B. Schiele and <a href=\"http://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C.Theobalt</a><br/>\n\t\t\t\t<i>MARCOnI - ConvNet-based MARker-less Motion Capture in Outdoor and Indoor Scenes</i> <br/>\n\t\t\t\tTo appear in IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) <br/> \t\n\t\t\t\t<a href=\"http://ieeexplore.ieee.org/document/7457717/\">[IEEE page]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "182": "<td width=\"130\">\n\t\t\t\t</td>",
    "181": "<td>\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t<a href=\"http://lgdv.cs.fau.de/people/card/justus/thies/\" target=\"_blank\">J. Thies</a>,\n\t\t\t\t\t<a href=\"http://www.graphics.stanford.edu/~niessner/index.html\" target=\"_blank\">M. Nie&#223;ner</a>\t\t\t\n\t\t\t\t\t<a href=\"http://lgdv.cs.fau.de/people/card/marc/stamminger/\" target=\"_blank\">M. Stamminger</a> and\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> \n\t\t\t\t<i>   FaceInCar: Real-time Dense Monocular Face Tracking of a Driver  </i> <br/>\n\t\t\t\tNational IT Summit 2016<br/> \t\n\t\t\t\t <a href=\"http://vcai.mpi-inf.mpg.de/projects/FaceInCar/\">[project page]</a>\n\t\t\t\t</td>  \n            ",
    "180": "<td>\n\t\t\t\t\t\t<a href=\"https://graphics.ethz.ch/~wuche/\">C. Wu</a>,\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://zurich.disneyresearch.com/derekbradley/\">D. Bradley</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~pgarrido/\">P. Garrido</a>, \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mzollhoef/\"> M. Zollh&#195;&#182;fer</a>,\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t\t<a href=\"https://graphics.ethz.ch/people/grossm/\">M. Gross</a>,\n\t\t\t\t\t\t and\n\t\t\t\t\t\t<a href=\"https://graphics.ethz.ch/~dbeeler/\">T. Beeler</a>\n\t\t\t\t\t\t <br/>\n\t\t\t\t<i>Model-based teeth reconstruction</i> <br/>\n\t\t\t\t ACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2016) <br/> \t\n\t\t\t\t[project page] [pdf]\n\t\t\t\t</td>  \n\t\t\t\t",
    "179": "<td>\n\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~pgarrido/\">P. Garrido</a>, \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mzollhoef/\"> M. Zollh&#195;&#182;fer</a>,\n\t\t\t\t\t\t<a href=\"https://graphics.ethz.ch/~wuche/\">C. Wu</a>,\n\t\t\t\t\t\t<a href=\"http://zurich.disneyresearch.com/derekbradley/\">D. Bradley</a>,\n\t\t\t\t\t\t<a href=\"http://www.technicolor.com/en/patrick-perez\">P. Perez</a>,\n\t\t\t\t\t\t<a href=\"https://graphics.ethz.ch/~dbeeler/\">T. Beeler</a>,\n\t\t\t\t\t\t and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t  <br/>\n\t\t\t\t<i>Corrective 3D reconstruction of lips from monocular video</i> <br/>\n\t\t\t\t ACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2016) <br/> \t\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/MonLipReconstruction/index.html\">[project page]</a><a> </a><a href=\"http://vcai.mpi-inf.mpg.de/files/SA2016/MonLipReconstruction-Low.pdf\">[pdf]</a>\n\t\t\t\t</td>  \n\t\t\t\t",
    "178": "<td>\n\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~hrhodin/\">H. Rhodin</a>, \n\t\t\t\t\t\t<a href=\"http://richardt.name/\"> C. Richardt</a>,\n\t\t\t\t\t\t<a href=\"http://dancasas.github.io\">D. Casas</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/de/departments/computer-vision-and-multimodal-computing/people/eldar-insafutdinov/\">E.  Insafutdinov</a>,\n\t\t\t\t\t\tMohammad Shafiei,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H-P. Seidel</a>,\n\t\t\t\t\t\t<a href=\"https://www.mpi-inf.mpg.de/de/departments/computer-vision-and-multimodal-computing/people/bernt-schiele/\" target=\"_blank\">B. Schiele</a>\n\t\t\t\t\t\t and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t  <br/>\n\t\t\t\t<i>EgoCap: Egocentric Marker-less Motion Capture with Two Fisheye Cameras</i> <br/>\n\t\t\t\t ACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2016) <br/> \t\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/EgoCap/\">[project page]</a> <a href=\"http://vcai.mpi-inf.mpg.de/projects/EgoCap/content/rhodin2016egocap.pdf\">[pdf]</a>\n\t\t\t\t</td>  \n            ",
    "177": "<td>\n\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~nroberti/\"> N. Robertini</a>,\n\t\t\t\t\t\t<a href=\"http://dancasas.github.io\">D. Casas</a>,\n\t\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~hrhodin/\">H. Rhodin</a>, \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~hpseidel/\" target=\"_blank\">H-P. Seidel</a>,\n\t\t\t\t\t\t and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t  <br/>\n\t\t\t\t<i>Model-based Outdoor Performance Capture</i> <br/>\n\t\t\t\t International Conference on 3D Vision, 3DV 2016 <br/> \t\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/OutdoorPerfcap/\">[project page]</a> <a href=\"http://vcai.mpi-inf.mpg.de/projects/OutdoorPerfcap/content/robertini_3DV2016.pdf\">[pdf]</a>\n\t\t\t\t</td>  \n            ",
    "176": "<td>\t\t\n\t\t\t\t\t\t<a href=\"http://richardt.name/\">C. Richardt</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~hyeongwoo/\">H. Kim</a>,\t\n\t\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~valgaerts/\">L. Valgaerts</a>,\t\t\t\t\t\t\n\t\t\t\t\t\t and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t\t<br/>\n\t\t\t\t<i>Dense Wide-Baseline Scene Flow From Two Handheld Video Cameras. </i> <br/>\n\t\t\t\t International Conference on 3D Vision (3DV),  2016 <br/> \t\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/SceneFlow/\">[project page]</a> <a href=\"http://vcai.mpi-inf.mpg.de/projects/SceneFlow/content/WideBaselineSceneFlow-RichardtEtAl-3DV2016-paper.pdf\">[pdf]\n\t\t\t\t</a></td>  \n\t\t\t",
    "175": "<td>\n\t\t\t  \t\t<a href=\"http://lgdv.cs.fau.de/people/card/Lucas/thies/\" target=\"_blank\">L. Thies</a>,\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&amp;oumlfer</a>, \n\t\t\t\t\t<a href=\"http://richardt.name/\" target=\"_blank\">C. Richardt</a>, \n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t<a href=\"http://lgdv.cs.fau.de/people/card/guenther/greiner/\" target=\"_blank\">G. Greiner</a>\n\t\t\t\t\t<br/>\n\t\t\t\t\t<i>   Real-time Halfway Domain Reconstruction of Motion and Geometry </i> <br/> \t\n\t\t\t\tInternational Conference on 3D Vision (3DV),  2016 <br/> \t\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/MZ/Papers/3DV2016_SF/page.html\">[project page]</a> <a href=\"http://vcai.mpi-inf.mpg.de/projects/MZ/Papers/3DV2016_SF/paper.pdf\">[pdf]</a>\n\t\t\t\t</td>  \n            ",
    "174": "<td>\n\t\t\t\t\t<a href=\"http://lgdv.cs.fau.de/people/card/justus/thies/\" target=\"_blank\">J. Thies</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t<a href=\"http://lgdv.cs.fau.de/people/card/marc/stamminger/\" target=\"_blank\">M. Stamminger</a>,\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t<a href=\"http://www.graphics.stanford.edu/~niessner/index.html\" target=\"_blank\">M. Nie&#223;ner</a>\t\t\t\n\t\t\t\t<i> Demo of Face2Face: Real-Time Face Capture and Reenactment of RGB Videos</i> <br/>\n\t\t\t\tSIGGRAPH 2016 Emerging Technologies<br/> \t\n\t\t\t\t <a href=\"http://s2016.siggraph.org/content/emerging-technologies\">[link]</a>\n\t\t\t\t</td>  \n            ",
    "173": "<td>\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t<i> Computer schneiden Grimassen</i> <br/>\n\t\t\t\tMax Planck Forschung 2016<br/> \t\n\t\t\t\t <a href=\"https://www.mpg.de/10659859/W003_Material_Technik_054-061.pdf\">[link]</a>\n\t\t\t\t</td>  \n            ",
    "172": "<td>\n\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~hrhodin/\">H. Rhodin</a>, \n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~nroberti/\"> N. Robertini</a>,\n\t\t\t\t\t\t<a href=\"http://dancasas.github.io\">D. Casas</a>,\n\t\t\t\t\t\t<a href=\"http://richardt.name/\" target=\"_blank\">C. Richardt</a> \n\t\t\t\t\t\tH-P. Seidel and\n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t  <br/>\n\t\t\t\t<i>General Automatic Human Shape and Motion Capture Using Volumetric Contour Cues</i> <br/>\n\t\t\t\tECCV 2016 <br/> \t\n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/VolumetricContourCues/\">[project page]</a> <a href=\"http://vcai.mpi-inf.mpg.de/projects/VolumetricContourCues/content/rhodin2016automatic.pdf\">[pdf]</a>\n\t\t\t\t</td>  \n            ",
    "171": "<td>\n\t\t\t\t  \t\t<a href=\"http://people.mpi-inf.mpg.de/~ssridhar/\">S. Sridhar</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~frmueller/\">F. Mueller</a>,\n\t\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&amp;oumlfer</a>, \n\t\t\t\t\t\t<a href=\"http://dancasas.github.io\">D. Casas</a>,\n\t\t\t\t\t\t<a href=\"http://users.comnet.aalto.fi/oulasvir/\">A. Oulasvirta</a> and \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t  <br/>\n\t\t\t\t<i>Real-time Joint Tracking of a Hand Manipulating an Object from RGB-D Input</i> <br/>\n\t\t\t\tECCV 2016 <br/> \t\n\t\t\t\t<a href=\"http://handtracker.mpi-inf.mpg.de/projects/RealtimeHO/\">[project page]</a> <a href=\"http://handtracker.mpi-inf.mpg.de/projects/RealtimeHO/content/RealtimeHO_ECCV2016.pdf\">[pdf]</a>\n\t\t\t\t</td>  \n            ",
    "170": "<td>\n\t\t\t\t  \t\t<a href=\"http://people.mpi-inf.mpg.de/~ssridhar/\">S. Sridhar</a>,\n\t\t\t\t\t\tG. Bailly,\n\t\t\t\t\t\tE. Heydrich, \n\t\t\t\t\t\t<a href=\"http://users.comnet.aalto.fi/oulasvir/\">A. Oulasvirta</a> and \n\t\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a>\n\t\t\t\t\t  <br/>\n\t\t\t\t<i>FullHand: Markerless Skeleton-based Tracking for Free-Hand Interaction</i> <br/>\n\t\t\t\tMPI-I-2016-4-002. Saarbr&#195;&#188;cken: Max-Planck-Institut f&#195;&#188;r Informatik 2016. <br/> \t\n\t\t\t\t<a href=\"http://pubman.mpdl.mpg.de/pubman/faces/viewItemOverviewPage.jsp?itemId=escidoc:2347450\"> [Pubman] </a><a href=\"http://people.mpi-inf.mpg.de/~ssridhar/pubs/MPI-I-2016-4-002.pdf\">[pdf]</a>\n\t\t\t\t</td>  \n            ",
    "169": "<td>\n\t\t\t\t\t  <a href=\"http://www.mpi-inf.mpg.de/~ameka/\" target=\"_blank\">A. Meka</a>,\n\t\t\t\t\t  <a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&#246;fer</a>,\n\t\t\t\t\t  <a href=\"http://richardt.name/\" target=\"_blank\">C. Richardt</a> and\n\t\t\t\t\t  <a href=\"http://www.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a><br/>\n\t\t\t\t<i>Live Intrinsic Video</i> <br/>\n\t\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH 2016). <br/> \t\n\t\t\t\t<a href=\"projects/LiveIntrinsicVideo/\">[project page]</a>\n\t\t\t\t</td>  \n            ",
    "168": "<td>\n\t\t\t\t\t<a href=\"http://lgdv.cs.fau.de/people/card/justus/thies/\" target=\"_blank\">J. Thies</a>,\n\t\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~mzollhoef/\" target=\"_blank\">M. Zollh&amp;oumlfer</a>,\n\t\t\t\t\t<a href=\"http://lgdv.cs.fau.de/people/card/marc/stamminger/\" target=\"_blank\">M. Stamminger</a>,\n\t\t\t\t\t<a href=\"https://people.mpi-inf.mpg.de/~theobalt/\" target=\"_blank\">C. Theobalt</a> and\n\t\t\t\t\t<a href=\"http://www.graphics.stanford.edu/~niessner/index.html\" target=\"_blank\">M. Nie&#223;ner</a>\n\t\t\t\t\t<br/>\n\t\t\t\t\t<i>Face2Face: Real-time Face Capture and Reenactment of RGB Videos</i><br/>\n\t\t\t\t\tProc. Computer Vision and Pattern Recognition (Oral) (CVPR 2016)<br/>\n                    <a href=\"projects/MZ/Papers/CVPR2016_FF/page.html\">[project page]</a> \n\t\t\t\t\t<a href=\"projects/MZ/Papers/CVPR2016_FF/paper.pdf\">[pdf]</a>\n\t\t\t\t</td>\n\t\t\t",
    "167": "<td>\n\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~pgarrido/\">P. Garrido</a>, <a href=\"http://people.mpi-inf.mpg.de/~mzollhoef/\">M. Zollh&#246;fer</a>, <a href=\"http://dancasas.github.io\">D. Casas</a>, <a href=\"http://www.mpi-inf.mpg.de/~valgaerts/\">L. Valgaerts</a>, K. Varanasi, P. Perez and <a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a><br/>\n\t\t\t\t<i>Reconstruction of Personalized 3D Face Rigs from Monocular Video</i><br/>\n\t\t\t\tACM Transactions on Graphics (TOG), 2016. (To be presented at SIGGRAPH 2016)<br/>\n                                <a href=\"http://vcai.mpi-inf.mpg.de/projects/PersonalizedFaceRig/\">[project page]</a> <a href=\"http://vcai.mpi-inf.mpg.de/files/TOG2016/PersonalizedFaceRig.pdf\">[pdf low res]</a>\n\t\t\t\t</td>\n\t\t\t",
    "166": "<td width=\"130\">\n\t\t\t</td>",
    "165": "<td>\n\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~ssridhar/\">S. Sridhar</a>, A. Oulasvirta and <a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a><br/>\n\t\t\t\t<i>Fast Tracking of Hand and Finger Articulations Using a Single Depth Camera</i><br/>\n\t\t\t\tTechnical Report MPI-I-2014-4-002. Saarbr&#195;&#188;cken: Max-Planck-Institut f&#195;&#188;r Informatik 2015.<br/>\n                <a href=\"files/MPI-I-2014-4-002.pdf\">[pdf]</a>\n\t\t\t\t</td>\n\t\t\t",
    "164": "<td>\n\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~hrhodin/\">H. Rhodin</a>, <a href=\"http://people.mpi-inf.mpg.de/~nroberti/\"> N. Robertini</a>, <a href=\"http://richardt.name\">C. Richardt</a>, H-P. Seidel and <a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a><br/>\n\t\t\t\t<i>A Versatile Scene Model with Differentiable Visibility Applied to Generative Pose Estimation</i><br/>\n\t\t\t\tInternational Conference on Computer Vision (ICCV), 2015<br/>\n                                <a href=\"https://vcai.mpi-inf.mpg.de/projects/DiffVis/\">[project page]</a> <a href=\"https://vcai.mpi-inf.mpg.de/projects/DiffVis/Rhodin2015DiffVis.pdf\">[pdf]</a>\n\t\t\t\t</td>\n\t\t\t",
    "163": "<td>\n\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/~kkim/\">K. In Kim</a>, <a href=\"http://www.jamestompkin.com/\">J. Tompkin</a>, <a href=\"http://vcg.seas.harvard.edu/people/hanspeter-pfister\">H. Pfister</a> and <a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a><br/>\n\t\t\t\t<i>Context-guided Diffusion for Label Propagation on Graphs</i><br/>\n\t\t\t\tInternational Conference on Computer Vision (ICCV), 2015<br/>\n\t\t\t\t[project page] [pdf]\n\t\t\t\t</td>\n\t\t\t",
    "162": "<td><a href=\"http://lgdv.cs.fau.de/people/card/justus/thies/\">J. Thies</a>, <a href=\"http://people.mpi-inf.mpg.de/~mzollhoef/\">M. Zollh&#246;fer</a>, <a href=\"http://www.graphics.stanford.edu/~niessner/\">M. Nie&#223;ner</a>, L. Valgaerts, M. Stamminger and C. Theobalt<br/>\n\t\t\t<i>Real-time Expression Transfer for Facial Reenactment </i><br/>\n\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH Asia 2015).<br/>\n\t\t\t<a href=\"projects/MZ/Papers/SGASIA2015_RR/page.html\">[project page]</a> <a href=\"projects/MZ/Papers/SGASIA2015_RR/paper.pdf\">[pdf]</a>\n\t\t\t</td>\n\t\t\t",
    "161": "<td>\n\t\t\t\t<a href=\"http://dancasas.github.io\">D. Casas</a>, <a href=\"http://richardt.name\">C. Richardt</a>, <a href=\"http://collomosse.com\">J. Collomosse</a>, <a href=\"https://people.mpi-inf.mpg.de/~theobalt/\">C. Theobalt</a> and <a href=\"http://kahlan.eps.surrey.ac.uk/Personal/AdrianHilton/Welcome.html\">A. Hilton</a><br/>\n<i>4D Model Flow: Precomputed Appearance Alignment for Real-time 4D Video Interpolation</i><br/>\n\t\t\tComputer Graphics Forum (Proc. Pacific Graphics 2015)<br/>\n\t\t\t<a href=\"http://richardt.name/publications/4d-model-flow/\">[project page]</a> <a href=\"files/casas_PG15.pdf\">[pdf]</a> <br/>\n\t\t\t</td>\n\t\t\t",
    "160": "<td>\n\t\t\tC. Richardt, J. Tompkin, J. Bai, and C. Theobalt<br/>\n\t\t\t<i>User-Centric Computational Videography</i><br/>\n\t\t\tCourse at SIGGRAPH 2015<br/>\n\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/teaching/uccv_course_2015/\">[course page]</a><br/>\n\t\t\t</td>\n            ",
    "159": "<td>\n\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~mzollhoef/\">M. Zollh&#246;fer</a>, A. Dai, M. Innmann, C. Wu, M. Stamminger, C. Theobalt, and <a href=\"http://www.graphics.stanford.edu/~niessner/\">M. Nie&#223;ner</a>. <br/>\n\t\t\t<i> Shading-based Refinement on Volumetric Signed Distance Functions. </i> <br/>\n\t\t\tACM Transactions on Graphics (Proc. of SIGGRAPH 2015).<br/>\n\t\t\t<a href=\"projects/MZ/Papers/SG2015_VSBR/page.html\">[project page]</a> <a href=\"projects/MZ/Papers/SG2015_VSBR/paper.pdf\">[pdf]</a>\n\t\t\t<br/>\n\t\t\t</td>  \n            ",
    "158": "<td>\n\t\t\tK. I. Kim, J. Tompkin, H. Pfister, and C. Theobalt. <br/>\n\t\t\t<i> Local High-order Regularization on Data Manifolds. </i> <br/>\n\t\t\tIn Proc. of Computer Vision and Pattern Recognition (CVPR) 2015. <br/>\n\t\t\t<a href=\"projects/hreg/index.html\">[project page]</a> <a href=\"projects/hreg/LocalHighorderRegularizationonDataManifoldsCVPR2015.pdf\">[pdf]</a>\n\t\t\t<br/>\n\t\t\t</td>  \n            ",
    "157": "<td>\n\t\t\tK. I. Kim, J. Tompkin, H. Pfister, and C. Theobalt. <br/>\n\t\t\t<i> Semi-supervised Learning with Explicit Relationship Regularization. </i> <br/>\n\t\t\tIn Proc. of Computer Vision and Pattern Recognition (CVPR) 2015. <br/>\n\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~kkim/relreg/index.html\">[project page]</a> <a href=\"http://people.mpi-inf.mpg.de/~kkim/relreg/SemisupervisedLearningwithExplicitRelationshipRegularizationCVPR2015.pdf\">[pdf]</a><br/>\n\t\t\t</td>  \n            ",
    "156": "<td>\n\t\t\t<br/> \n\t\t\tS. Sridhar, <a href=\"http://people.mpi-inf.mpg.de/~frmueller/\">F. Mueller</a>, A. Oulasvirta, and C. Theobalt. <br/>\n\t\t\t<i> Fast and Robust Hand Tracking Using Detection-Guided Optimization. </i> <br/>\n\t\t\tIn Proc. of Computer Vision and Pattern Recognition (CVPR) 2015. <br/>\n\t\t\t<a href=\"http://handtracker.mpi-inf.mpg.de/projects/FastHandTracker/\">[project page] </a>\n\t\t\t<br/>\n\t\t\t</td>  \n            ",
    "155": "<td>\n\t\t\tA. Elhayek, E. Aguiar, A. Jain, J. Tompson, L. Pishchulin, M. Andriluka, C. Bregler, B. Schiele C. Theobalt,<br/>\n\t\t\t<i> Efficient ConvNet-based Marker-less Motion Capture in General Scenes with a Low Number of Cameras</i> <br/>\n\t\t\tIn Proc. of Computer Vision and Pattern Recognition (CVPR) 2015. <br/> \t\n\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/convNet_moCap/\">[project page] </a>\t\t\t\t\t\t\n\t\t\t</td>  \n            ",
    "154": "<td>\n\t\t\t\t\t<br/> M. Granados, T. Aydin, J. R. Tena, J.-F. Lalonde, and C. Theobalt,<br/>\n\t\t\t\t\t <i>Contrast Use Metrics for Tone Mapping Images</i><br/>\n\t\t\t\t\t IEEE International Conference on Computational Photography (ICCP), 2015.   <br/>\n\t\t\t\t\t<a href=\"files/granados_iccp_15.pdf\">[pdf]</a>\t\t\t\n\t\t\t   </td>  \n            ",
    "153": "<td>\n\t\t\t\tM. A. Magnor, O. Grau, O. Sorkine-Hornung, C. Theobalt,<br/> \n\t\t\t\t<i><a href=\"http://www.crcpress.com/product/isbn/9781482243819\">Digital Representations of the Real World: How to Capture, Model, and Render Visual Reality</a></i><br/> \n\t\t\t\tISBN: 9781482243819 - CAT# K23451, Publisher: CRC Press, 2015.<br/> \n            </td>\n\n\t\t\t",
    "152": "<td>\n\t\t\t\t\t<br/> S. Sridhar, A. M. Feit, C. Theobalt, A. Oulasvirta,<br/>\n\n\t\t\t\t\t<i>Investigating the Dexterity of Multi-Finger Input for Mid-Air Text Entry</i><br/>\n\t\t\t\t\tProc. of SIGCHI Conference on Human Factors in Computing Systems (CHI) 2015.  <br/> \t\n\t\t\t\t\t<a href=\"http://handtracker.mpi-inf.mpg.de/projects/HandDexterity/\">[project page]</a> <a href=\"http://handtracker.mpi-inf.mpg.de/projects/HandDexterity/content/AirType_CHI2015.pdf\">[pdf]</a>\t\n\t\t\t   </td>  \n            ",
    "151": "<td>\n\t\t\t\t\t<br/> P. Garrido , L. Valgaerts , H. Sarmadi , I. Steiner , K. Varanasi , P. Perez , C. Theobalt,<br/>\n\n\t\t\t\t\t<i>VDub: Modifying Face Video of Actors for Plausible Visual Alignment to a Dubbed Audio Track</i><br/>\n\t\t\t\t\t\n\t\t\t\t\tComputer Graphics Forum (Proc. Eurographics 2015).  <br/> \t\n\t\t\t\t\t<a href=\"projects/VisualDubbing/\">[project page]</a> <a href=\"http://vcai.mpi-inf.mpg.de/files/EuroGraphics2015/dubbing.pdf\">[pdf low res]</a>\t\t\t\t\n\t\t\t   </td>  \n            ",
    "150": "<td>\n\t\t\t\t\t<br/> Y. Kwon, K. I. Kim, J. Tompkin, JH. Kim, C. Theobalt<br/>\n\n\t\t\t\t\t<i>Efficient Learning of Image Super-resolution and Compression Artifact Removal with Semi-local Gaussian Processes</i><br/>\n\t\t\t\t\tIEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) 2015.<br/>\n\t\t\t\t\t<a href=\"projects/ImageEnhancement/\">[project page]</a> <a href=\"http://vcai.mpi-inf.mpg.de/projects/ImageEnhancement/EfficientLearning-basedImageEnhancement_TPAMI2014_Paper.pdf\">[pdf]</a>\n\t\t\t\t</td>  \n            ",
    "149": "<td width=\"130\">\n\t\t\t\t</td>",
    "148": "<td>\n\t\t\t\t\t<br/> S. Sridhar, H. Rhodin, H.-P. Seidel, A. Oulasvirta, C. Theobalt,<br/>\n\n\t\t\t\t\t<i>Real-time Hand Tracking Using a Sum of Anisotropic Gaussians Model</i><br/>\n\t\t\t\t\t\n\t\t\t\t\tAccepted at the International Conference on 3D Vision (3DV), 2014.  <br/> \t\n\t\t\t\t\t<a href=\"http://handtracker.mpi-inf.mpg.de/projects/ellipsoidtracker_3dv2014/\">[project page]</a>\t\t\t\t\t \t\t\t\t\t\n\t\t\t   </td>  \n            ",
    "147": "<td>\n\t\t\t\t\t<br/> N. Robertini, E. de Aguiar, T. Helten, C. Theobalt,<br/>\n\n\t\t\t\t\t<i>Efficient Multi-view Performance Capture of Fine-Scale Surface Detail</i><br/>\n\t\t\t\t\t\n\t\t\t\t\tInternational Conference on 3D Vision (3DV), 2014.  <br/>\n\t\t\t\t\t<a href=\"http://people.mpi-inf.mpg.de/~nroberti/papers/3dv2014_GaussSurfRef.pdf\">[pdf]</a>\n\t\t\t\t</td>  \n            ",
    "146": "<td>\n\t\t\t\t\t<br/> A. Elhayek, C. Stoll, K. I. Kim, C. Theobalt,<br/>\n\n\t\t\t\t\t<i>Outdoor Human Motion Capture by Simultaneous Optimization of Pose and Camera Parameters</i><br/>\n\t\t\t\t\t\n\t\t\t\t\tComputer Graphics Forum (CGF), 2014.  <br/> \n\t\t\t\t\t <a href=\"files/CGF_2014/OutdoorHumanMotionCapture.pdf\"> [pdf]</a> \t\n\t\t\t\t\t<a href=\"files/CGF_2014/OutdoorHumanMotionCapture.mp4\">[video]</a> \t\t\n\t\t\t\t\t<a href=\"projects/outdoorsHMC/\">[project page]</a>\t\t\t\t\t\t\n\t\t\t   </td>  \n            ",
    "145": "<td>\n\t\t\t\t\t<br/> C. Wu, M. Zollh&#246;fer, M. Nie&#223;ner, M. Stamminger, S. Izadi, C. Theobalt,<br/>\n\n\t\t\t\t\t<i>Real-time Shading-based Refinement for Consumer Depth Cameras</i><br/>\n\t\t\t\t\t\n\t\t\t\t\tAccepted at SIGGRAPH Asia 33 (6), 200:1--200:10 (2014).   <br/> \n\t\t\t\t\t<a href=\"/projects/RealTimeSFS/\">[project page]</a>\t\t\t\t   \n\t\t\t   </td>  \n            ",
    "144": "<td>\n\t\t\t\t\t<br/>T. Neumann, K. Varanasi, C. Theobalt, M. Magnor, M. Wacker,<br/>\n\n\t\t\t\t\t<i>Compressed Manifold Modes for Mesh Processing</i><br/>\n\t\t\t\t\t\n\t\t\t\t\tComputer Graphics Forum (Proc. of Symposium on Geometry Processing SGP), vol. 33, no. 5, pp. 1&#226;&#128;&#147;10, Eurographics Association, 2014.  <br/> \n\t\t\t\t\t\t <a href=\"files/CMM14.pdf\"> [pdf]</a> \t\t   \n\t\t\t   </td>  \n            ",
    "143": "<td>\n\t\t\t\t\t<br/>M. Zollh&#246;fer, M. Nie&#223;ner, S. Izadi, C. Rheman, C. Zach, M. Fisher, C. Wu, A. Fitzgibbon, C. Loop, C. Theobalt, M. Stamminger,<br/>\n\n\t\t\t\t\t<i>Real-time Non-rigid Reconstruction using an RGB-D Camera</i><br/>\n\t\t\t\t\t\n\t\t\t\t\tAccepted at ACM Transactionson Graphics 33 (4) (Proc. SIGGRAPH), 156:1-156:12 (2014).<br/> \n\t\t\t\t\t<a href=\"projects/RealTimeNRR/\">[project page]</a>\t\n\t\t\t    </td>  \n            ",
    "142": "<td>\n\t\t\t\t\t<br/>P. Garrido , L. Valgaerts, O. Rehmsen, T. Thormaehlen, P. Pere, and C. Theobalt,<br/>\n\n\t\t\t\t\t<i>Automatic Face Reenactment</i><br/>\n\t\t\t\t\t\n\t\t\t\t\tAccepted at CVPR, 4217-4224 (2014).<br/> \n\t\t\t\t\t<a href=\"/projects/FaceReenactment/\">[project page]</a>\n\t\t\t    </td>  \n            ",
    "141": "<td>\n\t\t\t\t\t<br/>H. Rhodin, J. Tompkin, K.I. Kim, K. Varanasi, H-P Seidel, C. Theobalt,<br/>\n\n\t\t\t\t\t<i>Interactive Motion Mapping for Real-time Character Control</i><br/>\n\t\t\t\t\t\n\t\t\t\t\tComputer Graphics Forum (Proceedings Eurographics)33, 273&#226;&#128;&#147;282 (2014).<br/> \n\t\t\t\t\t\t<a href=\"projects/DirectMotionMapping/Rhodin2014_InteractiveMotionMapping.pdf\"> [pdf]</a> \n\t\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/DirectMotionMapping/index.html\">  [project page]</a> <br/>\t\t\n\t\t\t\t</td>  \n            ",
    "140": "<td>\n\t\t\t\tY. Liu, G. Ye, Y. Wang, Q. Dai, C. Theobalt,\n\t\t\t\t<i><a href=\"http://link.springer.com/chapter/10.1007/978-3-319-08651-4_5#page-1\">Human Performance Capture Using Multiple Handheld Kinects </a></i> in Computer Vision and Machine Learning with RGBD Sensors.\n\t\t\t\tISBN: 978-3-319-08650-7 (Print) 978-3-319-08651-4 (Online), Publisher: Springer, 2014.\n            </td>\n\n        ",
    "139": "<td>\n\t\t\t\t\tD. Khattab, C. Theobalt, AS. Hussein, MF. Tolba<br/>\n\t\t\t\t\t<i>Modified GrabCut for human face segmentation</i><br/>\n\t\t\t\t\tAin Shams Engineering Journal 5 (4), 1083 - 1091 (2014)<br/>\n\t\t\t\t\t<a href=\"files/khattab_2014.pdf\">[pdf]</a>\n\t\t\t\t</td>  \n            ",
    "138": "<td>\n\t\t\t\t\t<br/>F. Pece, J. Tompkin, H. Pfister, J. Kautz, C. Theobalt,<br/>\n\n\t\t\t\t\t<i>Device Effect on Panoramic Video+Context Tasks</i><br/>\n\t\t\t\t\t\n\t\t\t\t\tProceedings of European Conference on Visual Media Production (CVMP) 2014.\t\n\t\t\t\t</td>  \n            ",
    "137": "<td>\n\t\t\t\t\t\tK.I. Kim, J. Tompkin, C. Theobalt,<br/>\n\t\t\t\t\t\t<i>Local High-order Regularization on Data Manifolds</i><br/>\n                            MMPI-I-2014-4-001, 2014. \t\n\t\t\t\t</td>  \n            ",
    "136": "<td>\n                <br/>\t\t\n\t\t\t\t\tS. Sridhar, A. Oulasvirta, C. Theobalt,<br/>\n\t\t\t\t\t<i>Fast Tracking of Hand and Finger Articulations Using a Single Depth Camera</i><br/>\n                    MPI-I-2014-4-002. Saarbr&#195;&#188;cken: Max-Planck-Institut f&#195;&#188;r Informatik 2015.     \n\t\t\t</td>\n        ",
    "135": "<td width=\"130\">\n\t\t\t\t</td>",
    "134": "<td>\n\n                <br/> T. Neumann, K. Varanasi, S. Wenger, M. Wacker, M. Magno, C. Theobalt,<br/>\n\n                <i>Sparse localized deformation components</i><br/>\n\t\t\t\t\n\t\t\t\tSIGGRAPH Asia 2013.<br/> \n\t\t\t\t\t <a href=\"files/splocs.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"files/splocs2.pdf\">[supplementary material]</a>\n                    <a href=\"http://www.youtube.com/watch?v=87bdnpOemyk\">[video]</a> \n\t\t\t\t\t<a href=\"http://www.drematrix.de/?portfolio=english-sparse-localized-deformation-components&amp;lang=en\">  [project page]</a> <br/>\n\t\t\t\t\t\t\t\n            </td>\n\t\t\t\n\n        ",
    "133": "<td>\n\n                <br/> N. Robertini, T. Neumann, K. Varanasi, and C. Theobalt,<br/>\n\n                <i>Capture of arm muscle deformations using a depth camera</i><br/>\n\t\t\t\t\n\t\t\t\tProceedings of CVMP, 12:1--12:10 (2013).\n\t\t\t\t<a href=\"files/kinmusc.pdf\"> [pdf]</a> \t\t\t\n            </td>\n\t\t\t\n\n        ",
    "132": "<td>\n\n                <br/> T. Helten, M. M&#252;ller, and H.-P. Seidel, and C. Theobalt,<br/>\n\n                <i> Real-time Body Tracking with One Depth Camera and Inertial Sensors</i><br/>\n\t\t\t\t\n\t\t\t\t In 2013 IEEE International Conference on Computer Vision (ICCV) Sydney, Australia, 1105-1112, 2013.\t\t\n\t\t\t\t<a href=\"http://gvvperfcapeva.mpi-inf.mpg.de/public/InertialDepthTracker/index.php\"> [project]</a> \n\t\t\t\t \n            </td>\n\t\t\t\n\n        ",
    "131": "<td>\n\n                <br/> S. Sridhar, A. Oulasvirta, and C. Theobalt,<br/>\n\n                <i> Interactive Markerless Articulated Hand Motion Tracking using RGB and Depth Data</i><br/>\n\t\t\t\t\n\t\t\t\t In 2013 IEEE International Conference on Computer Vision (ICCV), Sydney, Australia, 2456 - 2463 (2013).\t\t\t\t\n\t\t\t\t <a href=\"http://handtracker.mpi-inf.mpg.de/projects/handtracker_iccv2013/\">  [project page]</a> \n\t\t   </td>\n\t\t\t\n\n        ",
    "130": "<td>\n\n                <br/>C. Wu, C. Stoll, L. Valgaerts, C. Theobalt,<br/>\n\n                <i> On-set Performance Capture of Multiple Actors With A Stereo Camera</i><br/>\n\t\t\t\t\n\t\t\t\t In ACM Transactions on Graphics (Proc. of SIGGRAPH Asia) 32, 1-11 (2013).\n\t\t\t\t\t<a href=\"/projects/BinoCap/\">  [project page]</a> \t\t\t\t\n            </td>\n\t\t\t\n\n        ",
    "129": "<td>\n\n                <br/>P. Garrido, L. Valgaerts, C. Wu, C. Theobalt,<br/>\n\n                <i> Reconstructing Detailed Dynamic Face Geometry from Monocular Video</i><br/>\n\t\t\t\t\n\t\t\t\t In ACM Transactions on Graphics (Proc. of SIGGRAPH Asia) 32, 158:1-158:10 (2013).\n\t\t\t\t\t<a href=\"/projects/MonFaceCap/\">  [project page]</a> \t\t\t\t\n            </td>\n\t\t\t\n\n        ",
    "128": "<td>\n\n                <br/>J. Tompkin, M.H. Kim, K.I. Kim, J. Kautz, C. Theobalt,<br/>\n\n                <i> Preference and Artifact Analysis of Video Transitions of Places</i><br/>\n\t\t\t\t\n\t\t\t\t In ACM Transactions on Applied Perception vol. 10 (3), 13:1-13:19 (2013).\n\t\t\t\t\t<a href=\"/projects/VideoTransitionsOfPlaces/\">[project page]</a> \t\t\t\t\n            </td>\n\t\t\t\n\n        ",
    "127": "<td>\n\n                <br/>J. Tompkin, F. Pece, R. Shah, S. Izadi, J. Kautz, C. Theobalt,<br/>\n\n                <i> Video Collections in Panoramic Contexts</i><br/>\n\t\t\t\t\n\t\t\t\tin: UIST, 131 - 140 (2013).\n\t\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/Vidicontexts/\">[project page]</a>\t\t\t\t\n            </td>\n\t\t\t\n\n        ",
    "126": "<td>\n\n                <br/> M. Granados, K. I. Kim, J. Tompkin, C. Theobalt,<br/>\n\n                <i> Automatic Noise Modeling for Ghost-free HDR Reconstruction</i><br/>\n\t\t\t\t\n\t\t\t\tIn ACM Transactions on Graphics (Proc. of SIGGRAPH Asia) 32, 201:1-201:10 (2013). \n\t\t\t\t\t<a href=\"files/SIGGRAPH_ASIA_2013/granados13_hdrdeghosting.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"files/SIGGRAPH_ASIA_2013/granados13_hdrdeghosting_video.mp4\">[video]</a> \n\t\t\t\t\t<a href=\"/projects/hdrdeghosting/index.html\">  [project page]</a> <br/>\t\t\t\t\t\n            </td>\n\t\t\t\n\n        ",
    "125": "<td>\n\n                <br/> K. I. Kim, J. Tompkin, C. Theobalt,<br/>\n\n                <i>Curvature-aware regularization on Riemannian submanifolds</i><br/>\n\t\t\t\t\n\t\t\t\t in: ICCV, 881-888 (2013).\t\t\t\t\t\t\t\t\t\t  \n            </td>\n\t\t\t\n\n        ",
    "124": "<td>\n\n                <br/>Y. Liu, J. Gall, C. Stoll, Q. Dai, H.-P. Seidel, C. Theobalt,<br/>\n\n                <i>Markerless Motion Capture of Multiple Characters Using Multi-view Image Segmentation</i><br/>\n\t\t\t\t\n\t\t\t\taccepted in IEEE Transaction on PAMI 2013. \n\t\t\t\t <a href=\"files/pami2013/jgall_motioncapture_multiple_pami13.pdf\"> [pdf]</a> \n\t\t\t\t <a href=\"files/pami2013/pami_video.mp4\"> [video]</a> \t\t\t\t\t\t\t\t\t\t  \n            </td>\n\n        ",
    "123": "<td>\n\n                <br/>\n\n                T. Helten, A. Baak, G. Bharaj, M. M&#195;&#188;ller, H.-P. Seidel, C. Theobalt,<br/>\n\n                <i> Personalization and Evaluation of a Real-time Depth-based Full Body Tracker</i><br/>\n\t\t\t\t\n\t\t\t\tin proceedings of 3DV, 279-286, 2013. \n\t\t\t\t<a href=\"files/3DV2013/PersonalizedDepthTracker.pdf\"> [pdf]</a> \n\t\t\t\t<a href=\"files/3DV2013/PersonalizedDepthTracker.mp4\"> [video]</a> \t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n\n        ",
    "122": "<td>\n\n                <br/>\n\n                T. Neumann, K. Varanasi, N. Hasler, M. Wacker, M. Magnor, C. Theobalt,<br/>\n\n                <i> Capture and statistical modeling of arm-muscle deformations</i><br/>\n\t\t\t\t\n\t\t\t\tin Computer Graphics Forum (Proc. Eurographics) 32, 285-294 (2013). \n\t\t\t\t<a href=\"files/EuroGraphics2013/arnie.pdf\"> [pdf]</a> \n\t\t\t\t<a href=\"files/EuroGraphics2013/arnie.avi\"> [video]</a> \n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n\n        ",
    "121": "<td>\n\n                <br/>\n\n                G. Li, C. Wu, C. Stoll, Y. Liu, K. Varanasi, Q. Dai, C. Theobalt,<br/>\n\n                <i> Capturing Relightable Human Performances under General Uncontrolled Illumination</i><br/>\n\t\t\t\t\n\t\t\t\tin Computer Graphics Forum (Proc. Eurographics) 32, 1-8 (2013). \n\t\t\t\t<a href=\"files/EuroGraphics2013/relightPaper-EGconf-fin.pdf\"> [pdf]</a> \n\t\t\t\t<a href=\"files/EuroGraphics2013/RelightablePerfCap_eg_cameraready.mp4\"> [video]</a> \n\t\t\t\t<a href=\"http://vcai.mpi-inf.mpg.de/projects/RelightablePerfCap/index.html\">  [project page]</a> <br/>\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n\n        ",
    "120": "<td>\n\t\t\t\tM. Grzegorzek, C. Theobalt, R. Koch, A. Kolb (Eds.),\n\t\t\t\t<i><a href=\"http://link.springer.com/book/10.1007%2F978-3-642-44964-2\">Time-of-Flight and Depth Imaging. Sensors, Algorithms, and Applications </a></i>,\n\t\t\t\tISBN: 978-3-642-44963-5 (Print) 978-3-642-44964-2 (Online), Publisher: Springer, 2013.\n            </td>\n\n        ",
    "119": "<td>\n\t\t\t\tT. Helten,  A. Baak, M. M&#220;ller, C. Theobalt, \n\t\t\t\t<i> <a href=\"http://link.springer.com/chapter/10.1007%2F978-3-642-44964-2_9\"> Full-body Human Motion Capture from Monocular Depth Images </a></i>, in \n\t\t\t\tTime-of-Flight and Depth Imaging,\n\t\t\t\tISBN 978-3-642-44963-5; 978-3-642-44964-2, Publisher: Springer, 2013.\n\n            </td>\n\n        ",
    "118": "<td>\n\t\t\t\tK. Fatahalian, C. Theobalt, J. Lehtinen,\n\t\t\t\t<i>High-Performance Graphics</i>,\n\t\t\t\tAnaheim, California, USA, July 19-21, 2013. Proceedings. ACM 2013, ISBN 978-1-4503-2135-8\n\n            </td>\n\n        ",
    "117": "<td>\n\t\t\t\tF. Lenzen, K. I. Kim, H. Sch&#195;&#164;fer, R. Nair, S. Meister, F. Becker, C. S. Garbe, C. Theobalt,\n\t\t\t\t<i>Denoising Strategies for Time-of-Flight Data</i>, in \n\t\t\t\t A State-of-the-Art Survey on Time-of-Flight and Depth Imaging: Sensors, Algorithms, \n\t\t\t\t and Applications, Publisher: Springer, 2013.\n\n            </td>\n\n        ",
    "116": "<td>\n                <br/>\n\n                Y. Cui, S. Schuon, S. Thrun, D. Stricker, C. Theobalt,<br/>\n\n                <i> Algorithms for 3D shape scanning with a depth camera</i><br/>\n\t\t\t\t\n\t\t\t\t Transaction on PAMI 35, 1039-1050 (2013).  \n\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n        ",
    "115": "<td>\n                <br/>\n\n                G. Ye, Y. Liu, Y. Deng, N. Hasler, X. Ji, Q. Dai, C. Theobalt,<br/>\n\n                <i>Free-viewpoint Video of Human Actors using Multiple Handheld Kinects</i><br/>\n\t\t\t\t\n\t\t\t\t accepted in IEEE Trans. System, Man &amp; Cybernetics Part B, vol. 43 (5), 1370-1382 (2013).  \n\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n        ",
    "114": "<td>\n                <br/>\n\n                D. Kurmankhojayev, N. Hasler, C. Theobalt,<br/>\n\n                <i>Monocular Pose Capture with a Depth Camera Using a Sums-of-Gaussians Body Model</i><br/>\n\t\t\t\t\n\t\t\t\t in: Pattern Recognition (DAGM/GCPR) 35, 415 - 425 (2013). \n\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n        ",
    "113": "<td>\n                <br/>\n\n                C. Rupprecht, O. Pauly, C. Theobalt, S. Ilic,<br/>\n\n                <i>3D Semantic Parameterization for Human Shape Modeling: Application to 3D Animation</i><br/>\n\t\t\t\t\n\t\t\t\t in proceedings of 3DV, 255 - 262 (2013).\n\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n        ",
    "112": "<td width=\"130\">\n\t\t\t\t</td>",
    "111": "<td>\n\n                <br/>\n\n                L. Valgaerts, C. Wu, A. Bruhn, H.-P. Seidel, C. Theobalt,<br/>\n\n                <i> Lightweight Binocular Facial Performance Capture under Uncontrolled Lighting</i><br/>\n\n                in ACM Transactions on Graphics (Proc. SIGGRAPH ASIA), 31 (6), 1-11 (2012). \n\t\t\t\t\t<a href=\"files/SIGGRAPH_ASIA_2012/facecap.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"files/SIGGRAPH_ASIA_2012/facecap_supplementary_material.pdf\">[supplementary material]</a>\n                    <a href=\"files/SIGGRAPH_ASIA_2012/facecap.avi\">[video]</a>\n\t<a href=\"/projects/FaceCap/index.html\">\n  [project page]</a>\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n\n        ",
    "110": "<td>\n\n                <br/>\n\n                M. Granados, K. I. Kim, J. Tompkin, J. Kautz, C. Theobalt,<br/>\n\n                <i> Background inpainting for videos with dynamic objects and a free-moving camera</i><br/>\n\n                in: ECCV, 682 - 695 (2012).\n\t\t\t   <a href=\"files/ECCV2012/granados12b_vidbginp.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"projects/vidbginp/granados12b_vidbginp.mp4\">[video]</a> \t\t\t   \n\t\t\t   <a href=\"projects/vidbginp/index.html\">[project page]</a>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n\n        ",
    "109": "<td>\n\n    G. Ye, Y. Liu, N. Hasler, X. Ji, Q. Dai, C. Theobalt. <br/> <i>Performance Capture of Interacting Characters with Handheld Kinects.</i> in: ECCV, 272 - 285 (2012). <a href=\"files/ECCV2012/KinectCap/KinectsMocap.pdf\">[pdf]</a> <a href=\"http://gvvperfcapeva.mpi-inf.mpg.de/public/KinectsMocap/\">[project page]</a>            <br/>\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n\n        ",
    "108": "<td>\n\n                <br/>\n\n                K. I. Kim, J. Tompkin, M. Theobald, J. Kautz, C. Theobalt,<br/>\n\n                <i> Match graph construction for large image databases</i><br/>\n\n                in European Conference on Computer Vision (ECCV), 2012.\n\t\t\t\t\t<a href=\"files/ECCV2012/MainPaper.pdf\">[pdf]</a> \n\t\t\t\t\t<a href=\"files/ECCV2012/SupplMat.pdf\">[supplementary material]</a>\n            </td>\n\n        ",
    "107": "<td>\n\n                <br/>\n\n                C. Wu, K. Varanasi, C. Theobalt,<br/>\n\n                <i>Full-body performance capture under uncontrolled and varying illumination : A shading-based approach</i><br/>\n\n                European Conference on Computer Vision (ECCV), 757 - 770 (2012).\n\t\t\t\t\t\t   <a href=\"files/eccv2012/shadingtracker.pdf\">[pdf]</a> \n\t\t\t\t\t\t   <a href=\"files/eccv2012/shadingtracker.avi\">[video]</a> \n\t\t\t\t\t\t   <a href=\"files/eccv2012/supplemental.pdf\">[supplementary material]</a>  \n\n            </td>\n\n        ",
    "106": "<td>\n\n                <br/>\n\n                D. Wu, Y. Liu, I. Ihrke, Q. Dai, C. Theobalt,<br/>\n\n                <i>Performance Capture of High-Speed Motion Using Staggered Multi-view Recording</i><br/>\n\n                Computer Graphics Forum (Proc. Pacific Graphics) 31 (7), 2019 - 2028 (2012).\n\t\t\t\t\t\t\t\t<a href=\"files/PG2012/PG2012.pdf\">[pdf]</a> \n\t\t\t\t\t\t\t\t<a href=\"files/PG2012/PG2012.mp4\">[video]</a>\n\t\t\t\t\t\t\t\t<a href=\"http://media.au.tsinghua.edu.cn/wudi/PerformanceCaptureStaggerMultiView.html\">[project page]</a>\n\n            </td>\n\n        ",
    "105": "<td>\n\n                <br/>\n               Y. Kown, K. I. Kim, J.-H. Kim, C. Theobalt,<br/>\n                <i> Efficient learning-based image enhancement: application to super-resolution and compression artifact removal</i><br/>\n  \t\t\t     in BMVC, 340 - 347 (2012). \n\t\t\t\t\t<a href=\"projects/imglearn/imglearn.htm\">[project page]</a>\n            </td>\n\n        ",
    "104": "<td>\n\n                <br/>\n\n                M. Richter, K. Varanasi, N. Hasler, C. Theobalt,<br/>\n\n                <i>Real-time reshaping of humans</i><br/>\n\n                International Conference on 3D Imaging, Data Processing, Visualization and Transmission (3DimPVT), 2012.\n\t\t\t\t\t\t\t\t<a href=\"files/3DimPVT/human_reshape.pdf\">[pdf]</a> \n\t\t\t\t\t\t\t\t<a href=\"files/3DimPVT/human_reshape.mp4\">[video]</a> \n            </td>\n\n        ",
    "103": "<td>\n\n                <br/>\n\n                A. Elhayek, C. Stoll, K. I. Kim, H.-P. Seidel, C. Theobalt<br/>\n\n                <i>Feature-Based Multi-Video Synchronization with Subframe Accuracy</i><br/>\n\n                 in: Pattern Recognition. Springer Lecture Notes in Computer Science (DAGM), 2012.\n\t\t\t\t\t\t   <a href=\"files/DAGM2012/DAGM2012.pdf\">[pdf]</a>\n\t\t\t\t\t\t   <a href=\"files/DAGM2012/DAGM2012_materials.pdf\">[supplementary material]</a>\t \n\n            </td>\n\n        ",
    "102": "<td>\n                <br/>\n                J. Tompkin, K.I. Kim, J. Kautz, C. Theobalt<br/>\n                <i>Videoscapes: Exploring Sparse, Unstructured Video Collections</i><br/>\n                in ACM Transactions on Graphics (Proc. of SIGGRAPH) 31 (4), 1 - 12 (2012). \n\t\t\t\t   <a href=\"files/SIGGRAPH2012/videoscapes.pdf\">[pdf]</a>\n\t\t\t\t\t<a href=\"files/SIGGRAPH2012/videoscapes-supplemental-material-final.pdf\">[supplementary material]</a>\n                    <a href=\"files/SIGGRAPH2012/videoscapes-supplemental-video-final.mp4\">[video]</a> <a href=\"files/SIGGRAPH2012/Videoscapes_SIGGRAPH2012_9_upload.pptx\">[pptx]</a>\n            </td>\n        ",
    "101": "<td>\n                <br/>\n                A. Elhayek, C. Stoll, N. Hasler, K. I. Kim, H.-P. Seidel, C. Theobalt<br/>\n                <i>Spatio-temporal Motion Tracking with Unsynchronized Cameras</i><br/>\n                 in IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Providence, USA, 1870 - 1877 (2012),\n                 <a href=\"files/old_site_files/ElhStoHasKimSeiThe12Spacetime.pdf\">\n                    [pdf]</a> <a href=\"files/old_site_files/ElhStoHasKimSeiThe12Spacetime.wmv\">\n                        [video]</a>\n            </td>\n        ",
    "100": "<td>\n                <br/>\n                G. Bharaj, T. Thorm&#195;&#164;hlen, H.-P. Seidel, C. Theobalt<br/>\n                <i>Automatically Rigging Multi-component Characters</i><br/>\n                 in Computer Graphics Forum (Proc. EUROGRAPHICS), 31 (2), 755 - 764 (2012). <a href=\"files/old_site_files/armc_eg_2012.pdf\">\n                    [pdf]</a> <a href=\"files/old_site_files/armc_eg_2012.avi\">[video]\n                </a><a href=\"http://www.mpi-inf.mpg.de/%7Egbharaj/papers/armc_eg_2012/index.html\">(project\n                    page)</a>\n            </td>\n        ",
    "99": "<td>\n                M. Granados, J. Tompkin, K. I. Kim, O. Grau, J. Kautz, C.\n                Theobalt<br/>\n                <i>How Not to Be Seen - Object Removal from Videos of Crowded Scenes </i>\n                <br/>\n                 in Computer Graphics Forum (Proc. EUROGRAPHICS), 31 (2), 219 - 228 (2012). <a href=\"projects/vidinp/granados12_vidinp.pdf\">\n                    [pdf]</a> <a href=\"projects/vidinp/granados12_vidinp.mp4\">[video]</a>\n\t\t\t\t\t<a href=\"projects/vidinp\">[project page]</a>\n            </td>\n        ",
    "98": "<td>\n                C. Richardt, C. Stoll, N. Dogdgson; H.-P. Seidel, C. Theobalt,<br/>\n                <i>Coherent Spatiotemporal Filtering, Upsampling and Rendering of RGBZ Videos</i><br/>\n                 in Computer Graphics Forum (Proc. EUROGRAPHICS), 31 (2), 247 - 256 (2012). <a href=\"files/old_site_files/rgbz.pdf\">\n                    [pdf]</a> <a href=\"http://vimeo.com/34294948\">[video]</a> <a href=\"http://www.mpi-inf.mpg.de/resources/rgbz-camera/\">\n                        [project page]</a>\n            </td>\n        ",
    "97": "<td>\n\n                A. Baak, M. M&#195;&#188;ller, G. Bharaj, H.-P. Seidel, C. Theobalt, <i>A Data-Driven Approach for Real-Time \n\t\t\t\tFull Body Pose Reconstruction from a Depth Camera</i>, in \n\t\t\t\t<a href=\"http://www.springer.com/computer/image+processing/book/978-1-4471-4639-1#\">\n\n                        Consumer Depth Cameras for Computer Vision</a>, A. Fossati, J. Gall, H. Grabner, \n\t\t\t\t\t\tX. Ren, and K. Konolige (Eds.), ISBN 978-1-4471-4639-1, Springer, 2012.\n\n            </td>\n\n        ",
    "96": "<td>\n                A. Elhayek, C. Stoll, K. I. Kim, H.-P. Seidel, C. Theobalt,<br/>\n                <i>Feature-Based Multi-Video Synchronization with Subframe Accuracy</i><br/>\n                 in: Pattern Recognition. Springer Lecture Notes in Computer Science (DAGM), 266 - 275 (2012).\n\t\t\t\t\t\t   <a href=\"files/DAGM2012/DAGM2012.pdf\">[pdf]</a>\n\t\t\t\t\t\t   <a href=\"files/DAGM2012/DAGM2012_materials.pdf\">[supplementary material]</a>\t\n            </td>\n        ",
    "95": "<td width=\"130\">\n\t\t\t\t</td>",
    "94": "<td>\n                C. Stoll, N. Hasler, J. Gall, H.-P. Seidel, C. Theobalt,<br/>\n                <i>Fast Articulated Motion Tracking using a Sums of Gaussians Body Model</i><br/>\n                IEEE International Conference on Computer Vision  (ICCV), 951 - 958 (2011). <a href=\"files/old_site_files/sog.pdf\">\n                    [pdf]</a> <a href=\"files/old_site_files/sog.mp4\">[video]</a>\n            </td>\n        ",
    "93": "<td>\n                C. Wu, K. Varanasi, Y. Liu, H.-P. Seidel, C. Theobalt,<br/>\n                <i>Shading-based Dynamic Shape Refinement from Multi-view Video under General Illumination</i>,\n                <br/>\n                IEEE International Conference on Computer Vision (ICCV), 1108 - 1115 (2011).<a href=\"files/old_site_files/dynamicshading.pdf\">[pdf]</a>\n                <a href=\"files/old_site_files/dynamicshading.avi\">[video]</a>\n            </td>\n        ",
    "92": "<td>\n                A. Baak, M. M&#195;&#188;ller, G. Bharaj, H.-P. Seidel, C. Theobalt<br/>\n                <i>A Data-Driven Approach for Real-Time Full Body Pose Reconstruction from a Depth Camera</i><br/>\n                IEEE International Conference on Computer Vision (ICCV), 1092 - 1099 (2011). <a href=\"files/old_site_files/2011_Baak_ICCV.pdf\">\n                    [pdf]</a> <a href=\"files/old_site_files/2011_Baak_ICCV.avi\">[video]</a>\n                <a href=\"projects/DataDrivenDepthTracking/index.html\">(project\n                    page)</a>\n            </td>\n        ",
    "91": "<td>\n                F. Xu, Y. Liu, C. Stoll, J. Tompkin, G. Bharaj, Q. Dai,\n                H.-P. Seidel, J. Kautz, C. Theobalt<br/>\n                <i>Video-based Characters - Creating New Human Performances from a Multi-view Video\n                    Database</i><br/>\n                in ACM Transactions on Graphics 30(4) (Proc. of SIGGRAPH 2011) <a href=\"files/old_site_files/vbc_2011/vbc_2011.pdf\">\n                    [pdf]</a> <a href=\"files/old_site_files/vbc_2011/vbc_2011.mp4\">[video]</a><br/>\n            </td>\n        ",
    "90": "<td>\n                Y. Liu, C. Stoll, J. Gall, H.-P. Seidel, C. Theobalt,<br/>\n                <i>Markerless Motion Capture of Interacting Characters Using Multi-view Image Segmentation</i><br/>\n                IEEE Conference on Computer Vision and Pattern Recognition (CVPR),<br/>\n                p. 1249-1256, 2011 - oral presentation. <a href=\"files/old_site_files/multitrack_cvpr11.pdf\">\n                    [pdf]</a> <a href=\"files/old_site_files/mmic.mp4\">[video]</a><br/>\n                <small>\n                    <br/>\n                    <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n                        <tbody>\n                            <tr>\n                                <!--\t\t\t\t<td><img style=\"margin: 0em 0em 0em 1em;\" src=\"./images/pdf.gif\" border=\"0\" width=\"20\" height=\"20\"></td> <td><a href=\"\">[pdf]</a></td>\n\t\t\t\t<td><img style=\"margin: 0em 0em 0em 1em;\" src=\"./images/vid.gif\" border=\"0\" width=\"20\" height=\"20\"></td> <td>[video]</td> -->\n                            </tr>\n                        </tbody>\n                    </table>\n                </small>\n            </td>\n        ",
    "89": "<td>\n                C. Wu, B. Wilburn, Y. Matsushita, C. Theobalt,<br/>\n                <i>High-quality shape from multi-view stereo and shading under general illumination</i><br/>\n                IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2011. <a href=\"files/old_site_files/shadingcue_CVPR11.pdf\">\n                    [pdf]</a> <a href=\"/projects/shadingcue/index.html\">(data)</a><br/>\n                <small>\n                    <br/>\n                    <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n                        <tbody>\n                            <tr>\n                                <!--\t\t\t\t<td><img style=\"margin: 0em 0em 0em 1em;\" src=\"./images/pdf.gif\" border=\"0\" width=\"20\" height=\"20\"></td> <td>[pdf]</td>\n\t\t\t\t<td><img style=\"margin: 0em 0em 0em 1em;\" src=\"./images/vid.gif\" border=\"0\" width=\"20\" height=\"20\"></td> <td>[video]</td> -->\n                            </tr>\n                        </tbody>\n                    </table>\n                </small>\n            </td>\n        ",
    "88": "<td>\n\t\t\t\t\tK.I. Kim, Y. Kwon, C. Theobalt,<br/> <i>Efficient Learning-based Image Enhancement</i>,<br/>\n                            MPI-I-2011-4-002, 2011. \n            </td>\n        ",
    "87": "<td width=\"130\">\n\t\t\t\t</td>",
    "86": "<td>\n                C. Stoll, J. Gall, E. de Aguiar, S. Thrun, C. Theobalt,<br/>\n                <i>Video-based Reconstruction of Animatable Human Characters</i><br/>\n                on Graphics (Proc. SIGGRAPH ASIA), 29(6), p. 139-149 (2010), Seoul, Korea.<br/>\n                <a href=\"files/old_site_files/vrhc.pdf\">[pdf]</a> <a href=\"files/old_site_files/vrhc.mp4\">\n                    [video]</a> <a href=\"http://www.mpi-inf.mpg.de/resources/perfcap/index_vrhc.html\">[project page]</a>\n            </td>\n        ",
    "85": "<td>\n                A. Jain, T. Thormaehlen, H.-P. Seidel, C. Theobalt,<br/>\n                <i>MovieReshape: Tracking and Reshaping of Humans in Videos</i><br/>\n                 in ACM Transactions on Graphics (Proc. SIGGRAPH ASIA), 29(6), p.149-157 (2010), Seoul, Korea.<br/>\n                <a href=\"files/old_site_files/MovieReshape.pdf\">[pdf]</a> <a href=\"files/old_site_files/MovieReshape.avi\">\n                    [video]</a> <a href=\"http://www.mpi-inf.mpg.de/resources/MovieReshape/\">[project page]</a>\n            </td>\n        ",
    "84": "<td>\n                L. Valgaerts, A. Bruhn, H. Zimmer, J. Weickert, C. Stoll, C.\n                Theobalt,<br/>\n                <i>Joint Estimation of Motion, Structure and Geometry from Stereo Sequences</i><br/>\n                in Proc. of European Conference on Computer Vision (ECCV) 2010.<br/>\n                <a href=\"files/old_site_files/msgs.pdf\">[pdf]</a> <a href=\"http://www.mia.uni-saarland.de/valgaerts/eccv10/sceneflow/index.shtml\">\n                    [project page]</a><br/>\n            </td>\n        ",
    "83": "<td>\n                C. Linz, C. Lipski, L. Rogge, C. Theobalt, M. Magnor,<br/>\n                <i>Space-Time Visual Effects as a Post-Production Process</i>,<br/>\n                in Proc. ACM Workshop on 3D Video Processing, Firenze, Italy, 1 - 6 (October 2010) <a href=\"files/old_site_files/Linz_3DVP10.pdf\">\n                    (paper)</a><br/>\n            </td>\n        ",
    "82": "<td>\n                M. Granados, B. Ajdin, M. Wand, C. Theobalt, H.-P. Seidel,\n                H. P. A. Lensch,<br/>\n                <i>Optimal HDR reconstruction with linear digital cameras</i>,<br/>\n                In Proc. IEEE CVPR, 215 - 222 (2010) <a href=\"projects/opthdr/granados10_opthdr.pdf\">\n                    [pdf]</a><a href=\"projects/opthdr\">\n                    [project page]</a><br/>\n            </td>\n        ",
    "81": "<td>\n                <br/>\n                Y. Cui, S. Schuon, D. Chan, S. Thrun, C. Theobalt<br/>\n                <i>3D Shape Scanning with a Time-of-Flight Camera</i><br/>\n                In Proc. of CVPR, p. 1173-1180 (2010),  <a href=\"http://ai.stanford.edu/%7Eschuon/sr/cvpr10_scanning.pdf\">\n                    [pdf]</a> <a href=\"http://ai.stanford.edu/%7Eschuon/sr/cvpr10_scanning_additional.pdf\">[supplementary material]</a> <a href=\"http://www.youtube.com/watch?v=IXr9zqz6Bjc\">[video]</a>\n                <a href=\"files/old_site_files/tof/\">[data]</a>\n            </td>\n        ",
    "80": "<td>\n                C. Theobalt, E. de Aguiar, C. Stoll, H-P. Seidel, S. Thrun, <i>Performance Capture from\n                    Multi-view Video</i>, in <a href=\"http://www.springer.com/mathematics/book/978-3-642-12391-7\">\n                        Image and Geometry Procesing for 3D-Cinematography</a>, R. Ronfard and G.\n                Taubin (Eds.), ISBN 978-3-642-12391-7, Springer, 2010.\n            </td>\n        ",
    "79": "<td width=\"130\">\n\t\t\t\t</td>",
    "78": "<td>\n                <br/>\n                S. Levine, C. Theobalt, V. Koltun,<br/>\n                <i>Real-Time Prosody-Driven Synthesis of Body Language.</i><br/>\n                in ACM TOG (Proc. of SIGGRAPH Asia), 28(5), 2009, Yokohama, Japan.<a href=\"files/old_site_files/bodylanguage.pdf\">[pdf]</a>\n                <a href=\"files/old_site_files/bodylanguage.avi\">[video]</a>\n            </td>\n        ",
    "77": "<td>\n                <br/>\n                Y. M. Kim, C. Theobalt, J. Diebel, J. Kosecka, B. Micusik,\n                S. Thrun,<br/>\n                <i>Multi-view Image and ToF Sensor Fusion for Dense 3D Reconstruction</i>.\n                <br/>\n                In Proc. of 3DIM 2009, co-hosted with ICCV 2009. <a href=\"files/old_site_files/3dim09.pdf\">\n                    [pdf]</a> <a href=\"http://www.stanford.edu/%7Ejinhae/iccv09/\">(Project Page)</a>\n            </td>\n        ",
    "76": "<td>\n                S. Srivastava, A. Saxena, C. Theobalt, S. Thrun, A. Y.~Ng,<br/>\n                <i>i23 - Rapid Interactive 3D Reconstruction from a Single Image</i>, Proc. VMV,\n                2009 <a href=\"files/old_site_files/interactive3d.pdf\">[pdf]</a><a href=\"http://www.youtube.com/watch?v=IkP5bcl8SiQ\">[video]</a>\n            </td>\n        ",
    "75": "<td>\n                S. Schuon, C. Theobalt, J. Davis, S. Thrun,\n                <br/>\n                <i>LidarBoost: Depth Superresolution for ToF 3D Shape Scanning</i>.<br/>\n                In Proc. of IEEE CVPR, p. 343-350, 2009. <a href=\"files/old_site_files/cvpr09_superresolution.pdf\">\n                    [pdf]</a> <a href=\"files/old_site_files/cvpr09_superresolution_additional.pdf\">\n                        [supplementary material]</a><a href=\"files/old_site_files/tof/\">[data]</a>\n            </td>\n        ",
    "74": "<td>\n                J. Gall, C. Stoll, E. de Aguiar Edilson, C. Theobalt, B. Rosenhahn, H.-P. Seidel.<br/>\n                <i>Motion Capture using Joint Skeleton Tracking and Surface Estimation</i><br/>\n                Proc. IEEE Conference on Computer Vision and Pattern Recognition 2009 <a href=\"http://www.mpi-inf.mpg.de/%7Estoll/paper/stse.pdf\">\n                    [pdf]</a> <a href=\"http://www.vision.ee.ethz.ch/%7Egallju/projects/skelsurf/index.html\">\n                        [project]</a>\n            </td>\n        ",
    "73": "<td width=\"130\">\n\t\t\t\t</td>",
    "72": "<td>\n                Y.M. Kim, D. Chan, C. Theobalt, S. Thrun,\n                <br/>\n                <i>Design and Calibration of a Multi-view TOF Sensor Fusion System.</i><br/>\n                in Proc. IEEE CVPR Workshop on Time-of-flight Computer Vision 2008. <a href=\"files/old_site_files/TOF_CV_mvfuse_calib_final.pdf\">\n                    [pdf]</a>\n                <br/>\n            </td>\n        ",
    "71": "<td>\n                D. Chan, H. Buisman, C. Theobalt, S. Thrun. <i>A Noise-aware Filter for Real-time Depth\n                    Upsampling</i>,<br/>\n                in Proc. of ECCV Workshop on Multi-camera and Multi-modal Sensor Fusion Algorithms\n                and Applications, 2008.<a href=\"files/old_site_files/eccv08.pdf\"> [pdf]</a><br/>\n            </td>\n        ",
    "70": "<td>\n                S. Schuon, C. Theobalt, J. Davis, S. Thrun,\n                <br/>\n                <i>High-quality Scanning using Time-of-Flight Depth Superresolution.</i><br/>\n                in IEEE CVPR Workshop on Time-Of-Flight Computer Vision 2008. <a href=\"files/old_site_files/TOF_CV_Superresolution_final.pdf\">\n                    [pdf]</a>\n                <br/>\n            </td>\n        ",
    "69": "<td>\n                E. de Aguiar, C. Stoll , C. Theobalt, N. Ahmed, H.-P. Seidel, S. Thrun,\n                <br/>\n                <i>Performance Capture from Sparse Multi-view Video</i>,<br/>\n                in Proc. of SIGGRAPH 2008, ACM TOG 27(3), 2008. Los Angeles, USA. \n\t\t\t\t<a href=\"http://www.mpi-inf.mpg.de/resources/perfcap/\">[project page]</a>\n                <br/>\n                <blink> Data now available !</blink>\n                <br/>\n            </td>\n        ",
    "68": "<td>\n                N. Ahmed, C. Theobalt, P. Dobrev, H.-P. Seidel, S. Thrun,\n                <br/>\n                <i>Robust Fusion of Dynamic Shape and Normal Capture for High-quality Reconstruction\n                    of Time-varying Geometry</i>,<br/>\n                in Proc. of CVPR 2008. <a href=\"files/old_site_files/cvpr08b.pdf\">[pdf]</a>\n                <a href=\"files/old_site_files/CVPR08b.wmv\">[video]</a>\n            </td>\n        ",
    "67": "<td>\n                N. Ahmed, C. Theobalt, C. Roessl, S. Thrun, H.-P. Seidel,\n                <br/>\n                <i>Dense Correspondence Finding for Parametrization-free Animation Reconstruction from\n                    Video</i>,\n                <br/>\n                in Proc. of CVPR 2008. [Oral presentation - Acceptance Rate 3.95%] <a href=\"files/old_site_files/cvpr08a.pdf\">\n                    [pdf]</a> <a href=\"files/old_site_files/CVPR08a.wmv\">[video]</a>\n            </td>\n        ",
    "66": "<td>\n                E. de Aguiar, C. Theobalt, S. Thrun, H.-P. Seidel,\n                <br/>\n                <i>Automatic Conversion of Mesh Animations into Skeleton-based Animations.</i><br/>\n                In Proc. of EUROGRAPHICS 2008 (Computer Graphics Forum, vol. 27 issue 2), Crete,\n                Greece.\n                <br/>\n                <!-- [<a href=\"publications/deAguiar_eg08.pdf\">pdf</a>]   -->\n                [<a href=\"http://www.mpi-inf.mpg.de/%7Eedeaguia/animation_eg08.html#bib_eg08\">BibTeX</a>]\n                [<a href=\"http://www.mpi-inf.mpg.de/%7Eedeaguia/animation_eg08.html\">project page</a>]\n            </td>\n        ",
    "65": "<td>\n                M. Eisemann, B. de Decker, M. Magnor, P. Bekaert, E. de Aguiar, N. Ahmed, C. Theobalt,\n                A. Sellent,\n                <br/>\n                <i>Floating Textures.</i><br/>\n                In Proc. of EUROGRAPHICS 2008 (Computer Graphics Forum, vol. 27 issue 2), Crete,\n                Greece. <a href=\"files/old_site_files/Eisemann08FT_EG08.pdf\">[pdf]</a>\n                <a href=\"files/old_site_files/Eisemann08FT_EG08_final.avi\">[video]</a><br/>\n                <!-- [<a href=\"publications/deAguiar_hm07.pdf\">pdf</a>]   -->\n                <!-- [<a href=\"http://www.mpi-inf.mpg.de/~edeaguia/deformablemeshtracking.html#bib_cvpr07\">BibTeX</a>]  -->\n                <!-- [<a href=\"http://www.mpi-inf.mpg.de/~edeaguia/deformablemeshtracking.html\">project page</a>]  -->\n            </td>\n        ",
    "64": "<td>\n                C. Theobalt, E. de Aguiar, M. Magnor, H.-P. Seidel. <i>Reconstructing human shape, motion\n                    and appearance from multi-view video,</i> in <a href=\"http://www.springer.com/west/home/new+%26+forthcoming+titles+%28default%29?SGWID=4-40356-22-173739822-0\">\n                        Three-dimensional Television</a> , H. Ozaktas, L. Onural (Eds.), ISBN-978-3-540-72531-2,\n                Springer, 2008.\n            </td>\n        ",
    "63": "<td>\n                C. Theobalt, M. Magnor, H.-P. Seidel, <i>Video-based Capturing and Rendering of People</i>,\n                chapter in book <a href=\"http://www.springer.com/computer/image+processing/book/978-1-4020-6692-4\">\n                    <i>Human Motion - Understanding, Modeling, Capture and Animation</i></a>, B.\n                Rosenhahn, R. Klette, D. Metaxas (Eds.), ISBN 978-1402066924, Springer, 2008.\n                <br/>\n            </td>\n        ",
    "62": "<td width=\"130\">\n\t\t\t\t</td>",
    "61": "<td>\n                Z. Dong, J. Kautz, C. Theobalt, H.-P. Seidel.\n                <br/>\n                <i>Interactive Global Illumination Using Implicit Visibility</i>,<br/>\n                Accepted by Pacific Graphics 2007 (oral paper),<a href=\"http://www.mpi-inf.mpg.de/%7Edong/download/PG07_ImplicitVis.pdf\">[PDF]</a>\n            </td>\n        ",
    "60": "<td>\n                C. Theobalt, C. Roessl, E. de Aguiar, H.-P. Seidel,<br/>\n                <i>Animation Collage</i>,<br/>\n                Proc. ACM SIGGRAPH/EUROGRAPHICS Symposium on Computer Animation, p. 271-280, 2007, San Diego,\n                USA. [<a href=\"files/old_site_files/SCA2007/anim_collage.html\">project page</a>]<br/>\n                <br/>\n            </td>\n        ",
    "59": "<td>\n                N. Ahmed, C. Theobalt, M. Magnor, H.-P. Seidel,<br/>\n                <i>Spatio-Temporal Registration Techniques for Relightable 3D Video</i>,<br/>\n                Proc. of IEEE ICIP, p. 501-504, 2007 [<a href=\"http://www.mpi-sb.mpg.de/%7Etheobalt/RFVV/index.html\">project\n                    page</a>]<br/>\n            </td>\n        ",
    "58": "<td>\n                I. Ihrke, G. Ziegler, A. Tevs, C. Theobalt, M. Magnor, H.-P. Seidel,<br/>\n                <i>Eikonal Rendering - Efficient Light Transport in Refractive Objects.</i><br/>\n                ACM Transactions on Graphics (Proc. of ACM SIGGRAPH 2007), ACM TOG, 26(3), p. 59ff, San Diego, USA. [<a href=\"http://www.mpi-inf.mpg.de/resources/EikonalRendering/index.html\">project\n                    page</a>]<br/>\n            </td>\n        ",
    "57": "<td>\n                M. Song, Z. Dong, C. Theobalt, H. Wang, Z. Liu, H.-P. Seidel,<br/>\n                <i>A Generic Framework for Efficient 2D and 3D Facial Expression Analogy</i>,<br/>\n                IEEE Transactions on Multimedia, 9(7), p.1384-1395, 2007. \n\t\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?isnumber=4351892&amp;arnumber=4351915&amp;count=25&amp;index=6\">\n                        [Publisher's page]</a> <a href=\"files/old_site_files/IEEE_mm_2007_preprint.pdf\">\n                            (preprint)\n                            <br/>\n                        </a>\n            </td>\n        ",
    "56": "<td>\n                C. Stoll, E. de Aguiar, C. Theobalt, H.-P. Seidel,<br/>\n                <i>A Volumetric Approach to Interactive Shape Editing.</i><br/>\n                Technical Report MPI-I-2007-4-004, MPII, 2007. [<a href=\"http://www.mpi-inf.mpg.de/%7Eedeaguia/publications/deAguiar_tr2007.pdf\">pdf</a>]\n                [<a href=\"http://www.mpi-inf.mpg.de/%7Eedeaguia/edeaguia_tr07.avi\">avi</a>]\n                <!-- [<a href=\"http://www.mpi-inf.mpg.de/~edeaguia/deformablemeshtracking.html#bib_cvpr07\">BibTeX</a>]  -->\n                <!-- [<a href=\"http://www.mpi-inf.mpg.de/~edeaguia/deformablemeshtracking.html\">project page</a>]  -->\n            </td>\n        ",
    "55": "<td>\n                E. de Aguiar, C. Theobalt, C. Stoll, H.-P. Seidel,<br/>\n                <i>Marker-less Deformable Mesh Tracking for Human Shape and Motion Capture.</i><br/>\n                In Proc. of IEEE CVPR 2007, Minneapolis, USA.<br/>\n                [<a href=\"http://www.mpi-inf.mpg.de/%7Eedeaguia/publications/deAguiar_cvpr07.pdf\">pdf</a>]\n                [<a href=\"http://www.mpi-inf.mpg.de/%7Eedeaguia/deformablemeshtracking.html#bib_cvpr07\">BibTeX</a>]\n                [<a href=\"http://www.mpi-inf.mpg.de/%7Eedeaguia/deformablemeshtracking.html\">project\n                    page</a>]\n            </td>\n        ",
    "54": "<td>\n                Rapid Animation of Laser-scanned Humans.<br/>\n                <br/>\n                E.de Aguiar, C. Theobalt, C. Stoll, H.-P. Seidel,<br/>\n                <i>Rapid Animation of Laser-scanned Humans</i>,<br/>\n                in Proc. of IEEE Virtual Reality 2007, Charlotte, USA.<a href=\"http://www.mpi-inf.mpg.de/%7Eedeaguia/publications/deAguiar_vr07.pdf\">[paper]</a><br/>\n            </td>\n        ",
    "53": "<td>\n\n                <br/>\n                N. Ahmed, C. Theobalt, H.-P. Seidel,<br/>\n                <i>Spatio-temporal Reflectance Sharing for Relighatble 3D Video</i>,<br/>\n                Proc. of MIRAGE, Paris, 2007.<a href=\"files/old_site_files/camera134.pdf\">[paper]</a>\n                [<a href=\"http://www.mpi-sb.mpg.de/%7Etheobalt/RFVV/index.html\">project page</a>]\n                <br/>\n            </td>\n        ",
    "52": "<td>\n                GPU-based Realtime Quadtree/Octree Analysis<br/>\n                <br/>\n                G. Ziegler, R. Dimitrov, C. Theobalt, H.-P.Seidel,<br/>\n                <i>Real-time Quadtree Analysis using HistoPyramids</i>,<br/>\n                in Proc. of IS&amp;T/SPIE Symposium on Electronic Imaging, 2007, San Jose, CA.<a href=\"http://www.mpi-inf.mpg.de/%7Egziegler/gpu_quadtree/electronic_imaging_2006.pdf\">[paper]</a><a href=\"http://www.mpi-inf.mpg.de/%7Egziegler/gpu_quadtree/\">[videos]</a><br/>\n                <br/>\n            </td>\n        ",
    "51": "<td>\n               C. Theobalt, N. Ahmed, G.Ziegler, H.-P. Seidel,\n                <br/>\n                <i>High-quality Reconstruction of Virtual Actors from Multi-view Video Streams,</i><br/>\n                 in IEEE Signal Processing Magazine, 24(6), 2007. <a href=\"files/old_site_files/SPM_2008.pdf\">[pdf]</a> <br/>\n            </td>\n        ",
    "50": "<td>\n               E. Stoykova, A. Alatan, P. Benzie, N. Grammalidis, S. Malassiotis, J. Ostermann,\n                            S. Piekh, V. Sainov, C. Theobalt, T. Thevar, X. Zabulis,\n                <br/>\n                <i>3DTV: 3D Time-varying Scene\n                                Capture Technologies - A Survey,</i>\n                 in IEEE Transactions on Circuits and Systems\n                            for Video Technology, 17(11), p. 1568-1586, 2007. <br/>\n            </td>\n        ",
    "49": "<td>\n               C. Theobalt, N. Ahmed, H. Lensch, M. Magnor, H.-P. Seidel,\n                <br/>\n                <i>Seeing People in Different\n                            Light: Joint Shape, Motion, and Reflectance Capture,</i><br/>\n                 in IEEE Transactions on\n                            Visualization and Computer Graphics, 13(4), p. 663-674 2007. (<a href=\"http://doi.ieeecomputersociety.org/10.1109/TVCG.2007.1006\">publisher's\n                                webpage</a>)(<a href=\"files/old_site_files/theobalt_tvcg2007.pdf\">PDF</a>)\n            </td>\n        ",
    "48": "<td>\n                <br/>\n\nC. Weidenbach, B. Afshordel, U. Brahm, C. Cohrs, T. Engel, E. Keen, C. Theobalt,\n                            D. Topic. <i>System Description: SPASS Version 1.0.0</i>&#160;. In Harald Ganzinger,\n                            editor, Proc. 16th Int. Conf. on Automated Deduction (CADE-16-99), LNCS 1632, pages\n                            378-382. Springer Verlag, 1999.\t\t\t\n            </td>\n        ",
    "47": "<td>\n                <br/>\n\n                E. de Aguiar, C. Theobalt, C. Stoll, H.-P. Seidel,<br/>\n\n                <i>Marker-less 3D Feature Tracking for Mesh-based Human Motion Capture,</i><br/>\n\t\t\t\t\n\t\t\t\tin ICCV Workshop on Human Motion\n                            - Understanding, Modeling, Capture and Animation, LNCS Vol. 4814, p. 1-15, 2007,\n                            Rio de Janeiro, Brazil. <a href=\"http://www.mpi-inf.mpg.de/~edeaguia/publications/deAguiar_hm07.pdf\">\n                                [pdf]</a>. \n\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n        ",
    "46": "<td>\n                <br/>\n\n                E. de Aguiar, R. Zayer, C. Theobalt, M. Magnor, H.-P. Seidel,<br/>\n\n                <i>A Simple Framework for Natural Animation of Digitized Models,</i><br/>\n\t\t\t\t\n\t\t\t\tProc. of SIBGRAPI. IEEE Press, p.\n                            3-10, 2007. <a href=\"files/old_site_files/deAguiar_sibgrapi07.pdf\">[pdf]</a>.\n\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n        ",
    "45": "<td>\n                <br/>\n\n                E. de Aguiar, R. Zayer, C. Theobalt, M. Magnor, H.-P. Seidel,<br/>\n\n                <i>Video-driven Animation of Human Body Scans,</i><br/>\n\t\t\t\t\n\t\t\t\tProc. of SIBGRAPI. IEEE Press, p.\n                            3-10, 2007. <a href=\"files/old_site_files/deAguiar_sibgrapi07.pdf\">[pdf]</a>.\n\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n        ",
    "44": "<td>\n                <br/>\n\n                E. de Aguiar, R. Zayer, C. Theobalt, M. Magnor, H.-P. Seidel, <br/>\n\n                <i>Video-driven Animation of Human Body Scans,</i><br/>\n\t\t\t\t\n\t\t\t\tIEEE 3DTV-Conference, 2007, Kos Island, Greece. <a href=\"files/old_site_files/deAguiar_3dtvcon07.pdf\">\n                                [pdf]</a>.\n\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n        ",
    "43": "<td>\n                <br/>\n\n\t\t\tC. Stoll, E. de Aguiar, C. Theobalt, H.P. Seidel,<br/> <i>A Volumetric Approach to Interactive\n                            Shape Editing </i>,<br/>  MPI-I-2007-4-004, 2007.\n\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n        ",
    "42": "<td width=\"130\">\n\t\t\t\t</td>",
    "41": "<td>\n                <br/>\n                G. Ziegler, A. Tevs, C. Theobalt, H.-P. Seidel,<br/>\n                <i>GPU Point List Generation Through Histogram Pyramids</i>,<br/>\n                in Proc. of VMV'06, p. 137--141, Aachen, Germany, 2006. <a href=\"http://www.mpi-inf.mpg.de/%7Egziegler/gpu_pointlist/paper17_gpu_pointclouds.pdf\">\n                    [paper]</a><a href=\"http://www.mpi-inf.mpg.de/%7Egziegler/gpu_pointlist/heartbreaker.mpg\">[videos]</a><br/>\n                <br/>\n            </td>\n        ",
    "40": "<td>\n\t\t\t\t\t\tC. Theobalt, N. Ahmed, H. Lensch, M. Magnor, H.-P. Seidel,<br/>\n\t\t\t\t\t\t<i>Enhanced Dynamic Reflectometry for Relightable Free-Viewpoint Video</i>,<br/>\n\t\t\t\t\t\tMPI-I-2006-4-006, 2006.\n            </td>\n        ",
    "39": "<td>\n\t\t\t\t\tE. de Aguiar, R. Zayer, C. Theobalt, M. Magnor, H.-P. Seidel,<br/> <i>A Framework for\n                            Natural Animation of Digitized Models</i>,<br/>\n\t\t\t\t\t\t\tMPI-I-2006-4-003, 2006.\n            </td>\n        ",
    "38": "<td>\n\t\t\t\t\tE. de Aguiar, R. Zayer, C. Theobalt, M. Magnor, H.-P. Seidel,<br/> <i>A Framework for\n                            Natural Animation of Digitized Models</i>,<br/>\n\t\t\t\t\t\t\tMPI-I-2006-4-003, 2006.\n            </td>\n        ",
    "37": "<td width=\"130\">\n\t\t\t\t</td>",
    "36": "<td>\n                <i> E. de Aguiar, C. Theobalt, M. Magnor, H.-P. Seidel,</i><br/> Reconstructing Human Shape\n                            and Motion from Multi-view Video, <br/>  in Proc. of CVMP 2005, p. 42-49, London,\n                            UK, 2005. <a href=\"http://www.mpi-inf.mpg.de/~edeaguia/publications/deAguiar_cvmp05.pdf\">\n                                [pdf]</a> (<a href=\"http://www.mpii.mpg.de/%7Eedeaguia/projects.html#reconstruction\">project\n                    page</a>)\n            </td>\n        ",
    "35": "<td>\n\t\t\t\t\t\t\t\tC. Theobalt, M. Magnor, H.-P. Seidel,<br/> <i>3D Image Analysis and Synthesis at MPI\n\t\t\t\t\t\t\t\tInformatik</i>, <br/>invited paper, in Proc. of Vision, Video and Graphics, p. 85-91,\n\t\t\t\t\t\t\t\tEdinburgh, UK, 2005.<br/>\n\t\t\t\t</td>\n\t\t\t",
    "34": "<td>\n\t\t\t\t\t\t\tC. Theobalt, N. Ahmed, E. de Aguiar, G. Ziegler, H. Lensch, M. Magnor, H.-P. Seidel,<br/>\n                            <i>Joint Motion and Reflectance Capture for Creating Relightable 3D Videos</i>,<br/>\n                            Technical Report MPI-I-2005-4-004, Max-Planck-Institut fuer Informatik, 2005.\n            </td>\n        ",
    "33": "<td width=\"130\">\n\t\t\t\t</td>",
    "32": "<td>\n               C. Theobalt, J. Carranza, M. Magnor, H.-P. Seidel,\n                <br/>\n                <i>Combining 3D Flow Fields with\n                            Silhouette-based Human Motion Capture for Immersive Video,</i><br/>\n                 in Graphical Models,\n                            66, pages 333-351, 2004. <!--<a href=\"http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6WG3-4D9D7YV-1&_coverDate=11%2F01%2F2004&_alid=248029160&_rdoc=1&_fmt=&_orig=search&_qd=1&_cdi=6811&_sort=d&view=c&_acct=C000004638&_version=1&_urlVersion=0&_userid=43521&md5=05381e6a3fc3d02633b9b46c940120ad\">\n                                (publisher)</a>--> <a href=\"files/old_site_files/gm_article.pdf\">(preprint PDF)</a>\n            </td>\n        ",
    "31": "<td>\n               C. Theobalt, J. Carranza, M. Magnor, H.-P. Seidel,\n                <br/>\n                <i>3D Video - Being Part of the\n                            Movie,</i><br/>\n                 in ACM Computer Graphics, Vol. 38, No. 3, pages 18-20, 2004. <a href=\"files/old_site_files/SIGGRAPH_p18-20.pdf\">\n                                [pdf]</a>,<a href=\"http://www.siggraph.org/publications/newsletter/issues/v38/v38n3.pdf\">(complete\n                                    journal issue)</a>\n            </td>\n        ",
    "30": "<td>\n                <br/>\n\n                C. Theobalt, M. Magnor, P. Schueler, H.P. Seidel,<br/>\n\n                <i>Combining 2D Feature Tracking\n                            and Volume Reconstruction for Online Video-based Human Motion Capture,</i><br/>\n\t\t\t\t\n\t\t\t\textended paper, in International Journal of Image and Graphics (IJIG) - Special issue on\n                            Combining Images and Graphics, Vol. 4, No. 4, pages 563-583, 2004. <a href=\"http://www.worldscinet.com/ijig/04/0404/S0219467804001543.html\">\n                                (publisher)</a> <a href=\"files/old_site_files/IJIG04_draft.pdf\">(preprint)</a>.  \n\t\t\t\t\t\t\t\t\t\t\t\t\t  \n            </td>\n        ",
    "29": "<td>\nC. Theobalt, E. de Aguiar, M. Magnor, H. Theisel, H.-P. Seidel,<br/> <i>Marker-free Kinematic\n                            Skeleton Estimation from Sequences of Volume Data</i>.<br/> Proc. of ACM Symposium on\n                            Virtual Reality Software and Technology (VRST), p.57-64, Hong Kong, China, 2004.<a href=\"files/old_site_files/vrst2004_paper.pdf\">[pdf]</a> \n            </td>\n        ",
    "28": "<td>\nE. de Aguiar, C. Theobalt, M. Magnor, H. Theisel, H.-P. Seidel,<br/> <i>M^3: Marker-free\n                            Model Reconstruction and Motion Tracking from 3D Voxel Data</i>,<br/> in Proc. of Pacific\n                            Graphics, p.101-110, Seoul, Korea, 2004.<a href=\"http://www.mpi-sb.mpg.de/~edeaguia/publications/deAguiar_pg2004.pdf\">[pdf]</a>\n                        \n\t\t\t\t\t\t</td>\n        ",
    "27": "<td>\nC. Theobalt, G. Ziegler, M. Magnor, H.-P. Seidel,<br/> <i>Model-Based Free-Viewpoint\n                            Video: Acquisition, Rendering and Encoding </i>,<br/> Proc. Picture Coding Symposium\n                            (PCS'04), San Francisco, USA, 2004. <a href=\"files/old_site_files/pcs2004_paper.pdf\">\n                                [pdf]</a> \n            </td>\n        ",
    "26": "<td>\nM. Magnor, C. Theobalt, <i>Model-based Analysis of Multi-Video Data</i>, Proc. IEEE\n                            Southwest Symposium on Image Analysis and Interpretation (SSIAI'2004), Lake Tahoe,\n                            USA, accepted. <a href=\"files/old_site_files/ssiai04.pdf\">[pdf]</a>\n            </td>\n        ",
    "25": "<td>\n\t\t\t\n\t\t\tC. Theobalt, I. Albrecht, J. Haber, M. Magnor, H.-P. Seidel, <i>\n\t\t\t  <br/>\n\t\t\tPitching a Baseball - Tracking High-Speed Motion with Multi-Exposure Images</i>, Proc. of ACM SIGGRAPH\n\t\t2004 (ACM Transactions on Graphics Special issue), pages 540-547, Los Angeles, USA,\n\t\t2004. <a href=\"files/old_site_files/SIG2004a_final.pdf\">[pdf]</a>\n\t\t<a href=\"http://www.mpi-sb.mpg.de/%7Etheobalt/Baseball/index.html\">[project page]</a>\n            </td>\n        ",
    "24": "<td width=\"130\">\n\t\t\t\t</td>",
    "23": "<td>\n\t\t\t\n\t\t\t\n               J. Carranza, C. Theobalt. M. Magnor, H.P. Seidel, <i>\n\t\t\t\t\t\t   <br/>\n\t\t\t\t\t\tFree-Viewpoint Video of Human Actors</i>. in Proc. of ACM SIGGRAPH 2003, p.569-577, San Diego, CA. \n\t\t\t\t\t\t\n\t\t\t\t\t\t<a href=\"files/old_site_files/sig03_preprint.pdf\">[pdf]</a>\n\t\t\t\t\t\t<a href=\"http://www.mpi-sb.mpg.de/%7Etheobalt/FreeViewpointVideo/free_viewpoint_video.html\">(project\n                    page)</a>\n\t\t\n            </td>\n        ",
    "22": "<td>\nC. Theobalt, J. Carranza, M. Magnor, H.P. Seidel, <i>A Parallel Framework for Silhouette-based\n                            Human Motion Capture</i>, in Proc. of Vision, Modeling and Visualization, p.207-214,\n                            Munich, Germany, 2003. <a href=\"files/old_site_files/vmv2003_paper.pdf\">[pdf]</a>\n            </td>\n        ",
    "21": "<td>\nC. Theobalt, J. Carranza, M. Magnor, H.P. Seidel, <i>Enhancing Silhouette-based\n                            Human Motion Capture with 3D Motion Fields</i>, Proc. of Pacific Graphics 2003,p.185-193,\n                            Canmore, Canada. <a href=\"files/old_site_files/pg03_paper.pdf\">[pdf]</a>\n\t\t\t\t\t\t\t</td>\n        ",
    "20": "<td>\nC. Theobalt, M. Li, M Magnor, H.P. Seidel, <i>A Flexible and Versatile Studio for\n                            Synchronized Multi-View Video Recording</i>, in Proc. of Vision, Video and Graphics\n                            2003, p.9-16, Bath, UK.\n\t\t\t\t\t\t\t</td>\n        ",
    "19": "<td width=\"130\">\n\t\t\t\t</td>",
    "18": "<td>\n                <br/>\n\n                C. Theobalt, M. Magnor, P. Schueler, H.P. Seidel,<br/>\n\n                <i>Combining 2D Feature Tracking\n                            and Volume Reconstruction for Online Video-based Human Motion Capture,</i><br/>\n\t\t\t\t\n\t\t\t\t\t. in Proceedings\n                            of Pacific Graphics 2002, Beijing, China. p.96-103. <a href=\"files/old_site_files/VisualHullTracking/paper.pdf\">\n                                [pdf]</a>\t\t\t\t\t\t\t\t\t  \n            </td>\n        ",
    "17": "<td>\n                <br/>\n\nC. Theobalt, J. Bos, T. Chapman, A. Espinosa-Romero, M. Fraser, G. Hayes, E. Klein,\n                            T. Oka, R. Reeve. <i>Talking to Godot: Dialogue with a Mobile Robot.</i>&#160; Proc.\n                            of IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS2002). pages 1338-1343.\n                            Lausanne, Switzerland. 2002. <a href=\"files/old_site_files/745.pdf\">[pdf]</a>\n\t\t\t\t\t\t\t\n            </td>\n        ",
    "16": "<td>\nC. Theobalt, M. Magnor, P. Schueler, H.P. Seidel, <i>Multi-Layer Skeleton Fitting\n                            for Online Human Motion Capture</i>. in Proceedings of 7th International Fall Workshop\n                            on Vision, Modeling and Visualization (VMV 2002), Erlangen, Germany. p.471-478.\n                            <a href=\"files/old_site_files/vmv2002_final.pdf\">[pdf]</a>\n\t\t\t\t\t\t\t</td>\n        ",
    "15": "<td width=\"130\">\n\t\t\t\t</td>",
    "14": "<td>\n                The Relightable Free-Viewpoint Video Project. [<a href=\"http://www.mpi-sb.mpg.de/%7Etheobalt/RFVV/index.html\">project\n                    page</a>]\n            </td>\n        ",
    "13": "<td>\n                GPU-based Realtime Quadtree/Octree Analysis<br/>\n                <br/>\n                G. Ziegler, R. Dimitrov, C. Theobalt, H.-P.Seidel,<br/>\n                <i>Real-time Quadtree Analysis using HistoPyramids</i>,<br/>\n                in Proc. of IS&amp;T/SPIE Symposium on Electronic Imaging, 2007, San Jose, CA.<a href=\"http://www.mpi-inf.mpg.de/%7Egziegler/gpu_quadtree/electronic_imaging_2006.pdf\">[paper]</a><a href=\"http://www.mpi-inf.mpg.de/%7Egziegler/gpu_quadtree/\">[videos]</a><br/>\n                <br/>\n            </td>\n        ",
    "12": "<td>\n                GPU-based Data Compaction using HistoPyramids<br/>\n                <br/>\n                G. Ziegler, A. Tevs, C. Theobalt, H.-P. Seidel,<br/>\n                <i>GPU Point List Generation Through Histogram Pyramids</i>,<br/>\n                in Proc. of VMV'06, p. 137--141, Aachen, Germany, 2006. <a href=\"http://www.mpi-inf.mpg.de/%7Egziegler/gpu_pointlist/paper17_gpu_pointclouds.pdf\">\n                    [paper]</a><a href=\"http://www.mpi-inf.mpg.de/%7Egziegler/gpu_pointlist/heartbreaker.mpg\">[videos]</a><br/>\n                <br/>\n            </td>\n        ",
    "11": "<td>\n                Automatic Learning of Articulated Skeletons from 3D Marker Trajectories. <a href=\"http://www.mpii.mpg.de/%7Eedeaguia/mocapskeleton.html\">\n                    [project page]</a>\n            </td>\n        ",
    "10": "<td>\n                Confluent Motion - A Simple Method for Animating Scanned Geometry. [<a href=\"http://www.mpii.mpg.de/%7Eedeaguia/confluentmotion.html\">project\n                    page</a>]\n            </td>\n        ",
    "9": "<td>\n                Tracking High-speed Motion with Multi-exposure Images. [<a href=\"http://www.mpi-sb.mpg.de/%7Etheobalt/Baseball/index.html\">project\n                    page</a>]\n            </td>\n        ",
    "8": "<td>\n                Free-Viewpoint Video of Human Actors. [<a href=\"http://www.mpi-sb.mpg.de/%7Etheobalt/FreeViewpointVideo/free_viewpoint_video.html\">project\n                    page</a>]\n            </td>\n        ",
    "7": "<td>\n                Enhancing Human Motion Capture with 3D Motion Fields. [<a href=\"files/old_site_files/SceneFlowFitting/index.html\">project\n                    page</a>]\n            </td>\n        ",
    "6": "<td>\n                Automatic Generation of Human Avatars. [<a href=\"http://www.mpii.mpg.de/%7Eedeaguia/projects.html#avatar\">project\n                    page</a>]\n            </td>\n        ",
    "5": "<td>\n                Reconstructing Human Shape and Motion. [<a href=\"http://www.mpii.mpg.de/%7Eedeaguia/projects.html#reconstruction\">project\n                    page</a>]\n            </td>\n        ",
    "4": "<td>\n                Automatic Marker-less Reconstruction of Kinematic Skeletons. [<a href=\"http://www.mpi-sb.mpg.de/%7Etheobalt/model_reconstruction/model_reconstruction.html\">project\n                    page</a>]\n            </td>\n        ",
    "3": "<td>\n                Marker-free Human Motion Capture. [<a href=\"http://www.mpi-sb.mpg.de/%7Etheobalt/VisualHullTracking/index.html\">project\n                    page</a>]\n            </td>\n        ",
    "2": "<td>\n                Volumetric Reconstruction of Dynamic Scenes. [<a href=\"http://www.mpi-sb.mpg.de/%7Etheobalt/SceneReconstruction/scene_reconstruction.html\">project\n                    page</a>]\n            </td>\n        ",
    "1": "<td>\n                The secret projects - there are always secret projects :-)\n            </td>\n        ",
}